{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", valid=False, normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "        \n",
    "        if valid:\n",
    "            idx = int(len(inputs) * .8)\n",
    "            return inputs[:idx], inputs[idx:], outputs[:idx], outputs[idx:]\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = (self.inputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "    \n",
    "class ValidationDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, inputs, outputs, transform=None):\n",
    "        super(ValidationDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = inputs, outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(city = city, split = split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64  # batch size \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import random\n",
    "\n",
    "# def show_sample_batch(sample_batch):\n",
    "#     \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "#     inp, out = sample_batch\n",
    "#     batch_sz = inp.size(0)\n",
    "#     agent_sz = inp.size(1)\n",
    "    \n",
    "#     fig, axs = plt.subplots(1, batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "#     fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "#     axs = axs.ravel()   \n",
    "#     for i in range(batch_sz):\n",
    "#         axs[i].xaxis.set_ticks([])\n",
    "#         axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "#         axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "#         axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "# for i_batch, sample_batch in enumerate(train_loader):\n",
    "#     # inp[i] is a scene with 50 coordinates, input[i, j] is a coordinate\n",
    "#     # gotta loop through each scene in the batch\n",
    "#     inp, out = sample_batch # inp: (batch size, 50, 2), out: (batch size, 60, 2)\n",
    "#     \"\"\"\n",
    "#     TODO:\n",
    "#       implement your Deep learning model\n",
    "#       implement training routine\n",
    "#     \"\"\"\n",
    "#     show_sample_batch(sample_batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1e6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e554722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def train(net, n_epochs, train_loader, loss_fct, criterion, device, val_loader=None, valid=False):\n",
    "    train_l= []\n",
    "    val_l = []\n",
    "    for epoch in range(n_epochs):\n",
    "        ## training loop\n",
    "        for i_batch, batch in enumerate(train_loader):\n",
    "            # inp[i] is a scene with 50 coordinates, input[i, j] is a coordinate\n",
    "            inp, out = batch\n",
    "            inp = inp.float().to(device)\n",
    "            out = out.float().to(device)\n",
    "            \n",
    "            # 0 pad the end of input seq\n",
    "            #inp = torch.cat((inp, torch.zeros(inp.size(0), 10, inp.size(2), device=device)), dim=1)\n",
    "            pred = net(inp)#.to(device)\n",
    "            # print('input: {}'.format(inp[0, :3]))\n",
    "            # print('preds: {}'.format(pred[0, :3]))\n",
    "            # print('true: {}'.format(out[0, :3]))\n",
    "            \n",
    "            loss = loss_fct(pred, out)\n",
    "\n",
    "            criterion.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            criterion.step()\n",
    "            \n",
    "        train_l.append(loss.item())\n",
    "        \n",
    "        if valid:\n",
    "            for i_batch, batch in enumerate(val_loader):\n",
    "                with torch.no_grad():\n",
    "                    inp, out = batch\n",
    "                    inp = inp.float().to(device)\n",
    "                    out = out.float().to(device)\n",
    "\n",
    "                    inp = torch.cat((inp, torch.zeros(inp.size(0), 10, inp.size(2), device=device)), dim=1)\n",
    "                    pred = net(inp).to(device)\n",
    "\n",
    "                    val_loss = loss_fct(pred, out)\n",
    "        if valid:\n",
    "            val_l.append(val_loss.item())\n",
    "            \n",
    "            print('epoch: {}, training loss: {}, validation loss: {}'.format(epoch + 1, loss, val_loss))\n",
    "        else:\n",
    "            print('epoch: {}, training loss: {}'.format(epoch + 1, loss))\n",
    "        \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    sns.lineplot(ax=ax[0], x=np.arange(0, len(train_l)), y=train_l)\n",
    "    if valid:\n",
    "        sns.lineplot(ax=ax[1], x=np.arange(0, len(val_l)), y=val_l)\n",
    "    print('-'* 70)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79c99cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe4eb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from d2l.ai\n",
    "def grad_clipping(net, theta):\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "\n",
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, device, num_layers=1, dropout=0, bidirectional=False):\n",
    "#         super(RNN, self).__init__()\n",
    "#         self.device = device\n",
    "#         self.embed = nn.Embedding(input_size, hidden_size)\n",
    "#         self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "#         if bidirectional:\n",
    "#             self.fc = nn.Linear(2 * hidden_size, output_size)\n",
    "#         else:\n",
    "#             self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.to(self.device)\n",
    "        \n",
    "#         x = F.layer_norm(x, x.size())\n",
    "        \n",
    "#         x = self.embed(x)\n",
    "        \n",
    "#         out, _ = self.rnn(x)\n",
    "        \n",
    "#         out = self.fc(out)\n",
    "\n",
    "#         return out\n",
    "\n",
    "##\n",
    "\n",
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size,device, num_layers, dropout=0, bidirectional=False):\n",
    "#         super(RNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.device = device\n",
    "    \n",
    "\n",
    "#         self.embed = nn.Embedding(input_size, hidden_size)\n",
    "#         self.lstm = nn.LSTM(hidden_size,hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#     def forward(self, x, hidden, cell):\n",
    "#         x = x.to(self.device)\n",
    "        \n",
    "#         out = self.embed(x.type_as(long))\n",
    "     \n",
    "#         out, (hidden, cell) = self.lstm(x.unsqueeze(1), (hidden, cell))\n",
    "#         out = self.fc(out.reshape(out.shape[0], -1))\n",
    "#         return out, (hidden, cell)\n",
    "\n",
    "#     def init_hidden(self, batch_size):\n",
    "#         hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "#         cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "#         return hidden, cell\n",
    "\n",
    "# import seaborn as sns\n",
    "# def train(net, n_epochs, train_loader, loss_fct, criterion, device, val_loader=None, valid=False):\n",
    "#     train_l= []\n",
    "#     val_l = []\n",
    "#     for epoch in range(n_epochs):\n",
    "# #         ## training loop\n",
    "#         for i_batch, batch in enumerate(train_loader):\n",
    "        \n",
    "#             hidden, cell = net.init_hidden(64)\n",
    "# #             hidden, cell = net.init_hidden(64)\n",
    "# #             # inp[i] is a scene with 50 coordinates, input[i, j] is a coordinate\n",
    "#             x, y = batch\n",
    "#             x = x.float().to(device)\n",
    "#             y = y.float().to(device)\n",
    "            \n",
    "            \n",
    "#             #         #x, y = randomBatch(text, batch_size, 2)\n",
    "# #         x = x.to(device)\n",
    "# #         y = y.to(device)\n",
    "        \n",
    "#             loss = 0\n",
    "#             net.zero_grad()\n",
    "\n",
    "#             for char in range(2):\n",
    "#                 output, (hidden, cell) = net(x[:, char], hidden, cell)\n",
    "#                 loss += criterion(output, y[:, char])\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             loss = loss.item() / sequence_len\n",
    "# #             print(inp.Shape())\n",
    "# #             # 0 pad the end of input seq\n",
    "# #            # inp = torch.cat((inp, torch.zeros(inp.size(0), 10, inp.size(2), device=device)), dim=1)\n",
    "# #             #print(inp)\n",
    "# #             pred, (hidden, cell) = net(inp, hidden, cell)#.to(device)\n",
    "# #             # print('input: {}'.format(inp[0, :3]))\n",
    "# #             # print('preds: {}'.format(pred[0, :3]))\n",
    "# #             # print('true: {}'.format(out[0, :3]))\n",
    "            \n",
    "# #             loss = loss_fct(pred, out)\n",
    "\n",
    "# #             criterion.zero_grad()\n",
    "# #             loss.backward()\n",
    "# #             grad_clipping(net, 1)\n",
    "# #             criterion.step()\n",
    "#     #rnn = RNN(2, 256, device,2, 2).to(device)\n",
    "\n",
    "# #     optimizer = torch.optim.Adam(net.parameters(), lr)\n",
    "# #     criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "# #     training_size = 0\n",
    "\n",
    "# #     for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "# #         hidden, cell = net.init_hidden(batch_size)\n",
    "        \n",
    "# #         #x, y = randomBatch(text, batch_size, 2)\n",
    "# #         x = x.to(device)\n",
    "# #         y = y.to(device)\n",
    "        \n",
    "# #         loss = 0\n",
    "# #         rnn.zero_grad()\n",
    "        \n",
    "# #         for char in range(sequence_len):\n",
    "# #             output, (hidden, cell) = net(x[:, char], hidden, cell)\n",
    "# #             loss += criterion(output, y[:, char])\n",
    "\n",
    "# #         loss.backward()\n",
    "# #         optimizer.step()\n",
    "# #         loss = loss.item() / sequence_len\n",
    "# #         print(loss)\n",
    "            \n",
    "# #         train_l.append(loss.item())\n",
    "        \n",
    "# # #         if valid:\n",
    "# # #             for i_batch, batch in enumerate(val_loader):\n",
    "# # #                 with torch.no_grad():\n",
    "# # #                     inp, out = batch\n",
    "# # #                     inp = inp.float().to(device)\n",
    "# # #                     out = out.float().to(device)\n",
    "\n",
    "# # #                     inp = torch.cat((inp, torch.zeros(inp.size(0), 10, inp.size(2), device=device)), dim=1)\n",
    "                    \n",
    "                    \n",
    "# # #                     pred = net(inp).to(device)\n",
    "\n",
    "# # #                     val_loss = loss_fct(pred, out)\n",
    "# # #         if valid:\n",
    "# # #             val_l.append(val_loss.item())\n",
    "            \n",
    "# # #             print('epoch: {}, training loss: {}, validation loss: {}'.format(epoch + 1, loss, val_loss))\n",
    "# # #         else:\n",
    "# # #             print('epoch: {}, training loss: {}'.format(epoch + 1, loss))\n",
    "        \n",
    "    \n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
    "#     sns.lineplot(ax=ax[0], x=np.arange(0, len(train_l)), y=train_l)\n",
    "#     if valid:\n",
    "#         sns.lineplot(ax=ax[1], x=np.arange(0, len(val_l)), y=val_l)\n",
    "#     print('-'* 70)\n",
    "#     return\n",
    "\n",
    "\n",
    "# import seaborn as sns\n",
    "# def train(net, n_epochs, data_loader, criterion, loss_fct, device):\n",
    "#     l = []\n",
    "#     for epoch in range(n_epochs):\n",
    "#         for i_batch, batch in enumerate(data_loader):\n",
    "#             # inp[i] is a scene with 50 coordinates, input[i, j] is a coordinate\n",
    "#             inp, out = batch\n",
    "#             inp = inp.float().to(device)\n",
    "#             out = out.float().to(device)\n",
    "            \n",
    "#             # 0 pad the end of input seq\n",
    "#             inp = torch.cat((inp, torch.zeros(inp.size(0), 10, inp.size(2), device=device)), dim=1)\n",
    "#             pred = net(inp).to(device)\n",
    "#             # print('input: {}'.format(inp[0, :3]))\n",
    "#             # print('preds: {}'.format(pred[0, :3]))\n",
    "#             # print('true: {}'.format(out[0, :3]))\n",
    "\n",
    "#             loss = loss_fct(pred, out)\n",
    "\n",
    "#             criterion.zero_grad()\n",
    "#             loss.backward()\n",
    "#             grad_clipping(net, 1)\n",
    "#             criterion.step()\n",
    "        \n",
    "        \n",
    "#         l.append(loss.item())\n",
    "#         print('epoch: {}, loss: {}'.format(epoch + 1, loss))\n",
    "    \n",
    "#     sns.lineplot(x=np.arange(0, len(l)), y=l)\n",
    "#     print('---------------------------------------')\n",
    "#     return\n",
    "\n",
    "# def predict(net, data_loader, device):\n",
    "#     with torch.no_grad():\n",
    "#         for i_batch, batch in enumerate(data_loader):\n",
    "#             inp, _ = batch\n",
    "#             inp = torch.cat((inp.float().to(device), torch.zeros(inp.size(0), 10, inp.size(2)).to(device)), dim=1)\n",
    "                        \n",
    "#             preds = net(inp.float().to(device))\n",
    "            \n",
    "#             return preds\n",
    "        \n",
    "def write_city_preds(net, test_loader, device, city, fp):       \n",
    "    scene = 0\n",
    "    output = ''\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i_batch, batch in enumerate(test_loader):\n",
    "            inp = batch\n",
    "            inp = inp.float().to(device)\n",
    "            inp = torch.cat((inp, torch.zeros(inp.size(0), 10, inp.size(2), device=device)), dim=1)\n",
    "\n",
    "            preds = net(inp)\n",
    "            flat = preds[0].flatten().cpu().tolist()\n",
    "            \n",
    "            row = ['{}_{}'.format(scene, city)] + flat\n",
    "            row = [str(i) for i in row]\n",
    "            output += ','.join(row) + '\\n'\n",
    "            \n",
    "            scene += 1\n",
    "    \n",
    "    try:\n",
    "        with open('./submission.csv', 'a') as f:\n",
    "            f.write(output)\n",
    "        print('Predictions for {} generated!'.format(city))\n",
    "        return 1\n",
    "    except:\n",
    "        print('Error! Unsuccessful write...')\n",
    "        return -1\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2222c",
   "metadata": {},
   "source": [
    "## These models were trained with SGD as the opto and it wasn't very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "582919b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNN(2, 256, 2).to(device)\n",
    "# opto = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# loss_fct = nn.MSELoss()\n",
    "# train(model, 100, train_loader, opto, loss_fct, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a200af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNN(2, 128, 2).to(device)\n",
    "# opto = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# loss_fct = nn.MSELoss()\n",
    "# train(model, 100, train_loader, opto, loss_fct, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea3aa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNN(2, 128, 2).to(device)\n",
    "# opto = torch.optim.SGD(model.parameters(), lr=.1)\n",
    "# loss_fct = nn.MSELoss()\n",
    "# train(model, 100, train_loader, opto, loss_fct, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f7c35",
   "metadata": {},
   "source": [
    "## Started using Adam optimizer / lstm with dropout, these next 2 models are usable, adding l2 loss didnt converge, currently using the second one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ceae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNN(input_size=2, hidden_size=128, output_size=2, num_layers=2, dropout=.2).to(device)\n",
    "# opto = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "# loss_fct = nn.MSELoss()\n",
    "\n",
    "# train(model, 100, train_loader, opto, loss_fct, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d4aad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNN(input_size=2, hidden_size=256, output_size=2, num_layers=2, dropout=.2).to(device)\n",
    "# opto = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "# loss_fct = nn.MSELoss()\n",
    "\n",
    "# train(model, 100, train_loader, opto, loss_fct, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183cd4f",
   "metadata": {},
   "source": [
    "## Bidirectional doesn't make sense here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6cf9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNN(2, 256, 2, .2, True).to(device)\n",
    "# opto = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=.01)\n",
    "# loss_fct = nn.MSELoss()\n",
    "\n",
    "# train(model, 100, train_loader, opto, loss_fct, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a9ca7",
   "metadata": {},
   "source": [
    "# Test Dataset and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1678689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(fp, model, opto, loss_fct, device, valid=False):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"] \n",
    "    header = ['ID'] + ['v' + str(i) for i in range(0, 120)]\n",
    "    \n",
    "    with open(fp, 'w') as f:\n",
    "        f.write(','.join(header) + '\\n')\n",
    "\n",
    "    for city in cities:\n",
    "        batch_sz = 64\n",
    "        if valid:\n",
    "            i, v_i, o, v_o = get_city_trajectories(city=city, split=\"train\", valid=valid)\n",
    "            training_data = ValidationDataset(i, o)\n",
    "            validation_data = ValidationDataset(v_i, v_o)\n",
    "            train_loader = DataLoader(training_data, batch_size=batch_sz)\n",
    "            val_loader = DataLoader(validation_data, batch_size=batch_sz)\n",
    "        else:\n",
    "            val_loader = None\n",
    "            training_data = ArgoverseDataset(city=city, split='train')\n",
    "            train_loader = DataLoader(training_data, batch_size=batch_sz)\n",
    "        \n",
    "        train(model, 150, train_loader, loss_fct, opto, device, val_loader, valid)\n",
    "        \n",
    "        if not valid:\n",
    "            test_dataset  = ArgoverseDataset(city=city, split='test')\n",
    "            test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "            write_city_preds(model, test_loader, device, city, fp)\n",
    "\n",
    "    print(fp + ' generated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362cf69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, training loss: 1673.455078125\n",
      "epoch: 2, training loss: 1165.489013671875\n",
      "epoch: 3, training loss: 1115.4549560546875\n",
      "epoch: 4, training loss: 1165.020263671875\n",
      "epoch: 5, training loss: 1196.318115234375\n",
      "epoch: 6, training loss: 878.028076171875\n",
      "epoch: 7, training loss: 923.989013671875\n",
      "epoch: 8, training loss: 860.23974609375\n",
      "epoch: 9, training loss: 1107.8411865234375\n",
      "epoch: 10, training loss: 889.606201171875\n",
      "epoch: 11, training loss: 883.16064453125\n",
      "epoch: 12, training loss: 995.8150634765625\n",
      "epoch: 13, training loss: 1051.608642578125\n",
      "epoch: 14, training loss: 687.5641479492188\n",
      "epoch: 15, training loss: 576.2777709960938\n",
      "epoch: 16, training loss: 583.641845703125\n",
      "epoch: 17, training loss: 594.9974365234375\n",
      "epoch: 18, training loss: 677.5007934570312\n",
      "epoch: 19, training loss: 556.3046264648438\n",
      "epoch: 20, training loss: 600.3590087890625\n",
      "epoch: 21, training loss: 470.5979919433594\n",
      "epoch: 22, training loss: 445.346435546875\n",
      "epoch: 23, training loss: 445.04998779296875\n",
      "epoch: 24, training loss: 400.50921630859375\n",
      "epoch: 25, training loss: 416.8505859375\n",
      "epoch: 26, training loss: 568.0686645507812\n",
      "epoch: 27, training loss: 476.0810852050781\n",
      "epoch: 28, training loss: 360.80682373046875\n",
      "epoch: 29, training loss: 389.474609375\n",
      "epoch: 30, training loss: 300.7482604980469\n",
      "epoch: 31, training loss: 413.8830261230469\n",
      "epoch: 32, training loss: 296.3468017578125\n",
      "epoch: 33, training loss: 411.4813537597656\n",
      "epoch: 34, training loss: 261.81231689453125\n",
      "epoch: 35, training loss: 236.5152587890625\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RNN().to(device)\n",
    "opto = torch.optim.Adam(model.parameters(), lr=.0001)\n",
    "loss_fct = nn.MSELoss()\n",
    "\n",
    "generate_submission('./submission.csv', model, opto, loss_fct, device, valid=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
