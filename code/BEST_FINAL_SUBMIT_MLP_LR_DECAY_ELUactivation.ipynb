{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "718c38cf",
      "metadata": {
        "id": "718c38cf"
      },
      "source": [
        "## Install the package dependencies before running this notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/CSE151B1\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifzlyqLx88WP",
        "outputId": "bfb3c1f9-b1f4-4dd3-b028-20e9c6b573ae"
      },
      "id": "ifzlyqLx88WP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/CSE151B1\n",
            "BEST-MLP_Transform_Decay.ipynb\tLSTM.ipynb\t\t     submission1.csv\n",
            "EDA-3.ipynb\t\t\tMLP.ipynb\t\t     submission72.csv\n",
            "EDA-4.ipynb\t\t\tMLP_LRDecay_MILESTONE.ipynb  submission.csv\n",
            "EDA-5.ipynb\t\t\tMLP_LReLU23.ipynb\t     test\n",
            "Load_Argo2_Public.ipynb\t\tMLP_LReLU.ipynb\t\t     train\n",
            "LR_PYTORCH.ipynb\t\tMLP_Transform.ipynb\n",
            "LR_SKLEARN.ipynb\t\tsample_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pickle5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P1toKi09UOT",
        "outputId": "dd29cbf6-1c17-4af7-bfc3-d026e392d8d0"
      },
      "id": "4P1toKi09UOT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ac7530",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "16ac7530",
        "outputId": "1a1f507b-0b9a-4a7c-949d-28470f7e957d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os, os.path \n",
        "import numpy \n",
        "import pickle \n",
        "from glob import glob\n",
        "import math\n",
        "\n",
        "\"\"\"\n",
        "    number of trajectories in each city\n",
        "    # austin --  train: 43041 test: 6325 \n",
        "    # miami -- train: 55029 test:7971\n",
        "    # pittsburgh -- train: 43544 test: 6361\n",
        "    # dearborn -- train: 24465 test: 3671\n",
        "    # washington-dc -- train: 25744 test: 3829\n",
        "    # palo-alto -- train:  11993 test:1686\n",
        "\n",
        "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
        "    \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b472cf2",
      "metadata": {
        "id": "0b472cf2"
      },
      "source": [
        "## Create a Torch.Dataset class for the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091abbb7",
      "metadata": {
        "id": "091abbb7"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import pickle5 as pickle\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "ROOT_PATH = \"./\"\n",
        "\n",
        "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
        "splits = [\"train\", \"test\"]\n",
        "\n",
        "def get_city_trajectories(city=\"palo-alto\", split=\"train\", valid=False, normalized=False):\n",
        "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
        "    inputs = pickle.load(open(f_in, \"rb\"))\n",
        "    inputs = np.asarray(inputs)\n",
        "    \n",
        "    \n",
        "    if split==\"train\":\n",
        "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
        "        outputs = pickle.load(open(f_out, \"rb\"))\n",
        "        outputs = np.asarray(outputs)\n",
        "        \n",
        "        inps = []#np.array([])\n",
        "        out =  []#np.array([])\n",
        "        for i in range(inputs.shape[0]):\n",
        "            inp = np.concatenate([(inputs[i, :, 0] - inputs[i, 0, 0]).reshape(50, 1),\n",
        "                                  (inputs[i, :, 1] - inputs[i, 0, 1]).reshape(50, 1)], axis=1)\n",
        "            o = np.concatenate([(outputs[i, :, 0] - inputs[i, 0, 0]).reshape(60, 1),\n",
        "                                (outputs[i, :, 1] - inputs[i, 0, 1]).reshape(60, 1)], axis=1)\n",
        "            inps.append(inp)#np.append(inps,inp)\n",
        "            out.append(o)#np.append(out,o)\n",
        "            #inps = np.vstack((inps,inp))\n",
        "            #out = np.vstack((out,o))\n",
        "        \n",
        "        inps = np.array(inps)\n",
        "        out = np.array(out)\n",
        "             \n",
        "        if valid:\n",
        "            idx = int(len(inputs) * .8)\n",
        "            return inps[:idx], inps[idx:], out[:idx], out[idx:]\n",
        "        else:\n",
        "            return inps, out\n",
        "#   else: \n",
        "#         inps = []#np.array([])\n",
        "#         for i in range(inputs.shape[0]):\n",
        "#             inp = np.concatenate([(inputs[i, :, 0] - inputs[i, 0, 0]).reshape(50, 1), (inputs[i, :, 1] - inputs[i, 0, 1]).reshape(50, 1)], axis=1)\n",
        "#             inps.append(inp)\n",
        "#         inps = np.array(inps)\n",
        "\n",
        "    return inputs, None\n",
        "\n",
        "class ArgoverseDataset(Dataset):\n",
        "    \"\"\"Dataset class for Argoverse\"\"\"\n",
        "    def __init__(self, city: str, split:str, transform=None):\n",
        "        super(ArgoverseDataset, self).__init__()\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        if self.split == 'train':\n",
        "            data = (self.inputs[idx], self.outputs[idx])\n",
        "        else:\n",
        "            data = (self.inputs[idx])\n",
        "            \n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        return data\n",
        "    \n",
        "class ValidationDataset(Dataset):\n",
        "    \"\"\"Dataset class for Argoverse\"\"\"\n",
        "    def __init__(self, inputs, outputs, transform=None):\n",
        "        super(ValidationDataset, self).__init__()\n",
        "        self.transform = transform\n",
        "        self.inputs, self.outputs = inputs, outputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        data = (self.inputs[idx], self.outputs[idx])\n",
        "            \n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        return data\n",
        "\n",
        "# intialize a dataset\n",
        "city = 'palo-alto' \n",
        "split = 'train'\n",
        "train_dataset  = ArgoverseDataset(city = city, split = split)\n",
        "\n",
        "##get_city_trajectories()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "058453cc",
      "metadata": {
        "id": "058453cc"
      },
      "source": [
        "## Create a DataLoader class for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c14f0e7",
      "metadata": {
        "id": "5c14f0e7"
      },
      "outputs": [],
      "source": [
        "batch_sz = 32  # batch size \n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_sz)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f80b5e4",
      "metadata": {
        "id": "6f80b5e4"
      },
      "source": [
        "## Sample a batch of data and visualize "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6507c9a",
      "metadata": {
        "id": "c6507c9a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# import random\n",
        "\n",
        "# def show_sample_batch(sample_batch):\n",
        "#     \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
        "#     inp, out = sample_batch\n",
        "#     batch_sz = inp.size(0)\n",
        "#     agent_sz = inp.size(1)\n",
        "    \n",
        "#     fig, axs = plt.subplots(1, batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
        "#     fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "#     axs = axs.ravel()   \n",
        "#     for i in range(batch_sz):\n",
        "#         axs[i].xaxis.set_ticks([])\n",
        "#         axs[i].yaxis.set_ticks([])\n",
        "        \n",
        "        # first two feature dimensions are (x,y) positions\n",
        "#         axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
        "#         axs[i].scatter(out[i,:,0], out[i,:,1])\n",
        "\n",
        "        \n",
        "# for i_batch, sample_batch in enumerate(train_loader):\n",
        "#     # inp[i] is a scene with 50 coordinates, input[i, j] is a coordinate\n",
        "#     # gotta loop through each scene in the batch\n",
        "#     inp, out = sample_batch # inp: (batch size, 50, 2), out: (batch size, 60, 2)\n",
        "#     \"\"\"\n",
        "#     TODO:\n",
        "#       implement your Deep learning model\n",
        "#       implement training routine\n",
        "#     \"\"\"\n",
        "#     show_sample_batch(sample_batch)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4eb74d",
      "metadata": {
        "id": "fe4eb74d"
      },
      "outputs": [],
      "source": [
        "# from d2l.ai\n",
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    if isinstance(net, nn.Module):\n",
        "        params = [p for p in net.parameters() if p.requires_grad]\n",
        "    else:\n",
        "        params = net.params\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers, device, dropout=0):\n",
        "        super(RNN, self).__init__()\n",
        "        self.device = device\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=input_size, \n",
        "            hidden_size=hidden_size, \n",
        "            num_layers=n_layers, \n",
        "            dropout=dropout, \n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "#         self.rnn.flatten_parameters()\n",
        "                        \n",
        "        out, (hn, cn) = self.rnn(x)\n",
        "        \n",
        "        print(out)\n",
        "        \n",
        "        o = hn[-1]\n",
        "        \n",
        "        print(self.fc(o))\n",
        "        print(self.fc(o).size())\n",
        "\n",
        "                        \n",
        "        return self.fc(out)\n",
        "    \n",
        "    \n",
        "import seaborn as sns\n",
        "def train(net, n_epochs, train_loader, loss_fct, criterion, device, val_loader=None, valid=False):\n",
        "    train_l= []\n",
        "    val_l = []    \n",
        "    for epoch in range(n_epochs):\n",
        "        ## training loop\n",
        "        for i_batch, batch in enumerate(train_loader):\n",
        "            # inp[i] is a scene with 50 coordinates, input[i, j] is a coordinate\n",
        "            inp, out = batch\n",
        "            inp = inp.float().to(device)\n",
        "            out = out.float().to(device)\n",
        "            \n",
        "            pred = net(inp).to(device)\n",
        "            # print('input: {}'.format(inp[0, :3]))\n",
        "            # print('preds: {}'.format(pred[0, :3]))\n",
        "            # print('true: {}'.format(out[0, :3]))\n",
        "            \n",
        "            loss = loss_fct(pred, out)\n",
        "\n",
        "            criterion.zero_grad()\n",
        "            loss.backward()\n",
        "            grad_clipping(net, 1)\n",
        "            criterion.step()\n",
        "            \n",
        "        train_l.append(loss.item())\n",
        "        \n",
        "        if valid:\n",
        "            for i_batch, batch in enumerate(val_loader):\n",
        "                with torch.no_grad():\n",
        "                    inp, out = batch\n",
        "                    inp = inp.float().to(device)\n",
        "                    out = out.float().to(device)\n",
        "\n",
        "                    pred = net(inp).to(device)\n",
        "\n",
        "                    val_loss = loss_fct(pred, out)\n",
        "        if valid:\n",
        "            val_l.append(val_loss.item())\n",
        "            \n",
        "            print('epoch: {}, training loss: {}, validation loss: {}'.format(epoch + 1, loss, val_loss))\n",
        "        else:\n",
        "            print('epoch: {}, training loss: {}'.format(epoch + 1, loss))\n",
        "        \n",
        "    \n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    sns.lineplot(ax=ax[0], x=np.arange(0, len(train_l)), y=train_l)\n",
        "    if valid:\n",
        "        sns.lineplot(ax=ax[1], x=np.arange(0, len(val_l)), y=val_l)\n",
        "    print('-'* 70)\n",
        "    return\n",
        "\n",
        "    \n",
        "def write_city_preds(net, test_loader, device, city, fp):       \n",
        "    scene = 0\n",
        "    output = ''\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i_batch, batch in enumerate(test_loader):\n",
        "            inp = batch\n",
        "            inp = inp.float().to(device)\n",
        "\n",
        "            first = inp[:, 0:1, :].clone().detach()\n",
        "\n",
        "            inp = inp - first\n",
        "            \n",
        "            preds = net(inp).to(device)\n",
        "            preds = preds + first\n",
        "            \n",
        "            flat = preds[0].flatten().cpu().tolist()\n",
        "            \n",
        "            row = ['{}_{}'.format(scene, city)] + flat\n",
        "            row = [str(i) for i in row]\n",
        "            output += ','.join(row) + '\\n'\n",
        "            \n",
        "            scene += 1\n",
        "    \n",
        "    try:\n",
        "        with open('./submission.csv', 'a') as f:\n",
        "            f.write(output)\n",
        "        print('Predictions for {} generated!'.format(city))\n",
        "        return 1\n",
        "    except:\n",
        "        print('Error! Unsuccessful write...')\n",
        "        return -1\n",
        "            \n",
        "            \n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a2222c",
      "metadata": {
        "id": "a8a2222c"
      },
      "source": [
        "## These models were trained with SGD as the opto and it wasn't very good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "582919b7",
      "metadata": {
        "id": "582919b7"
      },
      "outputs": [],
      "source": [
        "# model = RNN(2, 256, 2).to(device)\n",
        "# opto = torch.optim.SGD(model.parameters(), lr=1)\n",
        "# loss_fct = nn.MSELoss()\n",
        "# train(model, 100, train_loader, opto, loss_fct, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a200af0",
      "metadata": {
        "id": "8a200af0"
      },
      "outputs": [],
      "source": [
        "# model = RNN(2, 128, 2).to(device) \n",
        "# opto = torch.optim.SGD(model.parameters(), lr=1)\n",
        "# loss_fct = nn.MSELoss()\n",
        "# train(model, 100, train_loader, opto, loss_fct, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3aa6fd",
      "metadata": {
        "id": "ea3aa6fd"
      },
      "outputs": [],
      "source": [
        "# model = RNN(2, 128, 2).to(device)\n",
        "# opto = torch.optim.SGD(model.parameters(), lr=.1)\n",
        "# loss_fct = nn.MSELoss()\n",
        "# train(model, 100, train_loader, opto, loss_fct, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c4f7c35",
      "metadata": {
        "id": "5c4f7c35"
      },
      "source": [
        "## Started using Adam optimizer / lstm with dropout, these next 2 models are usable, adding l2 loss didnt converge, currently using the second one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ceae11",
      "metadata": {
        "id": "04ceae11"
      },
      "outputs": [],
      "source": [
        "# model = RNN(input_size=2, hidden_size=128, output_size=2, num_layers=2, dropout=.2).to(device)\n",
        "# opto = torch.optim.Adam(model.parameters(), lr=.001)\n",
        "# loss_fct = nn.MSELoss()\n",
        "\n",
        "# train(model, 100, train_loader, opto, loss_fct, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4aad68",
      "metadata": {
        "id": "6d4aad68"
      },
      "outputs": [],
      "source": [
        "# model = RNN(input_size=2, hidden_size=256, output_size=2, num_layers=2, dropout=.2).to(device)\n",
        "# opto = torch.optim.Adam(model.parameters(), lr=.001)\n",
        "# loss_fct = nn.MSELoss()\n",
        "\n",
        "# train(model, 100, train_loader, opto, loss_fct, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e183cd4f",
      "metadata": {
        "id": "e183cd4f"
      },
      "source": [
        "## Bidirectional doesn't make sense here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6cf9018",
      "metadata": {
        "id": "b6cf9018"
      },
      "outputs": [],
      "source": [
        "# model = RNN(2, 256, 2, .2, True).to(device)\n",
        "# opto = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=.01)\n",
        "# loss_fct = nn.MSELoss()\n",
        "\n",
        "# train(model, 100, train_loader, opto, loss_fct, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c6a9ca7",
      "metadata": {
        "id": "5c6a9ca7"
      },
      "source": [
        "# Test Dataset and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1678689",
      "metadata": {
        "id": "c1678689"
      },
      "outputs": [],
      "source": [
        "def generate_submission(fp, model, n_epochs, batch_sz, opto, scheduler, loss_fct, device, valid=False):\n",
        "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"] \n",
        "    header = ['ID'] + ['v' + str(i) for i in range(0, 120)]\n",
        "    \n",
        "    with open(fp, 'w') as f:\n",
        "        f.write(','.join(header) + '\\n')\n",
        "\n",
        "    for city in cities:\n",
        "        if valid:\n",
        "            i, v_i, o, v_o = get_city_trajectories(city=city, split=\"train\", valid=valid)\n",
        "            training_data = ValidationDataset(i, o)\n",
        "            validation_data = ValidationDataset(v_i, v_o)\n",
        "            train_loader = DataLoader(training_data, batch_size=batch_sz)\n",
        "            val_loader = DataLoader(validation_data, batch_size=batch_sz)\n",
        "        else:\n",
        "            val_loader = None\n",
        "            training_data = ArgoverseDataset(city=city, split='train')\n",
        "            train_loader = DataLoader(training_data, batch_size=batch_sz)\n",
        "        \n",
        "#         train(model, n_epochs, train_loader, loss_fct, opto, device, val_loader, valid)\n",
        "        train_mlp(model, n_epochs, train_loader, loss_fct, opto, scheduler, device, city, val_loader, valid)\n",
        "        \n",
        "        #if not valid:\n",
        "        test_dataset  = ArgoverseDataset(city=city, split='test')\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "\n",
        "        write_city_preds(model, test_loader, device, city, fp)\n",
        "\n",
        "        print(\"\\nDone printing \" + str(city) + \" predictions\")\n",
        "        print('-'* 70)\n",
        "        \n",
        "    print(fp + ' generated!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417c1efd",
      "metadata": {
        "id": "417c1efd"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, device):\n",
        "        super(MLP, self).__init__()\n",
        "        self.device = device\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(100, 1024, device=device),\n",
        "            nn.ELU(),#nn.LeakyReLU(negative_slope = 0.75, inplace = False),\n",
        "            nn.Linear(1024, 512, device=device),\n",
        "            nn.ELU(),#nn.LeakyReLU(negative_slope = 0.75, inplace = False),\n",
        "            nn.Linear(512, 512, device=device)\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(512, 1024, device=device),\n",
        "            nn.ELU(),#nn.LeakyReLU(negative_slope = 0.75, inplace = False),\n",
        "            nn.Linear(1024, 120, device=device),\n",
        "            nn.ELU(),#nn.LeakyReLU(negative_slope = 0.75, inplace = False),\n",
        "            nn.Linear(120, 120, device=device)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "        x = x.reshape(-1, x.size(1) * x.size(2)).float()\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        #x = self.fc(x)\n",
        "        x = x.reshape(-1, 60, 2) \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c22622e",
      "metadata": {
        "id": "3c22622e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class MLP(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, output_size, device):\n",
        "#         super(MLP, self).__init__()\n",
        "#         self.device = device\n",
        "        \n",
        "#         self.encoder = nn.Sequential(\n",
        "#             nn.Linear(100, 64, device=device),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(64, 32, device=device),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(32, 32, device=device)\n",
        "#         )\n",
        "        \n",
        "#         self.decoder = nn.Sequential(\n",
        "#             nn.Linear(32, 64, device=device),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(64, 120, device=device),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(120, 120, device=device)\n",
        "#         )\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         x = x.to(self.device)\n",
        "#         x = x.reshape(-1, x.size(1) * x.size(2)).float()\n",
        "#         x = self.encoder(x)\n",
        "#         x = self.decoder(x)\n",
        "#         #x = self.fc(x)\n",
        "#         x = x.reshape(-1, 60, 2) \n",
        "#         return x#\n",
        "\n",
        "\n",
        "def train_mlp(net, n_epochs, train_loader, loss_fct, criterion, scheduler, device, city, val_loader=None, valid=False):\n",
        "    train_l= []\n",
        "    val_l = []\n",
        "    for epoch in range(n_epochs):\n",
        "        ## training loop\n",
        "       # h, c = net.init_hidden(64)\n",
        "        for i_batch, batch in enumerate(train_loader):\n",
        "            inp, out = batch\n",
        "            inp = inp.float().to(device)\n",
        "            out = out.float().to(device)\n",
        "            \n",
        "            pred = net(inp).to(device)\n",
        "            \n",
        "            loss = loss_fct(pred, out)\n",
        "\n",
        "            criterion.zero_grad()\n",
        "            loss.backward()\n",
        "#             grad_clipping(net, 3)\n",
        "            criterion.step()\n",
        "        \n",
        "        train_l.append(loss.item())\n",
        "        \n",
        "        if valid:    \n",
        "            for i_batch, batch in enumerate(val_loader):\n",
        "                with torch.no_grad():\n",
        "                    inp, out = batch\n",
        "                    inp = inp.float().to(device)\n",
        "                    out = out.float().to(device)\n",
        "                    \n",
        "\n",
        "                    pred = net(inp).to(device)\n",
        "                    \n",
        "\n",
        "                    val_loss = loss_fct(pred, out)\n",
        "        if valid:\n",
        "            val_l.append(val_loss.item())\n",
        "            \n",
        "            print('epoch: {}, training loss: {}, validation loss: {}'.format(epoch + 1, loss, val_loss))\n",
        "        else:\n",
        "            print('epoch: {}, training loss: {}'.format(epoch + 1, loss))\n",
        "        \n",
        "        scheduler.step()\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    sns.lineplot(ax=ax[0], x=np.arange(0, len(train_l)), y=train_l).set_title(\"Loss (MSE) for \" + str(city))\n",
        "    \n",
        "    if valid:\n",
        "        sns.lineplot(ax=ax[1], x=np.arange(0, len(val_l)), y=val_l).set_title(\"Loss (MSE) for \" + str(city))\n",
        "        \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca970636",
      "metadata": {
        "id": "ca970636"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e61f04",
      "metadata": {
        "id": "84e61f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c6d5e8f-d36c-4120-bc6c-c08d278fa34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, training loss: 69.76390075683594, validation loss: 72.71741485595703\n",
            "epoch: 2, training loss: 47.84113311767578, validation loss: 55.2185173034668\n",
            "epoch: 3, training loss: 43.08750534057617, validation loss: 48.33403778076172\n",
            "epoch: 4, training loss: 38.55887985229492, validation loss: 41.59785842895508\n",
            "epoch: 5, training loss: 35.3662223815918, validation loss: 35.78249740600586\n",
            "epoch: 6, training loss: 32.86486053466797, validation loss: 32.82795715332031\n",
            "epoch: 7, training loss: 31.59760856628418, validation loss: 31.30337142944336\n",
            "epoch: 8, training loss: 30.69320297241211, validation loss: 29.33355712890625\n",
            "epoch: 9, training loss: 29.97620964050293, validation loss: 27.562786102294922\n",
            "epoch: 10, training loss: 29.440092086791992, validation loss: 26.24809455871582\n",
            "epoch: 11, training loss: 29.04431915283203, validation loss: 25.258893966674805\n",
            "epoch: 12, training loss: 28.74970817565918, validation loss: 24.359018325805664\n",
            "epoch: 13, training loss: 28.467056274414062, validation loss: 23.628419876098633\n",
            "epoch: 14, training loss: 28.168798446655273, validation loss: 22.961498260498047\n",
            "epoch: 15, training loss: 27.86614227294922, validation loss: 22.42755699157715\n",
            "epoch: 16, training loss: 27.600372314453125, validation loss: 21.910152435302734\n",
            "epoch: 17, training loss: 27.366378784179688, validation loss: 21.445756912231445\n",
            "epoch: 18, training loss: 27.109121322631836, validation loss: 21.086942672729492\n",
            "epoch: 19, training loss: 26.863737106323242, validation loss: 20.756065368652344\n",
            "epoch: 20, training loss: 26.62575912475586, validation loss: 20.425037384033203\n",
            "epoch: 21, training loss: 26.409482955932617, validation loss: 20.111921310424805\n",
            "epoch: 22, training loss: 26.224491119384766, validation loss: 19.832351684570312\n",
            "epoch: 23, training loss: 26.05198860168457, validation loss: 19.57667350769043\n",
            "epoch: 24, training loss: 25.90107536315918, validation loss: 19.327178955078125\n",
            "epoch: 25, training loss: 25.767366409301758, validation loss: 19.060331344604492\n",
            "epoch: 26, training loss: 25.14631462097168, validation loss: 18.282501220703125\n",
            "epoch: 27, training loss: 25.071367263793945, validation loss: 18.045822143554688\n",
            "epoch: 28, training loss: 24.973968505859375, validation loss: 17.803871154785156\n",
            "epoch: 29, training loss: 24.87278175354004, validation loss: 17.56902313232422\n",
            "epoch: 30, training loss: 24.773853302001953, validation loss: 17.340681076049805\n",
            "epoch: 31, training loss: 24.684690475463867, validation loss: 17.142343521118164\n",
            "epoch: 32, training loss: 24.604055404663086, validation loss: 16.938547134399414\n",
            "epoch: 33, training loss: 24.519006729125977, validation loss: 16.73735237121582\n",
            "epoch: 34, training loss: 24.443601608276367, validation loss: 16.546628952026367\n",
            "epoch: 35, training loss: 24.378610610961914, validation loss: 16.3576717376709\n",
            "epoch: 36, training loss: 24.337383270263672, validation loss: 16.172592163085938\n",
            "epoch: 37, training loss: 24.287185668945312, validation loss: 16.002399444580078\n",
            "epoch: 38, training loss: 24.24785804748535, validation loss: 15.83128833770752\n",
            "epoch: 39, training loss: 24.207565307617188, validation loss: 15.671142578125\n",
            "epoch: 40, training loss: 24.186203002929688, validation loss: 15.53026008605957\n",
            "epoch: 41, training loss: 24.17286491394043, validation loss: 15.40659236907959\n",
            "epoch: 42, training loss: 24.157533645629883, validation loss: 15.300396919250488\n",
            "epoch: 43, training loss: 24.132810592651367, validation loss: 15.1737060546875\n",
            "epoch: 44, training loss: 24.119417190551758, validation loss: 15.04793930053711\n",
            "epoch: 45, training loss: 24.10576820373535, validation loss: 14.954384803771973\n",
            "epoch: 46, training loss: 24.082984924316406, validation loss: 14.87106704711914\n",
            "epoch: 47, training loss: 24.0584659576416, validation loss: 14.78644847869873\n",
            "epoch: 48, training loss: 24.042022705078125, validation loss: 14.716838836669922\n",
            "epoch: 49, training loss: 24.030458450317383, validation loss: 14.64810848236084\n",
            "epoch: 50, training loss: 24.001798629760742, validation loss: 14.58178997039795\n",
            "epoch: 51, training loss: 23.522628784179688, validation loss: 13.995482444763184\n",
            "epoch: 52, training loss: 23.545419692993164, validation loss: 13.994025230407715\n",
            "epoch: 53, training loss: 23.56183433532715, validation loss: 13.967004776000977\n",
            "epoch: 54, training loss: 23.565105438232422, validation loss: 13.940140724182129\n",
            "epoch: 55, training loss: 23.559526443481445, validation loss: 13.914667129516602\n",
            "epoch: 56, training loss: 23.53429412841797, validation loss: 13.878877639770508\n",
            "epoch: 57, training loss: 23.515045166015625, validation loss: 13.835049629211426\n",
            "epoch: 58, training loss: 23.490772247314453, validation loss: 13.789591789245605\n",
            "epoch: 59, training loss: 23.46917724609375, validation loss: 13.746984481811523\n",
            "epoch: 60, training loss: 23.43901824951172, validation loss: 13.693150520324707\n",
            "epoch: 61, training loss: 23.394468307495117, validation loss: 13.639039039611816\n",
            "epoch: 62, training loss: 23.358612060546875, validation loss: 13.591706275939941\n",
            "epoch: 63, training loss: 23.338787078857422, validation loss: 13.546666145324707\n",
            "epoch: 64, training loss: 23.314321517944336, validation loss: 13.503021240234375\n",
            "epoch: 65, training loss: 23.278501510620117, validation loss: 13.452024459838867\n",
            "epoch: 66, training loss: 23.245595932006836, validation loss: 13.401809692382812\n",
            "epoch: 67, training loss: 23.20798110961914, validation loss: 13.349308967590332\n",
            "epoch: 68, training loss: 23.17191505432129, validation loss: 13.305273056030273\n",
            "epoch: 69, training loss: 23.1444149017334, validation loss: 13.25979232788086\n",
            "epoch: 70, training loss: 23.115758895874023, validation loss: 13.218586921691895\n",
            "epoch: 71, training loss: 23.08121109008789, validation loss: 13.181172370910645\n",
            "epoch: 72, training loss: 23.03075408935547, validation loss: 13.137078285217285\n",
            "epoch: 73, training loss: 22.990726470947266, validation loss: 13.0927152633667\n",
            "epoch: 74, training loss: 22.952524185180664, validation loss: 13.040122985839844\n",
            "epoch: 75, training loss: 22.920562744140625, validation loss: 12.99199104309082\n",
            "epoch: 76, training loss: 22.543066024780273, validation loss: 12.865006446838379\n",
            "epoch: 77, training loss: 22.53426742553711, validation loss: 12.825918197631836\n",
            "epoch: 78, training loss: 22.512863159179688, validation loss: 12.793882369995117\n",
            "epoch: 79, training loss: 22.47783660888672, validation loss: 12.76259994506836\n",
            "epoch: 80, training loss: 22.431758880615234, validation loss: 12.732181549072266\n",
            "epoch: 81, training loss: 22.386518478393555, validation loss: 12.70494270324707\n",
            "epoch: 82, training loss: 22.348222732543945, validation loss: 12.655571937561035\n",
            "epoch: 83, training loss: 22.265064239501953, validation loss: 12.609642028808594\n",
            "epoch: 84, training loss: 22.131389617919922, validation loss: 12.561880111694336\n",
            "epoch: 85, training loss: 22.073755264282227, validation loss: 12.516846656799316\n",
            "epoch: 86, training loss: 22.016265869140625, validation loss: 12.483061790466309\n",
            "epoch: 87, training loss: 21.964462280273438, validation loss: 12.446427345275879\n",
            "epoch: 88, training loss: 21.878131866455078, validation loss: 12.410611152648926\n",
            "epoch: 89, training loss: 21.82909393310547, validation loss: 12.37739372253418\n",
            "epoch: 90, training loss: 21.783546447753906, validation loss: 12.34501838684082\n",
            "epoch: 91, training loss: 21.725318908691406, validation loss: 12.308416366577148\n",
            "epoch: 92, training loss: 21.688737869262695, validation loss: 12.280064582824707\n",
            "epoch: 93, training loss: 21.6463680267334, validation loss: 12.247121810913086\n",
            "epoch: 94, training loss: 21.599239349365234, validation loss: 12.21330451965332\n",
            "epoch: 95, training loss: 21.55286979675293, validation loss: 12.169556617736816\n",
            "epoch: 96, training loss: 21.501171112060547, validation loss: 12.127157211303711\n",
            "epoch: 97, training loss: 21.45830726623535, validation loss: 12.09426212310791\n",
            "epoch: 98, training loss: 21.401235580444336, validation loss: 12.069470405578613\n",
            "epoch: 99, training loss: 21.35687828063965, validation loss: 12.066271781921387\n",
            "epoch: 100, training loss: 21.307464599609375, validation loss: 12.056652069091797\n",
            "epoch: 101, training loss: 21.240985870361328, validation loss: 12.364368438720703\n",
            "epoch: 102, training loss: 21.197561264038086, validation loss: 12.321576118469238\n",
            "epoch: 103, training loss: 21.15993309020996, validation loss: 12.295742988586426\n",
            "epoch: 104, training loss: 21.123821258544922, validation loss: 12.262676239013672\n",
            "epoch: 105, training loss: 21.08611297607422, validation loss: 12.228779792785645\n",
            "epoch: 106, training loss: 21.05658721923828, validation loss: 12.197174072265625\n",
            "epoch: 107, training loss: 21.03619384765625, validation loss: 12.162226676940918\n",
            "epoch: 108, training loss: 20.99871253967285, validation loss: 12.120248794555664\n",
            "epoch: 109, training loss: 20.96916961669922, validation loss: 12.081303596496582\n",
            "epoch: 110, training loss: 20.934062957763672, validation loss: 12.037842750549316\n",
            "epoch: 111, training loss: 20.897743225097656, validation loss: 11.999674797058105\n",
            "epoch: 112, training loss: 20.86423683166504, validation loss: 11.965169906616211\n",
            "epoch: 113, training loss: 20.829818725585938, validation loss: 11.928529739379883\n",
            "epoch: 114, training loss: 20.788734436035156, validation loss: 11.888306617736816\n",
            "epoch: 115, training loss: 20.758533477783203, validation loss: 11.853524208068848\n",
            "epoch: 116, training loss: 20.725481033325195, validation loss: 11.831019401550293\n",
            "epoch: 117, training loss: 20.694469451904297, validation loss: 11.812579154968262\n",
            "epoch: 118, training loss: 20.666736602783203, validation loss: 11.790800094604492\n",
            "epoch: 119, training loss: 20.639385223388672, validation loss: 11.767881393432617\n",
            "epoch: 120, training loss: 20.610612869262695, validation loss: 11.736742973327637\n",
            "epoch: 121, training loss: 20.581275939941406, validation loss: 11.708045959472656\n",
            "epoch: 122, training loss: 20.55684471130371, validation loss: 11.684670448303223\n",
            "epoch: 123, training loss: 20.534664154052734, validation loss: 11.661457061767578\n",
            "epoch: 124, training loss: 20.51407241821289, validation loss: 11.6399507522583\n",
            "epoch: 125, training loss: 20.495040893554688, validation loss: 11.613863945007324\n",
            "epoch: 126, training loss: 20.390823364257812, validation loss: 11.375144958496094\n",
            "epoch: 127, training loss: 20.352113723754883, validation loss: 11.313947677612305\n",
            "epoch: 128, training loss: 20.322248458862305, validation loss: 11.27164077758789\n",
            "epoch: 129, training loss: 20.295854568481445, validation loss: 11.236551284790039\n",
            "epoch: 130, training loss: 20.26996421813965, validation loss: 11.2025146484375\n",
            "epoch: 131, training loss: 20.24930191040039, validation loss: 11.169952392578125\n",
            "epoch: 132, training loss: 20.233964920043945, validation loss: 11.144491195678711\n",
            "epoch: 133, training loss: 20.2229061126709, validation loss: 11.1243257522583\n",
            "epoch: 134, training loss: 20.211210250854492, validation loss: 11.107836723327637\n",
            "epoch: 135, training loss: 20.199655532836914, validation loss: 11.089588165283203\n",
            "epoch: 136, training loss: 20.18798065185547, validation loss: 11.070406913757324\n",
            "epoch: 137, training loss: 20.17396354675293, validation loss: 11.051807403564453\n",
            "epoch: 138, training loss: 20.161373138427734, validation loss: 11.033785820007324\n",
            "epoch: 139, training loss: 20.14493179321289, validation loss: 11.014039039611816\n",
            "epoch: 140, training loss: 20.12549591064453, validation loss: 10.997177124023438\n",
            "epoch: 141, training loss: 20.10504722595215, validation loss: 10.97667121887207\n",
            "epoch: 142, training loss: 20.085145950317383, validation loss: 10.951668739318848\n",
            "epoch: 143, training loss: 20.062850952148438, validation loss: 10.928717613220215\n",
            "epoch: 144, training loss: 20.04666519165039, validation loss: 10.909377098083496\n",
            "epoch: 145, training loss: 20.03388214111328, validation loss: 10.891114234924316\n",
            "epoch: 146, training loss: 20.021827697753906, validation loss: 10.87334156036377\n",
            "epoch: 147, training loss: 20.01059341430664, validation loss: 10.855789184570312\n",
            "epoch: 148, training loss: 19.99802017211914, validation loss: 10.83609390258789\n",
            "epoch: 149, training loss: 19.982629776000977, validation loss: 10.817821502685547\n",
            "epoch: 150, training loss: 19.964420318603516, validation loss: 10.802638053894043\n",
            "epoch: 151, training loss: 20.00876235961914, validation loss: 10.609430313110352\n",
            "epoch: 152, training loss: 19.977903366088867, validation loss: 10.599045753479004\n",
            "epoch: 153, training loss: 19.94870948791504, validation loss: 10.592758178710938\n",
            "epoch: 154, training loss: 19.921537399291992, validation loss: 10.59049129486084\n",
            "epoch: 155, training loss: 19.894563674926758, validation loss: 10.58948802947998\n",
            "epoch: 156, training loss: 19.869638442993164, validation loss: 10.587417602539062\n",
            "epoch: 157, training loss: 19.844873428344727, validation loss: 10.582071304321289\n",
            "epoch: 158, training loss: 19.8225154876709, validation loss: 10.574710845947266\n",
            "epoch: 159, training loss: 19.80308723449707, validation loss: 10.564964294433594\n",
            "epoch: 160, training loss: 19.78548812866211, validation loss: 10.555011749267578\n",
            "epoch: 161, training loss: 19.769515991210938, validation loss: 10.544563293457031\n",
            "epoch: 162, training loss: 19.752910614013672, validation loss: 10.535984992980957\n",
            "epoch: 163, training loss: 19.73166275024414, validation loss: 10.530741691589355\n",
            "epoch: 164, training loss: 19.71265411376953, validation loss: 10.524698257446289\n",
            "epoch: 165, training loss: 19.695329666137695, validation loss: 10.518346786499023\n",
            "epoch: 166, training loss: 19.67915916442871, validation loss: 10.512039184570312\n",
            "epoch: 167, training loss: 19.665912628173828, validation loss: 10.503289222717285\n",
            "epoch: 168, training loss: 19.652732849121094, validation loss: 10.494219779968262\n",
            "epoch: 169, training loss: 19.638933181762695, validation loss: 10.486150741577148\n",
            "epoch: 170, training loss: 19.624221801757812, validation loss: 10.478858947753906\n",
            "epoch: 171, training loss: 19.609508514404297, validation loss: 10.47246265411377\n",
            "epoch: 172, training loss: 19.594532012939453, validation loss: 10.462395668029785\n",
            "epoch: 173, training loss: 19.5787410736084, validation loss: 10.448568344116211\n",
            "epoch: 174, training loss: 19.56259536743164, validation loss: 10.434452056884766\n",
            "epoch: 175, training loss: 19.544706344604492, validation loss: 10.42431926727295\n",
            "epoch: 176, training loss: 19.599441528320312, validation loss: 10.447354316711426\n",
            "epoch: 177, training loss: 19.569704055786133, validation loss: 10.418907165527344\n",
            "epoch: 178, training loss: 19.544544219970703, validation loss: 10.398168563842773\n",
            "epoch: 179, training loss: 19.524003982543945, validation loss: 10.377267837524414\n",
            "epoch: 180, training loss: 19.506023406982422, validation loss: 10.359514236450195\n",
            "epoch: 181, training loss: 19.489418029785156, validation loss: 10.343648910522461\n",
            "epoch: 182, training loss: 19.471786499023438, validation loss: 10.332084655761719\n",
            "epoch: 183, training loss: 19.451444625854492, validation loss: 10.326881408691406\n",
            "epoch: 184, training loss: 19.431236267089844, validation loss: 10.318648338317871\n",
            "epoch: 185, training loss: 19.40966033935547, validation loss: 10.31141185760498\n",
            "epoch: 186, training loss: 19.388010025024414, validation loss: 10.306940078735352\n",
            "epoch: 187, training loss: 19.368091583251953, validation loss: 10.30508041381836\n",
            "epoch: 188, training loss: 19.346786499023438, validation loss: 10.3001070022583\n",
            "epoch: 189, training loss: 19.3267765045166, validation loss: 10.295289993286133\n",
            "epoch: 190, training loss: 19.30927848815918, validation loss: 10.286822319030762\n",
            "epoch: 191, training loss: 19.295312881469727, validation loss: 10.271709442138672\n",
            "epoch: 192, training loss: 19.282798767089844, validation loss: 10.257538795471191\n",
            "epoch: 193, training loss: 19.269758224487305, validation loss: 10.244755744934082\n",
            "epoch: 194, training loss: 19.260128021240234, validation loss: 10.237234115600586\n",
            "epoch: 195, training loss: 19.24909019470215, validation loss: 10.231344223022461\n",
            "epoch: 196, training loss: 19.2380428314209, validation loss: 10.224040031433105\n",
            "epoch: 197, training loss: 19.227075576782227, validation loss: 10.217278480529785\n",
            "epoch: 198, training loss: 19.215730667114258, validation loss: 10.207518577575684\n",
            "epoch: 199, training loss: 19.204509735107422, validation loss: 10.193403244018555\n",
            "epoch: 200, training loss: 19.194805145263672, validation loss: 10.17971134185791\n",
            "epoch: 201, training loss: 19.331127166748047, validation loss: 10.25066089630127\n",
            "epoch: 202, training loss: 19.302921295166016, validation loss: 10.21786117553711\n",
            "epoch: 203, training loss: 19.276081085205078, validation loss: 10.202956199645996\n",
            "epoch: 204, training loss: 19.25027084350586, validation loss: 10.191099166870117\n",
            "epoch: 205, training loss: 19.229524612426758, validation loss: 10.18249797821045\n",
            "epoch: 206, training loss: 19.210451126098633, validation loss: 10.17331600189209\n",
            "epoch: 207, training loss: 19.192548751831055, validation loss: 10.160685539245605\n",
            "epoch: 208, training loss: 19.175905227661133, validation loss: 10.144336700439453\n",
            "epoch: 209, training loss: 19.16025733947754, validation loss: 10.129704475402832\n",
            "epoch: 210, training loss: 19.144821166992188, validation loss: 10.11495304107666\n",
            "epoch: 211, training loss: 19.12999725341797, validation loss: 10.099045753479004\n",
            "epoch: 212, training loss: 19.11495018005371, validation loss: 10.082945823669434\n",
            "epoch: 213, training loss: 19.099525451660156, validation loss: 10.068321228027344\n",
            "epoch: 214, training loss: 19.085660934448242, validation loss: 10.052669525146484\n",
            "epoch: 215, training loss: 19.072973251342773, validation loss: 10.036036491394043\n",
            "epoch: 216, training loss: 19.059978485107422, validation loss: 10.018243789672852\n",
            "epoch: 217, training loss: 19.046951293945312, validation loss: 9.999728202819824\n",
            "epoch: 218, training loss: 19.03346061706543, validation loss: 9.983976364135742\n",
            "epoch: 219, training loss: 19.019763946533203, validation loss: 9.968981742858887\n",
            "epoch: 220, training loss: 19.00604820251465, validation loss: 9.95284366607666\n",
            "epoch: 221, training loss: 18.9912166595459, validation loss: 9.936006546020508\n",
            "epoch: 222, training loss: 18.975765228271484, validation loss: 9.919113159179688\n",
            "epoch: 223, training loss: 18.960384368896484, validation loss: 9.90206527709961\n",
            "epoch: 224, training loss: 18.945674896240234, validation loss: 9.883980751037598\n",
            "epoch: 225, training loss: 18.93147087097168, validation loss: 9.864141464233398\n",
            "epoch: 226, training loss: 19.050703048706055, validation loss: 10.027615547180176\n",
            "epoch: 227, training loss: 19.02764129638672, validation loss: 9.991023063659668\n",
            "epoch: 228, training loss: 19.005632400512695, validation loss: 9.964789390563965\n",
            "epoch: 229, training loss: 18.986431121826172, validation loss: 9.944610595703125\n",
            "epoch: 230, training loss: 18.968055725097656, validation loss: 9.926142692565918\n",
            "epoch: 231, training loss: 18.950721740722656, validation loss: 9.908844947814941\n",
            "epoch: 232, training loss: 18.934730529785156, validation loss: 9.892716407775879\n",
            "epoch: 233, training loss: 18.92087173461914, validation loss: 9.879005432128906\n",
            "epoch: 234, training loss: 18.907960891723633, validation loss: 9.864306449890137\n",
            "epoch: 235, training loss: 18.897912979125977, validation loss: 9.850345611572266\n",
            "epoch: 236, training loss: 18.889955520629883, validation loss: 9.838770866394043\n",
            "epoch: 237, training loss: 18.881263732910156, validation loss: 9.829974174499512\n",
            "epoch: 238, training loss: 18.872116088867188, validation loss: 9.821317672729492\n",
            "epoch: 239, training loss: 18.862667083740234, validation loss: 9.811347961425781\n",
            "epoch: 240, training loss: 18.853330612182617, validation loss: 9.801082611083984\n",
            "epoch: 241, training loss: 18.844093322753906, validation loss: 9.789693832397461\n",
            "epoch: 242, training loss: 18.834518432617188, validation loss: 9.778202056884766\n",
            "epoch: 243, training loss: 18.825607299804688, validation loss: 9.768113136291504\n",
            "epoch: 244, training loss: 18.81776237487793, validation loss: 9.758384704589844\n",
            "epoch: 245, training loss: 18.80952262878418, validation loss: 9.747998237609863\n",
            "epoch: 246, training loss: 18.8011531829834, validation loss: 9.738256454467773\n",
            "epoch: 247, training loss: 18.79307746887207, validation loss: 9.727656364440918\n",
            "epoch: 248, training loss: 18.785165786743164, validation loss: 9.716623306274414\n",
            "epoch: 249, training loss: 18.776620864868164, validation loss: 9.705497741699219\n",
            "epoch: 250, training loss: 18.768156051635742, validation loss: 9.694099426269531\n",
            "epoch: 251, training loss: 18.946041107177734, validation loss: 9.875956535339355\n",
            "epoch: 252, training loss: 18.940364837646484, validation loss: 9.848079681396484\n",
            "epoch: 253, training loss: 18.92876625061035, validation loss: 9.824201583862305\n",
            "epoch: 254, training loss: 18.91718864440918, validation loss: 9.802176475524902\n",
            "epoch: 255, training loss: 18.90489959716797, validation loss: 9.780651092529297\n",
            "epoch: 256, training loss: 18.89204216003418, validation loss: 9.75805377960205\n",
            "epoch: 257, training loss: 18.877050399780273, validation loss: 9.737008094787598\n",
            "epoch: 258, training loss: 18.861478805541992, validation loss: 9.717436790466309\n",
            "epoch: 259, training loss: 18.845279693603516, validation loss: 9.698060035705566\n",
            "epoch: 260, training loss: 18.830142974853516, validation loss: 9.679871559143066\n",
            "epoch: 261, training loss: 18.81599998474121, validation loss: 9.661592483520508\n",
            "epoch: 262, training loss: 18.80209732055664, validation loss: 9.643190383911133\n",
            "epoch: 263, training loss: 18.788911819458008, validation loss: 9.625048637390137\n",
            "epoch: 264, training loss: 18.775798797607422, validation loss: 9.607290267944336\n",
            "epoch: 265, training loss: 18.763301849365234, validation loss: 9.591584205627441\n",
            "epoch: 266, training loss: 18.750612258911133, validation loss: 9.578006744384766\n",
            "epoch: 267, training loss: 18.738231658935547, validation loss: 9.565284729003906\n",
            "epoch: 268, training loss: 18.724794387817383, validation loss: 9.5552978515625\n",
            "epoch: 269, training loss: 18.711755752563477, validation loss: 9.546823501586914\n",
            "epoch: 270, training loss: 18.699134826660156, validation loss: 9.540562629699707\n",
            "epoch: 271, training loss: 18.687232971191406, validation loss: 9.535172462463379\n",
            "epoch: 272, training loss: 18.675827026367188, validation loss: 9.5297212600708\n",
            "epoch: 273, training loss: 18.66469955444336, validation loss: 9.524801254272461\n",
            "epoch: 274, training loss: 18.654258728027344, validation loss: 9.51990795135498\n",
            "epoch: 275, training loss: 18.644458770751953, validation loss: 9.51545238494873\n",
            "epoch: 276, training loss: 18.954496383666992, validation loss: 9.576557159423828\n",
            "epoch: 277, training loss: 18.933610916137695, validation loss: 9.557894706726074\n",
            "epoch: 278, training loss: 18.90776252746582, validation loss: 9.538737297058105\n",
            "epoch: 279, training loss: 18.88317108154297, validation loss: 9.524649620056152\n",
            "epoch: 280, training loss: 18.859119415283203, validation loss: 9.512727737426758\n",
            "epoch: 281, training loss: 18.837268829345703, validation loss: 9.501486778259277\n",
            "epoch: 282, training loss: 18.816146850585938, validation loss: 9.491394996643066\n",
            "epoch: 283, training loss: 18.796144485473633, validation loss: 9.482277870178223\n",
            "epoch: 284, training loss: 18.777263641357422, validation loss: 9.476340293884277\n",
            "epoch: 285, training loss: 18.755460739135742, validation loss: 9.479713439941406\n",
            "epoch: 286, training loss: 18.738941192626953, validation loss: 9.478983879089355\n",
            "epoch: 287, training loss: 18.7259578704834, validation loss: 9.471224784851074\n",
            "epoch: 288, training loss: 18.712669372558594, validation loss: 9.464668273925781\n",
            "epoch: 289, training loss: 18.700254440307617, validation loss: 9.45737361907959\n",
            "epoch: 290, training loss: 18.688648223876953, validation loss: 9.45015811920166\n",
            "epoch: 291, training loss: 18.67848777770996, validation loss: 9.443645477294922\n",
            "epoch: 292, training loss: 18.6693172454834, validation loss: 9.43697738647461\n",
            "epoch: 293, training loss: 18.660499572753906, validation loss: 9.430680274963379\n",
            "epoch: 294, training loss: 18.65188980102539, validation loss: 9.423410415649414\n",
            "epoch: 295, training loss: 18.644119262695312, validation loss: 9.416175842285156\n",
            "epoch: 296, training loss: 18.637083053588867, validation loss: 9.410165786743164\n",
            "epoch: 297, training loss: 18.630046844482422, validation loss: 9.404526710510254\n",
            "epoch: 298, training loss: 18.622922897338867, validation loss: 9.398797035217285\n",
            "epoch: 299, training loss: 18.61600112915039, validation loss: 9.392690658569336\n",
            "epoch: 300, training loss: 18.609933853149414, validation loss: 9.387460708618164\n",
            "epoch: 301, training loss: 18.924631118774414, validation loss: 9.42941951751709\n",
            "epoch: 302, training loss: 18.896512985229492, validation loss: 9.413253784179688\n",
            "epoch: 303, training loss: 18.873516082763672, validation loss: 9.394993782043457\n",
            "epoch: 304, training loss: 18.853853225708008, validation loss: 9.377639770507812\n",
            "epoch: 305, training loss: 18.836397171020508, validation loss: 9.362162590026855\n",
            "epoch: 306, training loss: 18.82164764404297, validation loss: 9.348305702209473\n",
            "epoch: 307, training loss: 18.810544967651367, validation loss: 9.33573055267334\n",
            "epoch: 308, training loss: 18.800844192504883, validation loss: 9.324932098388672\n",
            "epoch: 309, training loss: 18.79170799255371, validation loss: 9.315347671508789\n",
            "epoch: 310, training loss: 18.783607482910156, validation loss: 9.306714057922363\n",
            "epoch: 311, training loss: 18.77733039855957, validation loss: 9.300010681152344\n",
            "epoch: 312, training loss: 18.77145004272461, validation loss: 9.292898178100586\n",
            "epoch: 313, training loss: 18.764162063598633, validation loss: 9.284438133239746\n",
            "epoch: 314, training loss: 18.75629234313965, validation loss: 9.27596664428711\n",
            "epoch: 315, training loss: 18.74938201904297, validation loss: 9.26816463470459\n",
            "epoch: 316, training loss: 18.742937088012695, validation loss: 9.25978946685791\n",
            "epoch: 317, training loss: 18.73687171936035, validation loss: 9.251724243164062\n",
            "epoch: 318, training loss: 18.731121063232422, validation loss: 9.24395751953125\n",
            "epoch: 319, training loss: 18.724903106689453, validation loss: 9.236489295959473\n",
            "epoch: 320, training loss: 18.718738555908203, validation loss: 9.22953987121582\n",
            "epoch: 321, training loss: 18.71269989013672, validation loss: 9.2225341796875\n",
            "epoch: 322, training loss: 18.707067489624023, validation loss: 9.215497016906738\n",
            "epoch: 323, training loss: 18.702098846435547, validation loss: 9.20828628540039\n",
            "epoch: 324, training loss: 18.697307586669922, validation loss: 9.201257705688477\n",
            "epoch: 325, training loss: 18.692358016967773, validation loss: 9.194656372070312\n",
            "epoch: 326, training loss: 18.866676330566406, validation loss: 9.218331336975098\n",
            "epoch: 327, training loss: 18.845325469970703, validation loss: 9.208694458007812\n",
            "epoch: 328, training loss: 18.831056594848633, validation loss: 9.200136184692383\n",
            "epoch: 329, training loss: 18.820322036743164, validation loss: 9.191585540771484\n",
            "epoch: 330, training loss: 18.811296463012695, validation loss: 9.182146072387695\n",
            "epoch: 331, training loss: 18.803739547729492, validation loss: 9.172167778015137\n",
            "epoch: 332, training loss: 18.797727584838867, validation loss: 9.163447380065918\n",
            "epoch: 333, training loss: 18.791738510131836, validation loss: 9.155104637145996\n",
            "epoch: 334, training loss: 18.786231994628906, validation loss: 9.146622657775879\n",
            "epoch: 335, training loss: 18.78150749206543, validation loss: 9.137775421142578\n",
            "epoch: 336, training loss: 18.77764129638672, validation loss: 9.128168106079102\n",
            "epoch: 337, training loss: 18.774208068847656, validation loss: 9.1176176071167\n",
            "epoch: 338, training loss: 18.77200698852539, validation loss: 9.106459617614746\n",
            "epoch: 339, training loss: 18.769657135009766, validation loss: 9.096979141235352\n",
            "epoch: 340, training loss: 18.766090393066406, validation loss: 9.088196754455566\n",
            "epoch: 341, training loss: 18.763107299804688, validation loss: 9.080205917358398\n",
            "epoch: 342, training loss: 18.76007843017578, validation loss: 9.074424743652344\n",
            "epoch: 343, training loss: 18.75644874572754, validation loss: 9.069157600402832\n",
            "epoch: 344, training loss: 18.753263473510742, validation loss: 9.06405258178711\n",
            "epoch: 345, training loss: 18.75016212463379, validation loss: 9.058636665344238\n",
            "epoch: 346, training loss: 18.747055053710938, validation loss: 9.052916526794434\n",
            "epoch: 347, training loss: 18.744169235229492, validation loss: 9.047547340393066\n",
            "epoch: 348, training loss: 18.741907119750977, validation loss: 9.042120933532715\n",
            "epoch: 349, training loss: 18.739578247070312, validation loss: 9.037046432495117\n",
            "epoch: 350, training loss: 18.73592185974121, validation loss: 9.033347129821777\n",
            "epoch: 351, training loss: 18.647802352905273, validation loss: 8.915847778320312\n",
            "epoch: 352, training loss: 18.635068893432617, validation loss: 8.91140079498291\n",
            "epoch: 353, training loss: 18.628704071044922, validation loss: 8.909371376037598\n",
            "epoch: 354, training loss: 18.623886108398438, validation loss: 8.907780647277832\n",
            "epoch: 355, training loss: 18.619529724121094, validation loss: 8.90654468536377\n",
            "epoch: 356, training loss: 18.61540985107422, validation loss: 8.905062675476074\n",
            "epoch: 357, training loss: 18.611780166625977, validation loss: 8.903329849243164\n",
            "epoch: 358, training loss: 18.60843849182129, validation loss: 8.901573181152344\n",
            "epoch: 359, training loss: 18.60509490966797, validation loss: 8.899596214294434\n",
            "epoch: 360, training loss: 18.601125717163086, validation loss: 8.897385597229004\n",
            "epoch: 361, training loss: 18.59732437133789, validation loss: 8.89510726928711\n",
            "epoch: 362, training loss: 18.59361457824707, validation loss: 8.893010139465332\n",
            "epoch: 363, training loss: 18.58989906311035, validation loss: 8.891061782836914\n",
            "epoch: 364, training loss: 18.586069107055664, validation loss: 8.889069557189941\n",
            "epoch: 365, training loss: 18.581890106201172, validation loss: 8.886363983154297\n",
            "epoch: 366, training loss: 18.577775955200195, validation loss: 8.883524894714355\n",
            "epoch: 367, training loss: 18.573532104492188, validation loss: 8.880492210388184\n",
            "epoch: 368, training loss: 18.56924057006836, validation loss: 8.877792358398438\n",
            "epoch: 369, training loss: 18.56480598449707, validation loss: 8.875006675720215\n",
            "epoch: 370, training loss: 18.560209274291992, validation loss: 8.871626853942871\n",
            "epoch: 371, training loss: 18.55521583557129, validation loss: 8.867010116577148\n",
            "epoch: 372, training loss: 18.549650192260742, validation loss: 8.86131477355957\n",
            "epoch: 373, training loss: 18.544153213500977, validation loss: 8.85637378692627\n",
            "epoch: 374, training loss: 18.53842544555664, validation loss: 8.851612091064453\n",
            "epoch: 375, training loss: 18.532808303833008, validation loss: 8.847240447998047\n",
            "epoch: 376, training loss: 18.306373596191406, validation loss: 8.614178657531738\n",
            "epoch: 377, training loss: 18.308029174804688, validation loss: 8.619768142700195\n",
            "epoch: 378, training loss: 18.30763053894043, validation loss: 8.625100135803223\n",
            "epoch: 379, training loss: 18.306278228759766, validation loss: 8.629405975341797\n",
            "epoch: 380, training loss: 18.304079055786133, validation loss: 8.632767677307129\n",
            "epoch: 381, training loss: 18.30120086669922, validation loss: 8.634839057922363\n",
            "epoch: 382, training loss: 18.298561096191406, validation loss: 8.636025428771973\n",
            "epoch: 383, training loss: 18.29568099975586, validation loss: 8.636601448059082\n",
            "epoch: 384, training loss: 18.292736053466797, validation loss: 8.63696002960205\n",
            "epoch: 385, training loss: 18.28946304321289, validation loss: 8.637065887451172\n",
            "epoch: 386, training loss: 18.286182403564453, validation loss: 8.637206077575684\n",
            "epoch: 387, training loss: 18.28285026550293, validation loss: 8.637333869934082\n",
            "epoch: 388, training loss: 18.279314041137695, validation loss: 8.63733196258545\n",
            "epoch: 389, training loss: 18.275875091552734, validation loss: 8.63770866394043\n",
            "epoch: 390, training loss: 18.27245330810547, validation loss: 8.638256072998047\n",
            "epoch: 391, training loss: 18.268714904785156, validation loss: 8.638483047485352\n",
            "epoch: 392, training loss: 18.264795303344727, validation loss: 8.638099670410156\n",
            "epoch: 393, training loss: 18.260709762573242, validation loss: 8.637541770935059\n",
            "epoch: 394, training loss: 18.257068634033203, validation loss: 8.637445449829102\n",
            "epoch: 395, training loss: 18.25324821472168, validation loss: 8.637431144714355\n",
            "epoch: 396, training loss: 18.249431610107422, validation loss: 8.63768196105957\n",
            "epoch: 397, training loss: 18.245512008666992, validation loss: 8.63776683807373\n",
            "epoch: 398, training loss: 18.242088317871094, validation loss: 8.637443542480469\n",
            "epoch: 399, training loss: 18.238510131835938, validation loss: 8.636934280395508\n",
            "epoch: 400, training loss: 18.234981536865234, validation loss: 8.636208534240723\n",
            "epoch: 401, training loss: 18.06336784362793, validation loss: 8.429287910461426\n",
            "epoch: 402, training loss: 18.064199447631836, validation loss: 8.42805004119873\n",
            "epoch: 403, training loss: 18.06290054321289, validation loss: 8.42741870880127\n",
            "epoch: 404, training loss: 18.060791015625, validation loss: 8.427092552185059\n",
            "epoch: 405, training loss: 18.05874252319336, validation loss: 8.426613807678223\n",
            "epoch: 406, training loss: 18.05657958984375, validation loss: 8.425683975219727\n",
            "epoch: 407, training loss: 18.054183959960938, validation loss: 8.424241065979004\n",
            "epoch: 408, training loss: 18.052093505859375, validation loss: 8.422502517700195\n",
            "epoch: 409, training loss: 18.049970626831055, validation loss: 8.420523643493652\n",
            "epoch: 410, training loss: 18.04776382446289, validation loss: 8.418559074401855\n",
            "epoch: 411, training loss: 18.045509338378906, validation loss: 8.416435241699219\n",
            "epoch: 412, training loss: 18.043262481689453, validation loss: 8.414422988891602\n",
            "epoch: 413, training loss: 18.040918350219727, validation loss: 8.412332534790039\n",
            "epoch: 414, training loss: 18.03850555419922, validation loss: 8.410369873046875\n",
            "epoch: 415, training loss: 18.03597068786621, validation loss: 8.408416748046875\n",
            "epoch: 416, training loss: 18.03335189819336, validation loss: 8.406291961669922\n",
            "epoch: 417, training loss: 18.03071403503418, validation loss: 8.404486656188965\n",
            "epoch: 418, training loss: 18.02788543701172, validation loss: 8.402831077575684\n",
            "epoch: 419, training loss: 18.02495574951172, validation loss: 8.40126895904541\n",
            "epoch: 420, training loss: 18.022010803222656, validation loss: 8.399886131286621\n",
            "epoch: 421, training loss: 18.018978118896484, validation loss: 8.398566246032715\n",
            "epoch: 422, training loss: 18.015979766845703, validation loss: 8.397355079650879\n",
            "epoch: 423, training loss: 18.0130558013916, validation loss: 8.396368980407715\n",
            "epoch: 424, training loss: 18.010210037231445, validation loss: 8.39561939239502\n",
            "epoch: 425, training loss: 18.007591247558594, validation loss: 8.394806861877441\n",
            "epoch: 426, training loss: 17.950489044189453, validation loss: 8.259706497192383\n",
            "epoch: 427, training loss: 17.953598022460938, validation loss: 8.252389907836914\n",
            "epoch: 428, training loss: 17.953672409057617, validation loss: 8.248090744018555\n",
            "epoch: 429, training loss: 17.951885223388672, validation loss: 8.24585247039795\n",
            "epoch: 430, training loss: 17.949235916137695, validation loss: 8.245190620422363\n",
            "epoch: 431, training loss: 17.946176528930664, validation loss: 8.244860649108887\n",
            "epoch: 432, training loss: 17.94272804260254, validation loss: 8.243430137634277\n",
            "epoch: 433, training loss: 17.93909454345703, validation loss: 8.241477012634277\n",
            "epoch: 434, training loss: 17.935199737548828, validation loss: 8.239330291748047\n",
            "epoch: 435, training loss: 17.931270599365234, validation loss: 8.236907958984375\n",
            "epoch: 436, training loss: 17.927349090576172, validation loss: 8.234379768371582\n",
            "epoch: 437, training loss: 17.923362731933594, validation loss: 8.231443405151367\n",
            "epoch: 438, training loss: 17.919403076171875, validation loss: 8.228153228759766\n",
            "epoch: 439, training loss: 17.915176391601562, validation loss: 8.224617004394531\n",
            "epoch: 440, training loss: 17.910930633544922, validation loss: 8.220531463623047\n",
            "epoch: 441, training loss: 17.906841278076172, validation loss: 8.216029167175293\n",
            "epoch: 442, training loss: 17.902624130249023, validation loss: 8.211920738220215\n",
            "epoch: 443, training loss: 17.898420333862305, validation loss: 8.2081880569458\n",
            "epoch: 444, training loss: 17.89423179626465, validation loss: 8.204509735107422\n",
            "epoch: 445, training loss: 17.89000701904297, validation loss: 8.201078414916992\n",
            "epoch: 446, training loss: 17.8858642578125, validation loss: 8.197946548461914\n",
            "epoch: 447, training loss: 17.882064819335938, validation loss: 8.194952011108398\n",
            "epoch: 448, training loss: 17.878400802612305, validation loss: 8.19229793548584\n",
            "epoch: 449, training loss: 17.875171661376953, validation loss: 8.190699577331543\n",
            "epoch: 450, training loss: 17.87204360961914, validation loss: 8.189595222473145\n",
            "epoch: 451, training loss: 17.881208419799805, validation loss: 8.099164962768555\n",
            "epoch: 452, training loss: 17.880905151367188, validation loss: 8.089310646057129\n",
            "epoch: 453, training loss: 17.87904930114746, validation loss: 8.083033561706543\n",
            "epoch: 454, training loss: 17.877273559570312, validation loss: 8.078661918640137\n",
            "epoch: 455, training loss: 17.875722885131836, validation loss: 8.072918891906738\n",
            "epoch: 456, training loss: 17.87287139892578, validation loss: 8.071706771850586\n",
            "epoch: 457, training loss: 17.87101936340332, validation loss: 8.072636604309082\n",
            "epoch: 458, training loss: 17.867210388183594, validation loss: 8.070348739624023\n",
            "epoch: 459, training loss: 17.86290740966797, validation loss: 8.067461967468262\n",
            "epoch: 460, training loss: 17.858373641967773, validation loss: 8.064833641052246\n",
            "epoch: 461, training loss: 17.853872299194336, validation loss: 8.062200546264648\n",
            "epoch: 462, training loss: 17.84933090209961, validation loss: 8.059475898742676\n",
            "epoch: 463, training loss: 17.84462547302246, validation loss: 8.056791305541992\n",
            "epoch: 464, training loss: 17.839712142944336, validation loss: 8.054084777832031\n",
            "epoch: 465, training loss: 17.834823608398438, validation loss: 8.051329612731934\n",
            "epoch: 466, training loss: 17.830028533935547, validation loss: 8.04873275756836\n",
            "epoch: 467, training loss: 17.825420379638672, validation loss: 8.046233177185059\n",
            "epoch: 468, training loss: 17.820972442626953, validation loss: 8.04394245147705\n",
            "epoch: 469, training loss: 17.816709518432617, validation loss: 8.041617393493652\n",
            "epoch: 470, training loss: 17.812545776367188, validation loss: 8.039270401000977\n",
            "epoch: 471, training loss: 17.80821990966797, validation loss: 8.037001609802246\n",
            "epoch: 472, training loss: 17.80385971069336, validation loss: 8.034934043884277\n",
            "epoch: 473, training loss: 17.799516677856445, validation loss: 8.03292179107666\n",
            "epoch: 474, training loss: 17.794992446899414, validation loss: 8.031065940856934\n",
            "epoch: 475, training loss: 17.790462493896484, validation loss: 8.029376029968262\n",
            "epoch: 476, training loss: 17.804203033447266, validation loss: 7.905137062072754\n",
            "epoch: 477, training loss: 17.799182891845703, validation loss: 7.894750595092773\n",
            "epoch: 478, training loss: 17.793107986450195, validation loss: 7.888391017913818\n",
            "epoch: 479, training loss: 17.786865234375, validation loss: 7.88328218460083\n",
            "epoch: 480, training loss: 17.78082275390625, validation loss: 7.878645420074463\n",
            "epoch: 481, training loss: 17.77508544921875, validation loss: 7.87454080581665\n",
            "epoch: 482, training loss: 17.769466400146484, validation loss: 7.871018409729004\n",
            "epoch: 483, training loss: 17.7640380859375, validation loss: 7.867919921875\n",
            "epoch: 484, training loss: 17.758684158325195, validation loss: 7.86505126953125\n",
            "epoch: 485, training loss: 17.753440856933594, validation loss: 7.862400531768799\n",
            "epoch: 486, training loss: 17.74843978881836, validation loss: 7.859922885894775\n",
            "epoch: 487, training loss: 17.74378204345703, validation loss: 7.857641696929932\n",
            "epoch: 488, training loss: 17.739171981811523, validation loss: 7.85552453994751\n",
            "epoch: 489, training loss: 17.734655380249023, validation loss: 7.853403568267822\n",
            "epoch: 490, training loss: 17.730119705200195, validation loss: 7.851438522338867\n",
            "epoch: 491, training loss: 17.725522994995117, validation loss: 7.849607944488525\n",
            "epoch: 492, training loss: 17.720928192138672, validation loss: 7.84799337387085\n",
            "epoch: 493, training loss: 17.716140747070312, validation loss: 7.846386432647705\n",
            "epoch: 494, training loss: 17.71126365661621, validation loss: 7.844770431518555\n",
            "epoch: 495, training loss: 17.706296920776367, validation loss: 7.843336582183838\n",
            "epoch: 496, training loss: 17.701263427734375, validation loss: 7.842190265655518\n",
            "epoch: 497, training loss: 17.6961669921875, validation loss: 7.841265678405762\n",
            "epoch: 498, training loss: 17.69098472595215, validation loss: 7.840508937835693\n",
            "epoch: 499, training loss: 17.68562889099121, validation loss: 7.8398308753967285\n",
            "epoch: 500, training loss: 17.6800479888916, validation loss: 7.839138984680176\n",
            "Predictions for austin generated!\n",
            "\n",
            "Done printing austin predictions\n",
            "----------------------------------------------------------------------\n",
            "epoch: 1, training loss: 18.673648834228516, validation loss: 17.532194137573242\n",
            "epoch: 2, training loss: 17.828893661499023, validation loss: 16.97427749633789\n",
            "epoch: 3, training loss: 17.356464385986328, validation loss: 16.620113372802734\n",
            "epoch: 4, training loss: 16.991859436035156, validation loss: 16.37156105041504\n",
            "epoch: 5, training loss: 16.73933219909668, validation loss: 16.177724838256836\n",
            "epoch: 6, training loss: 16.5887393951416, validation loss: 16.01051902770996\n",
            "epoch: 7, training loss: 16.47378158569336, validation loss: 15.875927925109863\n",
            "epoch: 8, training loss: 16.370922088623047, validation loss: 15.774547576904297\n",
            "epoch: 9, training loss: 16.269161224365234, validation loss: 15.690274238586426\n",
            "epoch: 10, training loss: 16.174556732177734, validation loss: 15.616437911987305\n",
            "epoch: 11, training loss: 16.09317398071289, validation loss: 15.554412841796875\n",
            "epoch: 12, training loss: 16.024372100830078, validation loss: 15.497687339782715\n",
            "epoch: 13, training loss: 15.937482833862305, validation loss: 15.451380729675293\n",
            "epoch: 14, training loss: 15.868718147277832, validation loss: 15.407730102539062\n",
            "epoch: 15, training loss: 15.806005477905273, validation loss: 15.369062423706055\n",
            "epoch: 16, training loss: 15.73839282989502, validation loss: 15.342801094055176\n",
            "epoch: 17, training loss: 15.670600891113281, validation loss: 15.304733276367188\n",
            "epoch: 18, training loss: 15.59874439239502, validation loss: 15.252886772155762\n",
            "epoch: 19, training loss: 15.517279624938965, validation loss: 15.212933540344238\n",
            "epoch: 20, training loss: 15.4467134475708, validation loss: 15.17903995513916\n",
            "epoch: 21, training loss: 15.37654972076416, validation loss: 15.145180702209473\n",
            "epoch: 22, training loss: 15.309494018554688, validation loss: 15.115148544311523\n",
            "epoch: 23, training loss: 15.24346923828125, validation loss: 15.087433815002441\n",
            "epoch: 24, training loss: 15.176403045654297, validation loss: 15.060999870300293\n",
            "epoch: 25, training loss: 15.100027084350586, validation loss: 15.0355863571167\n",
            "epoch: 26, training loss: 14.93725299835205, validation loss: 14.968184471130371\n",
            "epoch: 27, training loss: 14.880565643310547, validation loss: 14.949183464050293\n",
            "epoch: 28, training loss: 14.826654434204102, validation loss: 14.929508209228516\n",
            "epoch: 29, training loss: 14.769951820373535, validation loss: 14.911160469055176\n",
            "epoch: 30, training loss: 14.712434768676758, validation loss: 14.895074844360352\n",
            "epoch: 31, training loss: 14.656693458557129, validation loss: 14.878022193908691\n",
            "epoch: 32, training loss: 14.603689193725586, validation loss: 14.859711647033691\n",
            "epoch: 33, training loss: 14.554974555969238, validation loss: 14.84295654296875\n",
            "epoch: 34, training loss: 14.507746696472168, validation loss: 14.825913429260254\n",
            "epoch: 35, training loss: 14.462716102600098, validation loss: 14.80896282196045\n",
            "epoch: 36, training loss: 14.421022415161133, validation loss: 14.793170928955078\n",
            "epoch: 37, training loss: 14.376221656799316, validation loss: 14.776329040527344\n",
            "epoch: 38, training loss: 14.324650764465332, validation loss: 14.75915241241455\n",
            "epoch: 39, training loss: 14.27475357055664, validation loss: 14.74166488647461\n",
            "epoch: 40, training loss: 14.233274459838867, validation loss: 14.723489761352539\n",
            "epoch: 41, training loss: 14.198939323425293, validation loss: 14.70707893371582\n",
            "epoch: 42, training loss: 14.168930053710938, validation loss: 14.69156265258789\n",
            "epoch: 43, training loss: 14.142522811889648, validation loss: 14.675615310668945\n",
            "epoch: 44, training loss: 14.116972923278809, validation loss: 14.658353805541992\n",
            "epoch: 45, training loss: 14.093188285827637, validation loss: 14.64113712310791\n",
            "epoch: 46, training loss: 14.071030616760254, validation loss: 14.623411178588867\n",
            "epoch: 47, training loss: 14.050740242004395, validation loss: 14.605401039123535\n",
            "epoch: 48, training loss: 14.0291166305542, validation loss: 14.587793350219727\n",
            "epoch: 49, training loss: 14.009982109069824, validation loss: 14.570119857788086\n",
            "epoch: 50, training loss: 13.990188598632812, validation loss: 14.553481101989746\n",
            "epoch: 51, training loss: 13.896873474121094, validation loss: 14.47957992553711\n",
            "epoch: 52, training loss: 13.874364852905273, validation loss: 14.464764595031738\n",
            "epoch: 53, training loss: 13.847424507141113, validation loss: 14.445845603942871\n",
            "epoch: 54, training loss: 13.828018188476562, validation loss: 14.42828369140625\n",
            "epoch: 55, training loss: 13.812947273254395, validation loss: 14.412774085998535\n",
            "epoch: 56, training loss: 13.798447608947754, validation loss: 14.398122787475586\n",
            "epoch: 57, training loss: 13.783546447753906, validation loss: 14.383703231811523\n",
            "epoch: 58, training loss: 13.769277572631836, validation loss: 14.3701753616333\n",
            "epoch: 59, training loss: 13.755765914916992, validation loss: 14.35716438293457\n",
            "epoch: 60, training loss: 13.743156433105469, validation loss: 14.344407081604004\n",
            "epoch: 61, training loss: 13.7306489944458, validation loss: 14.332669258117676\n",
            "epoch: 62, training loss: 13.717565536499023, validation loss: 14.321569442749023\n",
            "epoch: 63, training loss: 13.704388618469238, validation loss: 14.31087875366211\n",
            "epoch: 64, training loss: 13.692021369934082, validation loss: 14.300095558166504\n",
            "epoch: 65, training loss: 13.679378509521484, validation loss: 14.28956413269043\n",
            "epoch: 66, training loss: 13.66720962524414, validation loss: 14.279626846313477\n",
            "epoch: 67, training loss: 13.655203819274902, validation loss: 14.270075798034668\n",
            "epoch: 68, training loss: 13.642650604248047, validation loss: 14.260454177856445\n",
            "epoch: 69, training loss: 13.629562377929688, validation loss: 14.250516891479492\n",
            "epoch: 70, training loss: 13.614774703979492, validation loss: 14.239370346069336\n",
            "epoch: 71, training loss: 13.59744930267334, validation loss: 14.22591495513916\n",
            "epoch: 72, training loss: 13.586283683776855, validation loss: 14.215971946716309\n",
            "epoch: 73, training loss: 13.576129913330078, validation loss: 14.207045555114746\n",
            "epoch: 74, training loss: 13.563756942749023, validation loss: 14.196496963500977\n",
            "epoch: 75, training loss: 13.551241874694824, validation loss: 14.185006141662598\n",
            "epoch: 76, training loss: 13.511312484741211, validation loss: 14.140422821044922\n",
            "epoch: 77, training loss: 13.502493858337402, validation loss: 14.135263442993164\n",
            "epoch: 78, training loss: 13.49370002746582, validation loss: 14.130026817321777\n",
            "epoch: 79, training loss: 13.485047340393066, validation loss: 14.12397289276123\n",
            "epoch: 80, training loss: 13.48022174835205, validation loss: 14.118803024291992\n",
            "epoch: 81, training loss: 13.476685523986816, validation loss: 14.113452911376953\n",
            "epoch: 82, training loss: 13.472393989562988, validation loss: 14.107600212097168\n",
            "epoch: 83, training loss: 13.466924667358398, validation loss: 14.101351737976074\n",
            "epoch: 84, training loss: 13.45995807647705, validation loss: 14.09467601776123\n",
            "epoch: 85, training loss: 13.452381134033203, validation loss: 14.087550163269043\n",
            "epoch: 86, training loss: 13.44469165802002, validation loss: 14.08010482788086\n",
            "epoch: 87, training loss: 13.436708450317383, validation loss: 14.0735445022583\n",
            "epoch: 88, training loss: 13.429025650024414, validation loss: 14.067450523376465\n",
            "epoch: 89, training loss: 13.422085762023926, validation loss: 14.061327934265137\n",
            "epoch: 90, training loss: 13.415485382080078, validation loss: 14.055546760559082\n",
            "epoch: 91, training loss: 13.40878677368164, validation loss: 14.049479484558105\n",
            "epoch: 92, training loss: 13.401799201965332, validation loss: 14.043404579162598\n",
            "epoch: 93, training loss: 13.394460678100586, validation loss: 14.037463188171387\n",
            "epoch: 94, training loss: 13.387128829956055, validation loss: 14.031279563903809\n",
            "epoch: 95, training loss: 13.379974365234375, validation loss: 14.024953842163086\n",
            "epoch: 96, training loss: 13.37256145477295, validation loss: 14.018898963928223\n",
            "epoch: 97, training loss: 13.365378379821777, validation loss: 14.012813568115234\n",
            "epoch: 98, training loss: 13.358458518981934, validation loss: 14.006837844848633\n",
            "epoch: 99, training loss: 13.351789474487305, validation loss: 14.000385284423828\n",
            "epoch: 100, training loss: 13.345542907714844, validation loss: 13.994160652160645\n",
            "epoch: 101, training loss: 13.343803405761719, validation loss: 13.99673080444336\n",
            "epoch: 102, training loss: 13.334691047668457, validation loss: 13.991480827331543\n",
            "epoch: 103, training loss: 13.32622241973877, validation loss: 13.985739707946777\n",
            "epoch: 104, training loss: 13.318076133728027, validation loss: 13.979894638061523\n",
            "epoch: 105, training loss: 13.310073852539062, validation loss: 13.974380493164062\n",
            "epoch: 106, training loss: 13.302327156066895, validation loss: 13.968700408935547\n",
            "epoch: 107, training loss: 13.294486045837402, validation loss: 13.962793350219727\n",
            "epoch: 108, training loss: 13.28735065460205, validation loss: 13.95663070678711\n",
            "epoch: 109, training loss: 13.280749320983887, validation loss: 13.950435638427734\n",
            "epoch: 110, training loss: 13.274444580078125, validation loss: 13.944548606872559\n",
            "epoch: 111, training loss: 13.268104553222656, validation loss: 13.939009666442871\n",
            "epoch: 112, training loss: 13.261584281921387, validation loss: 13.933823585510254\n",
            "epoch: 113, training loss: 13.254961967468262, validation loss: 13.928689002990723\n",
            "epoch: 114, training loss: 13.248125076293945, validation loss: 13.923539161682129\n",
            "epoch: 115, training loss: 13.241100311279297, validation loss: 13.918477058410645\n",
            "epoch: 116, training loss: 13.234051704406738, validation loss: 13.913318634033203\n",
            "epoch: 117, training loss: 13.227211952209473, validation loss: 13.908023834228516\n",
            "epoch: 118, training loss: 13.220291137695312, validation loss: 13.902711868286133\n",
            "epoch: 119, training loss: 13.213226318359375, validation loss: 13.897470474243164\n",
            "epoch: 120, training loss: 13.205999374389648, validation loss: 13.892142295837402\n",
            "epoch: 121, training loss: 13.198738098144531, validation loss: 13.886824607849121\n",
            "epoch: 122, training loss: 13.191712379455566, validation loss: 13.881657600402832\n",
            "epoch: 123, training loss: 13.184869766235352, validation loss: 13.87653923034668\n",
            "epoch: 124, training loss: 13.178071975708008, validation loss: 13.871513366699219\n",
            "epoch: 125, training loss: 13.171300888061523, validation loss: 13.866531372070312\n",
            "epoch: 126, training loss: 13.178980827331543, validation loss: 13.880646705627441\n",
            "epoch: 127, training loss: 13.170637130737305, validation loss: 13.875632286071777\n",
            "epoch: 128, training loss: 13.162735939025879, validation loss: 13.870607376098633\n",
            "epoch: 129, training loss: 13.155088424682617, validation loss: 13.865592002868652\n",
            "epoch: 130, training loss: 13.14745807647705, validation loss: 13.860568046569824\n",
            "epoch: 131, training loss: 13.140656471252441, validation loss: 13.8555908203125\n",
            "epoch: 132, training loss: 13.134355545043945, validation loss: 13.850549697875977\n",
            "epoch: 133, training loss: 13.12856674194336, validation loss: 13.845372200012207\n",
            "epoch: 134, training loss: 13.123096466064453, validation loss: 13.840263366699219\n",
            "epoch: 135, training loss: 13.117851257324219, validation loss: 13.835200309753418\n",
            "epoch: 136, training loss: 13.112589836120605, validation loss: 13.830169677734375\n",
            "epoch: 137, training loss: 13.107407569885254, validation loss: 13.825121879577637\n",
            "epoch: 138, training loss: 13.102303504943848, validation loss: 13.820087432861328\n",
            "epoch: 139, training loss: 13.097127914428711, validation loss: 13.81520938873291\n",
            "epoch: 140, training loss: 13.092021942138672, validation loss: 13.81036376953125\n",
            "epoch: 141, training loss: 13.08702564239502, validation loss: 13.805530548095703\n",
            "epoch: 142, training loss: 13.082027435302734, validation loss: 13.800573348999023\n",
            "epoch: 143, training loss: 13.077049255371094, validation loss: 13.795467376708984\n",
            "epoch: 144, training loss: 13.072081565856934, validation loss: 13.790385246276855\n",
            "epoch: 145, training loss: 13.067198753356934, validation loss: 13.785210609436035\n",
            "epoch: 146, training loss: 13.06231689453125, validation loss: 13.780394554138184\n",
            "epoch: 147, training loss: 13.057134628295898, validation loss: 13.77570629119873\n",
            "epoch: 148, training loss: 13.051849365234375, validation loss: 13.771025657653809\n",
            "epoch: 149, training loss: 13.046380043029785, validation loss: 13.766313552856445\n",
            "epoch: 150, training loss: 13.041524887084961, validation loss: 13.762128829956055\n",
            "epoch: 151, training loss: 13.050317764282227, validation loss: 13.75466537475586\n",
            "epoch: 152, training loss: 13.04425048828125, validation loss: 13.751692771911621\n",
            "epoch: 153, training loss: 13.038411140441895, validation loss: 13.748574256896973\n",
            "epoch: 154, training loss: 13.032598495483398, validation loss: 13.745277404785156\n",
            "epoch: 155, training loss: 13.02684497833252, validation loss: 13.741785049438477\n",
            "epoch: 156, training loss: 13.021303176879883, validation loss: 13.738243103027344\n",
            "epoch: 157, training loss: 13.016334533691406, validation loss: 13.735154151916504\n",
            "epoch: 158, training loss: 13.011441230773926, validation loss: 13.73231029510498\n",
            "epoch: 159, training loss: 13.006515502929688, validation loss: 13.729551315307617\n",
            "epoch: 160, training loss: 13.001527786254883, validation loss: 13.726886749267578\n",
            "epoch: 161, training loss: 12.996637344360352, validation loss: 13.724264144897461\n",
            "epoch: 162, training loss: 12.99195384979248, validation loss: 13.721641540527344\n",
            "epoch: 163, training loss: 12.987329483032227, validation loss: 13.718904495239258\n",
            "epoch: 164, training loss: 12.982701301574707, validation loss: 13.716175079345703\n",
            "epoch: 165, training loss: 12.978073120117188, validation loss: 13.713567733764648\n",
            "epoch: 166, training loss: 12.973454475402832, validation loss: 13.711010932922363\n",
            "epoch: 167, training loss: 12.968788146972656, validation loss: 13.708504676818848\n",
            "epoch: 168, training loss: 12.964491844177246, validation loss: 13.706156730651855\n",
            "epoch: 169, training loss: 12.96036148071289, validation loss: 13.70389175415039\n",
            "epoch: 170, training loss: 12.956378936767578, validation loss: 13.701677322387695\n",
            "epoch: 171, training loss: 12.952495574951172, validation loss: 13.699442863464355\n",
            "epoch: 172, training loss: 12.948628425598145, validation loss: 13.6971435546875\n",
            "epoch: 173, training loss: 12.944796562194824, validation loss: 13.694857597351074\n",
            "epoch: 174, training loss: 12.941062927246094, validation loss: 13.692594528198242\n",
            "epoch: 175, training loss: 12.9373779296875, validation loss: 13.690343856811523\n",
            "epoch: 176, training loss: 12.955718040466309, validation loss: 13.65829849243164\n",
            "epoch: 177, training loss: 12.951784133911133, validation loss: 13.657124519348145\n",
            "epoch: 178, training loss: 12.94731330871582, validation loss: 13.655539512634277\n",
            "epoch: 179, training loss: 12.942866325378418, validation loss: 13.653716087341309\n",
            "epoch: 180, training loss: 12.9384765625, validation loss: 13.651718139648438\n",
            "epoch: 181, training loss: 12.934073448181152, validation loss: 13.649602890014648\n",
            "epoch: 182, training loss: 12.92969036102295, validation loss: 13.647417068481445\n",
            "epoch: 183, training loss: 12.925370216369629, validation loss: 13.645210266113281\n",
            "epoch: 184, training loss: 12.92101764678955, validation loss: 13.642956733703613\n",
            "epoch: 185, training loss: 12.916566848754883, validation loss: 13.640668869018555\n",
            "epoch: 186, training loss: 12.91201114654541, validation loss: 13.638367652893066\n",
            "epoch: 187, training loss: 12.907552719116211, validation loss: 13.63614559173584\n",
            "epoch: 188, training loss: 12.90314769744873, validation loss: 13.633996963500977\n",
            "epoch: 189, training loss: 12.898584365844727, validation loss: 13.631782531738281\n",
            "epoch: 190, training loss: 12.893936157226562, validation loss: 13.629646301269531\n",
            "epoch: 191, training loss: 12.889130592346191, validation loss: 13.62751579284668\n",
            "epoch: 192, training loss: 12.88432502746582, validation loss: 13.625382423400879\n",
            "epoch: 193, training loss: 12.879535675048828, validation loss: 13.623225212097168\n",
            "epoch: 194, training loss: 12.874626159667969, validation loss: 13.621041297912598\n",
            "epoch: 195, training loss: 12.870074272155762, validation loss: 13.619043350219727\n",
            "epoch: 196, training loss: 12.865750312805176, validation loss: 13.616976737976074\n",
            "epoch: 197, training loss: 12.86139965057373, validation loss: 13.615042686462402\n",
            "epoch: 198, training loss: 12.857134819030762, validation loss: 13.613234519958496\n",
            "epoch: 199, training loss: 12.852937698364258, validation loss: 13.611533164978027\n",
            "epoch: 200, training loss: 12.848771095275879, validation loss: 13.60981559753418\n",
            "epoch: 201, training loss: 12.881101608276367, validation loss: 13.567754745483398\n",
            "epoch: 202, training loss: 12.877470970153809, validation loss: 13.566722869873047\n",
            "epoch: 203, training loss: 12.87360668182373, validation loss: 13.56544017791748\n",
            "epoch: 204, training loss: 12.869917869567871, validation loss: 13.563886642456055\n",
            "epoch: 205, training loss: 12.866698265075684, validation loss: 13.561991691589355\n",
            "epoch: 206, training loss: 12.864100456237793, validation loss: 13.559715270996094\n",
            "epoch: 207, training loss: 12.862698554992676, validation loss: 13.556783676147461\n",
            "epoch: 208, training loss: 12.86194896697998, validation loss: 13.553505897521973\n",
            "epoch: 209, training loss: 12.862045288085938, validation loss: 13.550917625427246\n",
            "epoch: 210, training loss: 12.858574867248535, validation loss: 13.549206733703613\n",
            "epoch: 211, training loss: 12.855071067810059, validation loss: 13.547379493713379\n",
            "epoch: 212, training loss: 12.851516723632812, validation loss: 13.545515060424805\n",
            "epoch: 213, training loss: 12.847980499267578, validation loss: 13.543641090393066\n",
            "epoch: 214, training loss: 12.84436321258545, validation loss: 13.541767120361328\n",
            "epoch: 215, training loss: 12.840693473815918, validation loss: 13.539897918701172\n",
            "epoch: 216, training loss: 12.837056159973145, validation loss: 13.538079261779785\n",
            "epoch: 217, training loss: 12.833318710327148, validation loss: 13.536372184753418\n",
            "epoch: 218, training loss: 12.829577445983887, validation loss: 13.534674644470215\n",
            "epoch: 219, training loss: 12.825855255126953, validation loss: 13.532983779907227\n",
            "epoch: 220, training loss: 12.822199821472168, validation loss: 13.531323432922363\n",
            "epoch: 221, training loss: 12.818571090698242, validation loss: 13.52971363067627\n",
            "epoch: 222, training loss: 12.814946174621582, validation loss: 13.528094291687012\n",
            "epoch: 223, training loss: 12.811328887939453, validation loss: 13.526430130004883\n",
            "epoch: 224, training loss: 12.80773639678955, validation loss: 13.524711608886719\n",
            "epoch: 225, training loss: 12.804055213928223, validation loss: 13.522990226745605\n",
            "epoch: 226, training loss: 12.850659370422363, validation loss: 13.490997314453125\n",
            "epoch: 227, training loss: 12.846434593200684, validation loss: 13.490461349487305\n",
            "epoch: 228, training loss: 12.841612815856934, validation loss: 13.48973560333252\n",
            "epoch: 229, training loss: 12.836748123168945, validation loss: 13.488874435424805\n",
            "epoch: 230, training loss: 12.831958770751953, validation loss: 13.487905502319336\n",
            "epoch: 231, training loss: 12.827254295349121, validation loss: 13.486867904663086\n",
            "epoch: 232, training loss: 12.82272720336914, validation loss: 13.485760688781738\n",
            "epoch: 233, training loss: 12.81830883026123, validation loss: 13.484602928161621\n",
            "epoch: 234, training loss: 12.81395149230957, validation loss: 13.483416557312012\n",
            "epoch: 235, training loss: 12.809614181518555, validation loss: 13.482202529907227\n",
            "epoch: 236, training loss: 12.805298805236816, validation loss: 13.48099422454834\n",
            "epoch: 237, training loss: 12.80100154876709, validation loss: 13.479765892028809\n",
            "epoch: 238, training loss: 12.796725273132324, validation loss: 13.478507995605469\n",
            "epoch: 239, training loss: 12.792452812194824, validation loss: 13.477230072021484\n",
            "epoch: 240, training loss: 12.788213729858398, validation loss: 13.47594165802002\n",
            "epoch: 241, training loss: 12.783968925476074, validation loss: 13.47464656829834\n",
            "epoch: 242, training loss: 12.779741287231445, validation loss: 13.473363876342773\n",
            "epoch: 243, training loss: 12.775530815124512, validation loss: 13.472112655639648\n",
            "epoch: 244, training loss: 12.77131175994873, validation loss: 13.470871925354004\n",
            "epoch: 245, training loss: 12.76703929901123, validation loss: 13.469690322875977\n",
            "epoch: 246, training loss: 12.762731552124023, validation loss: 13.468525886535645\n",
            "epoch: 247, training loss: 12.758447647094727, validation loss: 13.46737003326416\n",
            "epoch: 248, training loss: 12.754095077514648, validation loss: 13.466193199157715\n",
            "epoch: 249, training loss: 12.74973201751709, validation loss: 13.465014457702637\n",
            "epoch: 250, training loss: 12.745405197143555, validation loss: 13.463825225830078\n",
            "epoch: 251, training loss: 12.80006217956543, validation loss: 13.448288917541504\n",
            "epoch: 252, training loss: 12.794779777526855, validation loss: 13.447945594787598\n",
            "epoch: 253, training loss: 12.789557456970215, validation loss: 13.4475679397583\n",
            "epoch: 254, training loss: 12.784344673156738, validation loss: 13.446998596191406\n",
            "epoch: 255, training loss: 12.779352188110352, validation loss: 13.446425437927246\n",
            "epoch: 256, training loss: 12.774639129638672, validation loss: 13.445779800415039\n",
            "epoch: 257, training loss: 12.77010440826416, validation loss: 13.445075035095215\n",
            "epoch: 258, training loss: 12.765719413757324, validation loss: 13.444374084472656\n",
            "epoch: 259, training loss: 12.761431694030762, validation loss: 13.443656921386719\n",
            "epoch: 260, training loss: 12.75717830657959, validation loss: 13.442898750305176\n",
            "epoch: 261, training loss: 12.752950668334961, validation loss: 13.442076683044434\n",
            "epoch: 262, training loss: 12.748710632324219, validation loss: 13.44119930267334\n",
            "epoch: 263, training loss: 12.744527816772461, validation loss: 13.440317153930664\n",
            "epoch: 264, training loss: 12.740334510803223, validation loss: 13.439393043518066\n",
            "epoch: 265, training loss: 12.736124038696289, validation loss: 13.43844223022461\n",
            "epoch: 266, training loss: 12.731954574584961, validation loss: 13.437484741210938\n",
            "epoch: 267, training loss: 12.727853775024414, validation loss: 13.436504364013672\n",
            "epoch: 268, training loss: 12.723856925964355, validation loss: 13.435498237609863\n",
            "epoch: 269, training loss: 12.719927787780762, validation loss: 13.434489250183105\n",
            "epoch: 270, training loss: 12.716087341308594, validation loss: 13.433456420898438\n",
            "epoch: 271, training loss: 12.712349891662598, validation loss: 13.432405471801758\n",
            "epoch: 272, training loss: 12.7086820602417, validation loss: 13.431326866149902\n",
            "epoch: 273, training loss: 12.705080032348633, validation loss: 13.430228233337402\n",
            "epoch: 274, training loss: 12.7015380859375, validation loss: 13.429121017456055\n",
            "epoch: 275, training loss: 12.69803237915039, validation loss: 13.427988052368164\n",
            "epoch: 276, training loss: 12.744993209838867, validation loss: 13.42725944519043\n",
            "epoch: 277, training loss: 12.740029335021973, validation loss: 13.426464080810547\n",
            "epoch: 278, training loss: 12.735734939575195, validation loss: 13.425704956054688\n",
            "epoch: 279, training loss: 12.731837272644043, validation loss: 13.424860954284668\n",
            "epoch: 280, training loss: 12.728235244750977, validation loss: 13.423898696899414\n",
            "epoch: 281, training loss: 12.72481918334961, validation loss: 13.422801971435547\n",
            "epoch: 282, training loss: 12.72118854522705, validation loss: 13.421624183654785\n",
            "epoch: 283, training loss: 12.717541694641113, validation loss: 13.420449256896973\n",
            "epoch: 284, training loss: 12.714011192321777, validation loss: 13.419299125671387\n",
            "epoch: 285, training loss: 12.710495948791504, validation loss: 13.418049812316895\n",
            "epoch: 286, training loss: 12.70704460144043, validation loss: 13.41677188873291\n",
            "epoch: 287, training loss: 12.70363998413086, validation loss: 13.415460586547852\n",
            "epoch: 288, training loss: 12.700298309326172, validation loss: 13.414132118225098\n",
            "epoch: 289, training loss: 12.697032928466797, validation loss: 13.412810325622559\n",
            "epoch: 290, training loss: 12.693787574768066, validation loss: 13.411479949951172\n",
            "epoch: 291, training loss: 12.69053840637207, validation loss: 13.410161972045898\n",
            "epoch: 292, training loss: 12.687320709228516, validation loss: 13.408885955810547\n",
            "epoch: 293, training loss: 12.68410873413086, validation loss: 13.407602310180664\n",
            "epoch: 294, training loss: 12.680913925170898, validation loss: 13.406299591064453\n",
            "epoch: 295, training loss: 12.677760124206543, validation loss: 13.405047416687012\n",
            "epoch: 296, training loss: 12.674558639526367, validation loss: 13.403860092163086\n",
            "epoch: 297, training loss: 12.671398162841797, validation loss: 13.402684211730957\n",
            "epoch: 298, training loss: 12.66826057434082, validation loss: 13.401480674743652\n",
            "epoch: 299, training loss: 12.665128707885742, validation loss: 13.400272369384766\n",
            "epoch: 300, training loss: 12.662028312683105, validation loss: 13.399043083190918\n",
            "epoch: 301, training loss: 12.70587158203125, validation loss: 13.405311584472656\n",
            "epoch: 302, training loss: 12.700799942016602, validation loss: 13.404240608215332\n",
            "epoch: 303, training loss: 12.696650505065918, validation loss: 13.403327941894531\n",
            "epoch: 304, training loss: 12.692954063415527, validation loss: 13.402410507202148\n",
            "epoch: 305, training loss: 12.68955135345459, validation loss: 13.401443481445312\n",
            "epoch: 306, training loss: 12.686358451843262, validation loss: 13.400411605834961\n",
            "epoch: 307, training loss: 12.683314323425293, validation loss: 13.399327278137207\n",
            "epoch: 308, training loss: 12.680356979370117, validation loss: 13.398202896118164\n",
            "epoch: 309, training loss: 12.677471160888672, validation loss: 13.3970308303833\n",
            "epoch: 310, training loss: 12.674601554870605, validation loss: 13.395781517028809\n",
            "epoch: 311, training loss: 12.671735763549805, validation loss: 13.394461631774902\n",
            "epoch: 312, training loss: 12.668892860412598, validation loss: 13.393122673034668\n",
            "epoch: 313, training loss: 12.666068077087402, validation loss: 13.391782760620117\n",
            "epoch: 314, training loss: 12.663240432739258, validation loss: 13.390446662902832\n",
            "epoch: 315, training loss: 12.660412788391113, validation loss: 13.389118194580078\n",
            "epoch: 316, training loss: 12.657615661621094, validation loss: 13.387792587280273\n",
            "epoch: 317, training loss: 12.654871940612793, validation loss: 13.386423110961914\n",
            "epoch: 318, training loss: 12.652158737182617, validation loss: 13.385055541992188\n",
            "epoch: 319, training loss: 12.649441719055176, validation loss: 13.383648872375488\n",
            "epoch: 320, training loss: 12.64674186706543, validation loss: 13.382233619689941\n",
            "epoch: 321, training loss: 12.644035339355469, validation loss: 13.380839347839355\n",
            "epoch: 322, training loss: 12.641342163085938, validation loss: 13.379472732543945\n",
            "epoch: 323, training loss: 12.638668060302734, validation loss: 13.378129005432129\n",
            "epoch: 324, training loss: 12.636001586914062, validation loss: 13.376795768737793\n",
            "epoch: 325, training loss: 12.63338851928711, validation loss: 13.37548828125\n",
            "epoch: 326, training loss: 12.678277015686035, validation loss: 13.384735107421875\n",
            "epoch: 327, training loss: 12.673515319824219, validation loss: 13.384061813354492\n",
            "epoch: 328, training loss: 12.669748306274414, validation loss: 13.383502006530762\n",
            "epoch: 329, training loss: 12.666483879089355, validation loss: 13.382874488830566\n",
            "epoch: 330, training loss: 12.663492202758789, validation loss: 13.382206916809082\n",
            "epoch: 331, training loss: 12.660727500915527, validation loss: 13.381487846374512\n",
            "epoch: 332, training loss: 12.658090591430664, validation loss: 13.38071060180664\n",
            "epoch: 333, training loss: 12.65548324584961, validation loss: 13.379831314086914\n",
            "epoch: 334, training loss: 12.652924537658691, validation loss: 13.37887954711914\n",
            "epoch: 335, training loss: 12.650383949279785, validation loss: 13.377877235412598\n",
            "epoch: 336, training loss: 12.647884368896484, validation loss: 13.376908302307129\n",
            "epoch: 337, training loss: 12.645387649536133, validation loss: 13.37595272064209\n",
            "epoch: 338, training loss: 12.642899513244629, validation loss: 13.375009536743164\n",
            "epoch: 339, training loss: 12.640399932861328, validation loss: 13.374046325683594\n",
            "epoch: 340, training loss: 12.637911796569824, validation loss: 13.373082160949707\n",
            "epoch: 341, training loss: 12.635416984558105, validation loss: 13.372103691101074\n",
            "epoch: 342, training loss: 12.6329345703125, validation loss: 13.371095657348633\n",
            "epoch: 343, training loss: 12.630438804626465, validation loss: 13.370079040527344\n",
            "epoch: 344, training loss: 12.627927780151367, validation loss: 13.369053840637207\n",
            "epoch: 345, training loss: 12.625398635864258, validation loss: 13.368021011352539\n",
            "epoch: 346, training loss: 12.622859954833984, validation loss: 13.36699104309082\n",
            "epoch: 347, training loss: 12.620302200317383, validation loss: 13.365921974182129\n",
            "epoch: 348, training loss: 12.617741584777832, validation loss: 13.364831924438477\n",
            "epoch: 349, training loss: 12.615178108215332, validation loss: 13.363741874694824\n",
            "epoch: 350, training loss: 12.612621307373047, validation loss: 13.362655639648438\n",
            "epoch: 351, training loss: 12.655198097229004, validation loss: 13.374981880187988\n",
            "epoch: 352, training loss: 12.650533676147461, validation loss: 13.374494552612305\n",
            "epoch: 353, training loss: 12.646921157836914, validation loss: 13.374066352844238\n",
            "epoch: 354, training loss: 12.64378547668457, validation loss: 13.373546600341797\n",
            "epoch: 355, training loss: 12.64084529876709, validation loss: 13.37283992767334\n",
            "epoch: 356, training loss: 12.638043403625488, validation loss: 13.37204647064209\n",
            "epoch: 357, training loss: 12.635369300842285, validation loss: 13.371195793151855\n",
            "epoch: 358, training loss: 12.632773399353027, validation loss: 13.370312690734863\n",
            "epoch: 359, training loss: 12.630197525024414, validation loss: 13.369426727294922\n",
            "epoch: 360, training loss: 12.627677917480469, validation loss: 13.368508338928223\n",
            "epoch: 361, training loss: 12.625167846679688, validation loss: 13.367572784423828\n",
            "epoch: 362, training loss: 12.622689247131348, validation loss: 13.366592407226562\n",
            "epoch: 363, training loss: 12.620201110839844, validation loss: 13.365528106689453\n",
            "epoch: 364, training loss: 12.617721557617188, validation loss: 13.364439010620117\n",
            "epoch: 365, training loss: 12.615270614624023, validation loss: 13.363348007202148\n",
            "epoch: 366, training loss: 12.612826347351074, validation loss: 13.362227439880371\n",
            "epoch: 367, training loss: 12.610372543334961, validation loss: 13.361095428466797\n",
            "epoch: 368, training loss: 12.607935905456543, validation loss: 13.35995864868164\n",
            "epoch: 369, training loss: 12.605504035949707, validation loss: 13.358806610107422\n",
            "epoch: 370, training loss: 12.603090286254883, validation loss: 13.357646942138672\n",
            "epoch: 371, training loss: 12.600685119628906, validation loss: 13.356481552124023\n",
            "epoch: 372, training loss: 12.598291397094727, validation loss: 13.35529613494873\n",
            "epoch: 373, training loss: 12.595924377441406, validation loss: 13.354101181030273\n",
            "epoch: 374, training loss: 12.593589782714844, validation loss: 13.35290241241455\n",
            "epoch: 375, training loss: 12.5912504196167, validation loss: 13.351706504821777\n",
            "epoch: 376, training loss: 12.624256134033203, validation loss: 13.367142677307129\n",
            "epoch: 377, training loss: 12.620122909545898, validation loss: 13.36580753326416\n",
            "epoch: 378, training loss: 12.61691665649414, validation loss: 13.364723205566406\n",
            "epoch: 379, training loss: 12.6141357421875, validation loss: 13.36365795135498\n",
            "epoch: 380, training loss: 12.611572265625, validation loss: 13.362590789794922\n",
            "epoch: 381, training loss: 12.609158515930176, validation loss: 13.361515998840332\n",
            "epoch: 382, training loss: 12.606833457946777, validation loss: 13.360443115234375\n",
            "epoch: 383, training loss: 12.604575157165527, validation loss: 13.359352111816406\n",
            "epoch: 384, training loss: 12.602339744567871, validation loss: 13.35826301574707\n",
            "epoch: 385, training loss: 12.600122451782227, validation loss: 13.35716724395752\n",
            "epoch: 386, training loss: 12.59793758392334, validation loss: 13.356073379516602\n",
            "epoch: 387, training loss: 12.595759391784668, validation loss: 13.354970932006836\n",
            "epoch: 388, training loss: 12.593602180480957, validation loss: 13.353872299194336\n",
            "epoch: 389, training loss: 12.591435432434082, validation loss: 13.352779388427734\n",
            "epoch: 390, training loss: 12.589288711547852, validation loss: 13.351683616638184\n",
            "epoch: 391, training loss: 12.587128639221191, validation loss: 13.350597381591797\n",
            "epoch: 392, training loss: 12.584968566894531, validation loss: 13.349512100219727\n",
            "epoch: 393, training loss: 12.582849502563477, validation loss: 13.348417282104492\n",
            "epoch: 394, training loss: 12.580738067626953, validation loss: 13.34733772277832\n",
            "epoch: 395, training loss: 12.578621864318848, validation loss: 13.346253395080566\n",
            "epoch: 396, training loss: 12.576497077941895, validation loss: 13.345181465148926\n",
            "epoch: 397, training loss: 12.57437515258789, validation loss: 13.34412670135498\n",
            "epoch: 398, training loss: 12.572235107421875, validation loss: 13.343057632446289\n",
            "epoch: 399, training loss: 12.570098876953125, validation loss: 13.342009544372559\n",
            "epoch: 400, training loss: 12.567947387695312, validation loss: 13.340970039367676\n",
            "epoch: 401, training loss: 12.58415412902832, validation loss: 13.356751441955566\n",
            "epoch: 402, training loss: 12.580793380737305, validation loss: 13.355169296264648\n",
            "epoch: 403, training loss: 12.57815933227539, validation loss: 13.354036331176758\n",
            "epoch: 404, training loss: 12.575834274291992, validation loss: 13.353046417236328\n",
            "epoch: 405, training loss: 12.5736722946167, validation loss: 13.352117538452148\n",
            "epoch: 406, training loss: 12.571579933166504, validation loss: 13.351197242736816\n",
            "epoch: 407, training loss: 12.569539070129395, validation loss: 13.350289344787598\n",
            "epoch: 408, training loss: 12.567543983459473, validation loss: 13.34938907623291\n",
            "epoch: 409, training loss: 12.565592765808105, validation loss: 13.34849739074707\n",
            "epoch: 410, training loss: 12.56365966796875, validation loss: 13.34761905670166\n",
            "epoch: 411, training loss: 12.56174373626709, validation loss: 13.346747398376465\n",
            "epoch: 412, training loss: 12.559834480285645, validation loss: 13.34587287902832\n",
            "epoch: 413, training loss: 12.557927131652832, validation loss: 13.345013618469238\n",
            "epoch: 414, training loss: 12.556035995483398, validation loss: 13.344168663024902\n",
            "epoch: 415, training loss: 12.554145812988281, validation loss: 13.343328475952148\n",
            "epoch: 416, training loss: 12.552248001098633, validation loss: 13.342497825622559\n",
            "epoch: 417, training loss: 12.550358772277832, validation loss: 13.34167194366455\n",
            "epoch: 418, training loss: 12.548482894897461, validation loss: 13.34084701538086\n",
            "epoch: 419, training loss: 12.54661750793457, validation loss: 13.3400297164917\n",
            "epoch: 420, training loss: 12.544756889343262, validation loss: 13.339218139648438\n",
            "epoch: 421, training loss: 12.54289722442627, validation loss: 13.338411331176758\n",
            "epoch: 422, training loss: 12.541027069091797, validation loss: 13.337602615356445\n",
            "epoch: 423, training loss: 12.539159774780273, validation loss: 13.336799621582031\n",
            "epoch: 424, training loss: 12.537303924560547, validation loss: 13.336016654968262\n",
            "epoch: 425, training loss: 12.535443305969238, validation loss: 13.335232734680176\n",
            "epoch: 426, training loss: 12.532535552978516, validation loss: 13.347298622131348\n",
            "epoch: 427, training loss: 12.5299711227417, validation loss: 13.345918655395508\n",
            "epoch: 428, training loss: 12.527935028076172, validation loss: 13.344963073730469\n",
            "epoch: 429, training loss: 12.526093482971191, validation loss: 13.344147682189941\n",
            "epoch: 430, training loss: 12.52435302734375, validation loss: 13.343390464782715\n",
            "epoch: 431, training loss: 12.52261734008789, validation loss: 13.342655181884766\n",
            "epoch: 432, training loss: 12.520914077758789, validation loss: 13.34192943572998\n",
            "epoch: 433, training loss: 12.519216537475586, validation loss: 13.341209411621094\n",
            "epoch: 434, training loss: 12.517534255981445, validation loss: 13.340487480163574\n",
            "epoch: 435, training loss: 12.515856742858887, validation loss: 13.339776039123535\n",
            "epoch: 436, training loss: 12.514175415039062, validation loss: 13.339080810546875\n",
            "epoch: 437, training loss: 12.512496948242188, validation loss: 13.338393211364746\n",
            "epoch: 438, training loss: 12.510822296142578, validation loss: 13.337729454040527\n",
            "epoch: 439, training loss: 12.509137153625488, validation loss: 13.337055206298828\n",
            "epoch: 440, training loss: 12.507447242736816, validation loss: 13.336392402648926\n",
            "epoch: 441, training loss: 12.505772590637207, validation loss: 13.33574104309082\n",
            "epoch: 442, training loss: 12.504096031188965, validation loss: 13.335098266601562\n",
            "epoch: 443, training loss: 12.502411842346191, validation loss: 13.334444999694824\n",
            "epoch: 444, training loss: 12.500722885131836, validation loss: 13.333805084228516\n",
            "epoch: 445, training loss: 12.49903392791748, validation loss: 13.333174705505371\n",
            "epoch: 446, training loss: 12.497344970703125, validation loss: 13.332536697387695\n",
            "epoch: 447, training loss: 12.4956636428833, validation loss: 13.331916809082031\n",
            "epoch: 448, training loss: 12.493980407714844, validation loss: 13.331302642822266\n",
            "epoch: 449, training loss: 12.492317199707031, validation loss: 13.330698013305664\n",
            "epoch: 450, training loss: 12.49064826965332, validation loss: 13.33008861541748\n",
            "epoch: 451, training loss: 12.472272872924805, validation loss: 13.335165977478027\n",
            "epoch: 452, training loss: 12.470304489135742, validation loss: 13.334038734436035\n",
            "epoch: 453, training loss: 12.46875286102295, validation loss: 13.333300590515137\n",
            "epoch: 454, training loss: 12.467297554016113, validation loss: 13.33268928527832\n",
            "epoch: 455, training loss: 12.465872764587402, validation loss: 13.332139015197754\n",
            "epoch: 456, training loss: 12.464444160461426, validation loss: 13.331618309020996\n",
            "epoch: 457, training loss: 12.463019371032715, validation loss: 13.331107139587402\n",
            "epoch: 458, training loss: 12.46157169342041, validation loss: 13.330615997314453\n",
            "epoch: 459, training loss: 12.460131645202637, validation loss: 13.330121994018555\n",
            "epoch: 460, training loss: 12.458659172058105, validation loss: 13.329608917236328\n",
            "epoch: 461, training loss: 12.457191467285156, validation loss: 13.329109191894531\n",
            "epoch: 462, training loss: 12.455705642700195, validation loss: 13.32861042022705\n",
            "epoch: 463, training loss: 12.454216003417969, validation loss: 13.328108787536621\n",
            "epoch: 464, training loss: 12.452740669250488, validation loss: 13.327610969543457\n",
            "epoch: 465, training loss: 12.451251983642578, validation loss: 13.327110290527344\n",
            "epoch: 466, training loss: 12.449759483337402, validation loss: 13.326605796813965\n",
            "epoch: 467, training loss: 12.448284149169922, validation loss: 13.326106071472168\n",
            "epoch: 468, training loss: 12.446803092956543, validation loss: 13.32561206817627\n",
            "epoch: 469, training loss: 12.445328712463379, validation loss: 13.325105667114258\n",
            "epoch: 470, training loss: 12.443840026855469, validation loss: 13.324613571166992\n",
            "epoch: 471, training loss: 12.44235610961914, validation loss: 13.324117660522461\n",
            "epoch: 472, training loss: 12.44086742401123, validation loss: 13.32363510131836\n",
            "epoch: 473, training loss: 12.439387321472168, validation loss: 13.323150634765625\n",
            "epoch: 474, training loss: 12.437904357910156, validation loss: 13.322674751281738\n",
            "epoch: 475, training loss: 12.436408996582031, validation loss: 13.322197914123535\n",
            "epoch: 476, training loss: 12.410670280456543, validation loss: 13.32092571258545\n",
            "epoch: 477, training loss: 12.408992767333984, validation loss: 13.320039749145508\n",
            "epoch: 478, training loss: 12.407666206359863, validation loss: 13.319483757019043\n",
            "epoch: 479, training loss: 12.40644645690918, validation loss: 13.3190336227417\n",
            "epoch: 480, training loss: 12.405243873596191, validation loss: 13.318615913391113\n",
            "epoch: 481, training loss: 12.404031753540039, validation loss: 13.318212509155273\n",
            "epoch: 482, training loss: 12.402822494506836, validation loss: 13.317817687988281\n",
            "epoch: 483, training loss: 12.401577949523926, validation loss: 13.317431449890137\n",
            "epoch: 484, training loss: 12.400330543518066, validation loss: 13.317046165466309\n",
            "epoch: 485, training loss: 12.399062156677246, validation loss: 13.31665325164795\n",
            "epoch: 486, training loss: 12.397788047790527, validation loss: 13.31626033782959\n",
            "epoch: 487, training loss: 12.396501541137695, validation loss: 13.31586742401123\n",
            "epoch: 488, training loss: 12.395218849182129, validation loss: 13.315475463867188\n",
            "epoch: 489, training loss: 12.39392375946045, validation loss: 13.315082550048828\n",
            "epoch: 490, training loss: 12.392614364624023, validation loss: 13.314687728881836\n",
            "epoch: 491, training loss: 12.391310691833496, validation loss: 13.314282417297363\n",
            "epoch: 492, training loss: 12.389986991882324, validation loss: 13.313882827758789\n",
            "epoch: 493, training loss: 12.388667106628418, validation loss: 13.313471794128418\n",
            "epoch: 494, training loss: 12.387335777282715, validation loss: 13.313074111938477\n",
            "epoch: 495, training loss: 12.386007308959961, validation loss: 13.3126802444458\n",
            "epoch: 496, training loss: 12.384653091430664, validation loss: 13.312278747558594\n",
            "epoch: 497, training loss: 12.383312225341797, validation loss: 13.311887741088867\n",
            "epoch: 498, training loss: 12.38196849822998, validation loss: 13.311493873596191\n",
            "epoch: 499, training loss: 12.380602836608887, validation loss: 13.311102867126465\n",
            "epoch: 500, training loss: 12.379236221313477, validation loss: 13.310709953308105\n",
            "Predictions for miami generated!\n",
            "\n",
            "Done printing miami predictions\n",
            "----------------------------------------------------------------------\n",
            "epoch: 1, training loss: 26.751134872436523, validation loss: 19.06188201904297\n",
            "epoch: 2, training loss: 25.651315689086914, validation loss: 18.94768524169922\n",
            "epoch: 3, training loss: 24.875885009765625, validation loss: 18.9746036529541\n",
            "epoch: 4, training loss: 24.273738861083984, validation loss: 19.05145835876465\n",
            "epoch: 5, training loss: 23.779747009277344, validation loss: 19.15985870361328\n",
            "epoch: 6, training loss: 23.35999870300293, validation loss: 19.29347038269043\n",
            "epoch: 7, training loss: 22.994720458984375, validation loss: 19.439437866210938\n",
            "epoch: 8, training loss: 22.67097282409668, validation loss: 19.584747314453125\n",
            "epoch: 9, training loss: 22.38105583190918, validation loss: 19.71268653869629\n",
            "epoch: 10, training loss: 22.11980438232422, validation loss: 19.81935691833496\n",
            "epoch: 11, training loss: 21.88330078125, validation loss: 19.9089298248291\n",
            "epoch: 12, training loss: 21.67019271850586, validation loss: 19.981168746948242\n",
            "epoch: 13, training loss: 21.473770141601562, validation loss: 20.042659759521484\n",
            "epoch: 14, training loss: 21.290695190429688, validation loss: 20.094751358032227\n",
            "epoch: 15, training loss: 21.118940353393555, validation loss: 20.14146614074707\n",
            "epoch: 16, training loss: 20.957080841064453, validation loss: 20.180566787719727\n",
            "epoch: 17, training loss: 20.801902770996094, validation loss: 20.214893341064453\n",
            "epoch: 18, training loss: 20.651287078857422, validation loss: 20.243953704833984\n",
            "epoch: 19, training loss: 20.505929946899414, validation loss: 20.270565032958984\n",
            "epoch: 20, training loss: 20.3643798828125, validation loss: 20.29319953918457\n",
            "epoch: 21, training loss: 20.22627830505371, validation loss: 20.3128662109375\n",
            "epoch: 22, training loss: 20.09355926513672, validation loss: 20.332294464111328\n",
            "epoch: 23, training loss: 19.96517562866211, validation loss: 20.351289749145508\n",
            "epoch: 24, training loss: 19.84051513671875, validation loss: 20.368005752563477\n",
            "epoch: 25, training loss: 19.7180233001709, validation loss: 20.382354736328125\n",
            "epoch: 26, training loss: 19.62359619140625, validation loss: 20.426555633544922\n",
            "epoch: 27, training loss: 19.515117645263672, validation loss: 20.435028076171875\n",
            "epoch: 28, training loss: 19.408124923706055, validation loss: 20.439828872680664\n",
            "epoch: 29, training loss: 19.303813934326172, validation loss: 20.440746307373047\n",
            "epoch: 30, training loss: 19.201860427856445, validation loss: 20.438461303710938\n",
            "epoch: 31, training loss: 19.102949142456055, validation loss: 20.432266235351562\n",
            "epoch: 32, training loss: 19.007347106933594, validation loss: 20.422943115234375\n",
            "epoch: 33, training loss: 18.914592742919922, validation loss: 20.410930633544922\n",
            "epoch: 34, training loss: 18.82438087463379, validation loss: 20.39638328552246\n",
            "epoch: 35, training loss: 18.736413955688477, validation loss: 20.379837036132812\n",
            "epoch: 36, training loss: 18.649818420410156, validation loss: 20.36150360107422\n",
            "epoch: 37, training loss: 18.565387725830078, validation loss: 20.3414249420166\n",
            "epoch: 38, training loss: 18.482620239257812, validation loss: 20.319896697998047\n",
            "epoch: 39, training loss: 18.40133285522461, validation loss: 20.297199249267578\n",
            "epoch: 40, training loss: 18.322521209716797, validation loss: 20.273391723632812\n",
            "epoch: 41, training loss: 18.247222900390625, validation loss: 20.248634338378906\n",
            "epoch: 42, training loss: 18.175127029418945, validation loss: 20.222898483276367\n",
            "epoch: 43, training loss: 18.10528564453125, validation loss: 20.197322845458984\n",
            "epoch: 44, training loss: 18.03709602355957, validation loss: 20.171215057373047\n",
            "epoch: 45, training loss: 17.970548629760742, validation loss: 20.14429473876953\n",
            "epoch: 46, training loss: 17.905441284179688, validation loss: 20.117429733276367\n",
            "epoch: 47, training loss: 17.841835021972656, validation loss: 20.089677810668945\n",
            "epoch: 48, training loss: 17.77967071533203, validation loss: 20.061864852905273\n",
            "epoch: 49, training loss: 17.71902084350586, validation loss: 20.034196853637695\n",
            "epoch: 50, training loss: 17.659809112548828, validation loss: 20.006568908691406\n",
            "epoch: 51, training loss: 17.61749839782715, validation loss: 20.018192291259766\n",
            "epoch: 52, training loss: 17.563419342041016, validation loss: 19.995325088500977\n",
            "epoch: 53, training loss: 17.510149002075195, validation loss: 19.971649169921875\n",
            "epoch: 54, training loss: 17.457984924316406, validation loss: 19.947568893432617\n",
            "epoch: 55, training loss: 17.40670394897461, validation loss: 19.923686981201172\n",
            "epoch: 56, training loss: 17.355693817138672, validation loss: 19.900556564331055\n",
            "epoch: 57, training loss: 17.30499267578125, validation loss: 19.878293991088867\n",
            "epoch: 58, training loss: 17.254745483398438, validation loss: 19.856945037841797\n",
            "epoch: 59, training loss: 17.20480728149414, validation loss: 19.836217880249023\n",
            "epoch: 60, training loss: 17.155088424682617, validation loss: 19.815536499023438\n",
            "epoch: 61, training loss: 17.105594635009766, validation loss: 19.794763565063477\n",
            "epoch: 62, training loss: 17.056428909301758, validation loss: 19.773679733276367\n",
            "epoch: 63, training loss: 17.007831573486328, validation loss: 19.751726150512695\n",
            "epoch: 64, training loss: 16.959474563598633, validation loss: 19.72958755493164\n",
            "epoch: 65, training loss: 16.911502838134766, validation loss: 19.707246780395508\n",
            "epoch: 66, training loss: 16.86396026611328, validation loss: 19.68476676940918\n",
            "epoch: 67, training loss: 16.816749572753906, validation loss: 19.66242790222168\n",
            "epoch: 68, training loss: 16.769691467285156, validation loss: 19.640466690063477\n",
            "epoch: 69, training loss: 16.722898483276367, validation loss: 19.619173049926758\n",
            "epoch: 70, training loss: 16.676572799682617, validation loss: 19.598283767700195\n",
            "epoch: 71, training loss: 16.6307430267334, validation loss: 19.577455520629883\n",
            "epoch: 72, training loss: 16.585485458374023, validation loss: 19.55673599243164\n",
            "epoch: 73, training loss: 16.540699005126953, validation loss: 19.536081314086914\n",
            "epoch: 74, training loss: 16.49635124206543, validation loss: 19.515836715698242\n",
            "epoch: 75, training loss: 16.452348709106445, validation loss: 19.495391845703125\n",
            "epoch: 76, training loss: 16.423568725585938, validation loss: 19.49553108215332\n",
            "epoch: 77, training loss: 16.383182525634766, validation loss: 19.477874755859375\n",
            "epoch: 78, training loss: 16.34352684020996, validation loss: 19.459426879882812\n",
            "epoch: 79, training loss: 16.304767608642578, validation loss: 19.440202713012695\n",
            "epoch: 80, training loss: 16.266643524169922, validation loss: 19.420324325561523\n",
            "epoch: 81, training loss: 16.22911834716797, validation loss: 19.39979362487793\n",
            "epoch: 82, training loss: 16.192136764526367, validation loss: 19.379150390625\n",
            "epoch: 83, training loss: 16.155614852905273, validation loss: 19.358360290527344\n",
            "epoch: 84, training loss: 16.11940574645996, validation loss: 19.337953567504883\n",
            "epoch: 85, training loss: 16.083541870117188, validation loss: 19.317712783813477\n",
            "epoch: 86, training loss: 16.048381805419922, validation loss: 19.297609329223633\n",
            "epoch: 87, training loss: 16.013713836669922, validation loss: 19.277698516845703\n",
            "epoch: 88, training loss: 15.97960090637207, validation loss: 19.257858276367188\n",
            "epoch: 89, training loss: 15.945817947387695, validation loss: 19.2382755279541\n",
            "epoch: 90, training loss: 15.912433624267578, validation loss: 19.218915939331055\n",
            "epoch: 91, training loss: 15.87936019897461, validation loss: 19.199838638305664\n",
            "epoch: 92, training loss: 15.846611022949219, validation loss: 19.181129455566406\n",
            "epoch: 93, training loss: 15.814225196838379, validation loss: 19.162424087524414\n",
            "epoch: 94, training loss: 15.78203296661377, validation loss: 19.14405059814453\n",
            "epoch: 95, training loss: 15.74998664855957, validation loss: 19.126056671142578\n",
            "epoch: 96, training loss: 15.718087196350098, validation loss: 19.10861587524414\n",
            "epoch: 97, training loss: 15.686454772949219, validation loss: 19.091169357299805\n",
            "epoch: 98, training loss: 15.655126571655273, validation loss: 19.073780059814453\n",
            "epoch: 99, training loss: 15.623902320861816, validation loss: 19.05680274963379\n",
            "epoch: 100, training loss: 15.592719078063965, validation loss: 19.04022216796875\n",
            "epoch: 101, training loss: 15.57390022277832, validation loss: 19.022289276123047\n",
            "epoch: 102, training loss: 15.544788360595703, validation loss: 19.009580612182617\n",
            "epoch: 103, training loss: 15.51608657836914, validation loss: 18.99635124206543\n",
            "epoch: 104, training loss: 15.487730026245117, validation loss: 18.982723236083984\n",
            "epoch: 105, training loss: 15.459630966186523, validation loss: 18.968791961669922\n",
            "epoch: 106, training loss: 15.431673049926758, validation loss: 18.95479393005371\n",
            "epoch: 107, training loss: 15.403874397277832, validation loss: 18.940811157226562\n",
            "epoch: 108, training loss: 15.3762788772583, validation loss: 18.926727294921875\n",
            "epoch: 109, training loss: 15.348840713500977, validation loss: 18.912643432617188\n",
            "epoch: 110, training loss: 15.321549415588379, validation loss: 18.898780822753906\n",
            "epoch: 111, training loss: 15.294486999511719, validation loss: 18.884958267211914\n",
            "epoch: 112, training loss: 15.267526626586914, validation loss: 18.871166229248047\n",
            "epoch: 113, training loss: 15.240690231323242, validation loss: 18.857616424560547\n",
            "epoch: 114, training loss: 15.21403694152832, validation loss: 18.84400177001953\n",
            "epoch: 115, training loss: 15.187661170959473, validation loss: 18.830312728881836\n",
            "epoch: 116, training loss: 15.161859512329102, validation loss: 18.816492080688477\n",
            "epoch: 117, training loss: 15.136335372924805, validation loss: 18.80278778076172\n",
            "epoch: 118, training loss: 15.110990524291992, validation loss: 18.789140701293945\n",
            "epoch: 119, training loss: 15.085881233215332, validation loss: 18.775510787963867\n",
            "epoch: 120, training loss: 15.060955047607422, validation loss: 18.761913299560547\n",
            "epoch: 121, training loss: 15.03620719909668, validation loss: 18.748294830322266\n",
            "epoch: 122, training loss: 15.011638641357422, validation loss: 18.734779357910156\n",
            "epoch: 123, training loss: 14.987192153930664, validation loss: 18.721397399902344\n",
            "epoch: 124, training loss: 14.96286392211914, validation loss: 18.70802879333496\n",
            "epoch: 125, training loss: 14.938607215881348, validation loss: 18.694717407226562\n",
            "epoch: 126, training loss: 14.923853874206543, validation loss: 18.660892486572266\n",
            "epoch: 127, training loss: 14.900880813598633, validation loss: 18.650556564331055\n",
            "epoch: 128, training loss: 14.878399848937988, validation loss: 18.639795303344727\n",
            "epoch: 129, training loss: 14.85627555847168, validation loss: 18.628660202026367\n",
            "epoch: 130, training loss: 14.834395408630371, validation loss: 18.617206573486328\n",
            "epoch: 131, training loss: 14.812702178955078, validation loss: 18.60556983947754\n",
            "epoch: 132, training loss: 14.791116714477539, validation loss: 18.59380340576172\n",
            "epoch: 133, training loss: 14.769651412963867, validation loss: 18.582054138183594\n",
            "epoch: 134, training loss: 14.748298645019531, validation loss: 18.570255279541016\n",
            "epoch: 135, training loss: 14.727100372314453, validation loss: 18.55834197998047\n",
            "epoch: 136, training loss: 14.706077575683594, validation loss: 18.546367645263672\n",
            "epoch: 137, training loss: 14.68521785736084, validation loss: 18.534263610839844\n",
            "epoch: 138, training loss: 14.664505004882812, validation loss: 18.52210807800293\n",
            "epoch: 139, training loss: 14.64390754699707, validation loss: 18.509918212890625\n",
            "epoch: 140, training loss: 14.62341594696045, validation loss: 18.497745513916016\n",
            "epoch: 141, training loss: 14.60299301147461, validation loss: 18.485567092895508\n",
            "epoch: 142, training loss: 14.58261775970459, validation loss: 18.473356246948242\n",
            "epoch: 143, training loss: 14.562334060668945, validation loss: 18.46118927001953\n",
            "epoch: 144, training loss: 14.542163848876953, validation loss: 18.449050903320312\n",
            "epoch: 145, training loss: 14.522068977355957, validation loss: 18.436920166015625\n",
            "epoch: 146, training loss: 14.502148628234863, validation loss: 18.424638748168945\n",
            "epoch: 147, training loss: 14.482295036315918, validation loss: 18.41249656677246\n",
            "epoch: 148, training loss: 14.462510108947754, validation loss: 18.400480270385742\n",
            "epoch: 149, training loss: 14.442896842956543, validation loss: 18.38838005065918\n",
            "epoch: 150, training loss: 14.423446655273438, validation loss: 18.376384735107422\n",
            "epoch: 151, training loss: 14.409985542297363, validation loss: 18.333892822265625\n",
            "epoch: 152, training loss: 14.391420364379883, validation loss: 18.324687957763672\n",
            "epoch: 153, training loss: 14.37341594696045, validation loss: 18.314943313598633\n",
            "epoch: 154, training loss: 14.355866432189941, validation loss: 18.304838180541992\n",
            "epoch: 155, training loss: 14.338664054870605, validation loss: 18.2945613861084\n",
            "epoch: 156, training loss: 14.32171630859375, validation loss: 18.28419303894043\n",
            "epoch: 157, training loss: 14.304965019226074, validation loss: 18.27375602722168\n",
            "epoch: 158, training loss: 14.288412094116211, validation loss: 18.263277053833008\n",
            "epoch: 159, training loss: 14.271990776062012, validation loss: 18.25278091430664\n",
            "epoch: 160, training loss: 14.255746841430664, validation loss: 18.24227523803711\n",
            "epoch: 161, training loss: 14.239678382873535, validation loss: 18.231718063354492\n",
            "epoch: 162, training loss: 14.22375774383545, validation loss: 18.221242904663086\n",
            "epoch: 163, training loss: 14.207939147949219, validation loss: 18.21080780029297\n",
            "epoch: 164, training loss: 14.192216873168945, validation loss: 18.20051383972168\n",
            "epoch: 165, training loss: 14.176633834838867, validation loss: 18.19022560119629\n",
            "epoch: 166, training loss: 14.161165237426758, validation loss: 18.179948806762695\n",
            "epoch: 167, training loss: 14.145821571350098, validation loss: 18.169771194458008\n",
            "epoch: 168, training loss: 14.130568504333496, validation loss: 18.159591674804688\n",
            "epoch: 169, training loss: 14.115436553955078, validation loss: 18.14948844909668\n",
            "epoch: 170, training loss: 14.100430488586426, validation loss: 18.13926887512207\n",
            "epoch: 171, training loss: 14.08556079864502, validation loss: 18.128986358642578\n",
            "epoch: 172, training loss: 14.070840835571289, validation loss: 18.118656158447266\n",
            "epoch: 173, training loss: 14.056198120117188, validation loss: 18.10840606689453\n",
            "epoch: 174, training loss: 14.041633605957031, validation loss: 18.098167419433594\n",
            "epoch: 175, training loss: 14.027195930480957, validation loss: 18.087907791137695\n",
            "epoch: 176, training loss: 14.015186309814453, validation loss: 18.04351234436035\n",
            "epoch: 177, training loss: 14.001387596130371, validation loss: 18.035470962524414\n",
            "epoch: 178, training loss: 13.988061904907227, validation loss: 18.02682113647461\n",
            "epoch: 179, training loss: 13.975049018859863, validation loss: 18.017913818359375\n",
            "epoch: 180, training loss: 13.962250709533691, validation loss: 18.008861541748047\n",
            "epoch: 181, training loss: 13.949605941772461, validation loss: 17.999731063842773\n",
            "epoch: 182, training loss: 13.937081336975098, validation loss: 17.99055290222168\n",
            "epoch: 183, training loss: 13.924657821655273, validation loss: 17.981307983398438\n",
            "epoch: 184, training loss: 13.912378311157227, validation loss: 17.971914291381836\n",
            "epoch: 185, training loss: 13.900175094604492, validation loss: 17.962522506713867\n",
            "epoch: 186, training loss: 13.888065338134766, validation loss: 17.953052520751953\n",
            "epoch: 187, training loss: 13.876063346862793, validation loss: 17.94361114501953\n",
            "epoch: 188, training loss: 13.86413288116455, validation loss: 17.933923721313477\n",
            "epoch: 189, training loss: 13.852256774902344, validation loss: 17.924312591552734\n",
            "epoch: 190, training loss: 13.840409278869629, validation loss: 17.914772033691406\n",
            "epoch: 191, training loss: 13.828646659851074, validation loss: 17.905305862426758\n",
            "epoch: 192, training loss: 13.816896438598633, validation loss: 17.895849227905273\n",
            "epoch: 193, training loss: 13.805209159851074, validation loss: 17.886463165283203\n",
            "epoch: 194, training loss: 13.793590545654297, validation loss: 17.877044677734375\n",
            "epoch: 195, training loss: 13.781989097595215, validation loss: 17.867605209350586\n",
            "epoch: 196, training loss: 13.770430564880371, validation loss: 17.85803985595703\n",
            "epoch: 197, training loss: 13.758917808532715, validation loss: 17.84847640991211\n",
            "epoch: 198, training loss: 13.747437477111816, validation loss: 17.83898162841797\n",
            "epoch: 199, training loss: 13.736039161682129, validation loss: 17.82945442199707\n",
            "epoch: 200, training loss: 13.724668502807617, validation loss: 17.819881439208984\n",
            "epoch: 201, training loss: 13.711419105529785, validation loss: 17.780780792236328\n",
            "epoch: 202, training loss: 13.700424194335938, validation loss: 17.773502349853516\n",
            "epoch: 203, training loss: 13.689811706542969, validation loss: 17.76548194885254\n",
            "epoch: 204, training loss: 13.679468154907227, validation loss: 17.75725555419922\n",
            "epoch: 205, training loss: 13.66929817199707, validation loss: 17.74898910522461\n",
            "epoch: 206, training loss: 13.65925121307373, validation loss: 17.740642547607422\n",
            "epoch: 207, training loss: 13.649299621582031, validation loss: 17.732322692871094\n",
            "epoch: 208, training loss: 13.639446258544922, validation loss: 17.7239990234375\n",
            "epoch: 209, training loss: 13.629663467407227, validation loss: 17.71564292907715\n",
            "epoch: 210, training loss: 13.619948387145996, validation loss: 17.7072811126709\n",
            "epoch: 211, training loss: 13.61032485961914, validation loss: 17.69889259338379\n",
            "epoch: 212, training loss: 13.600716590881348, validation loss: 17.69058609008789\n",
            "epoch: 213, training loss: 13.591147422790527, validation loss: 17.682344436645508\n",
            "epoch: 214, training loss: 13.58163070678711, validation loss: 17.6741943359375\n",
            "epoch: 215, training loss: 13.5721435546875, validation loss: 17.666061401367188\n",
            "epoch: 216, training loss: 13.562704086303711, validation loss: 17.657949447631836\n",
            "epoch: 217, training loss: 13.553308486938477, validation loss: 17.649900436401367\n",
            "epoch: 218, training loss: 13.543963432312012, validation loss: 17.641923904418945\n",
            "epoch: 219, training loss: 13.534634590148926, validation loss: 17.634008407592773\n",
            "epoch: 220, training loss: 13.525346755981445, validation loss: 17.626148223876953\n",
            "epoch: 221, training loss: 13.516072273254395, validation loss: 17.61826515197754\n",
            "epoch: 222, training loss: 13.50683307647705, validation loss: 17.61042022705078\n",
            "epoch: 223, training loss: 13.497599601745605, validation loss: 17.60256576538086\n",
            "epoch: 224, training loss: 13.48838996887207, validation loss: 17.594707489013672\n",
            "epoch: 225, training loss: 13.479225158691406, validation loss: 17.58682632446289\n",
            "epoch: 226, training loss: 13.464699745178223, validation loss: 17.557247161865234\n",
            "epoch: 227, training loss: 13.455704689025879, validation loss: 17.551576614379883\n",
            "epoch: 228, training loss: 13.447086334228516, validation loss: 17.5450382232666\n",
            "epoch: 229, training loss: 13.4386568069458, validation loss: 17.53827667236328\n",
            "epoch: 230, training loss: 13.430418968200684, validation loss: 17.5313777923584\n",
            "epoch: 231, training loss: 13.422301292419434, validation loss: 17.524351119995117\n",
            "epoch: 232, training loss: 13.414253234863281, validation loss: 17.517332077026367\n",
            "epoch: 233, training loss: 13.40627670288086, validation loss: 17.510295867919922\n",
            "epoch: 234, training loss: 13.398332595825195, validation loss: 17.5032958984375\n",
            "epoch: 235, training loss: 13.390417098999023, validation loss: 17.496313095092773\n",
            "epoch: 236, training loss: 13.382577896118164, validation loss: 17.48931312561035\n",
            "epoch: 237, training loss: 13.374756813049316, validation loss: 17.48228645324707\n",
            "epoch: 238, training loss: 13.366969108581543, validation loss: 17.475311279296875\n",
            "epoch: 239, training loss: 13.359197616577148, validation loss: 17.468385696411133\n",
            "epoch: 240, training loss: 13.35146713256836, validation loss: 17.46153450012207\n",
            "epoch: 241, training loss: 13.34374713897705, validation loss: 17.45471954345703\n",
            "epoch: 242, training loss: 13.336077690124512, validation loss: 17.447919845581055\n",
            "epoch: 243, training loss: 13.328414916992188, validation loss: 17.44126319885254\n",
            "epoch: 244, training loss: 13.32077407836914, validation loss: 17.434688568115234\n",
            "epoch: 245, training loss: 13.313175201416016, validation loss: 17.428165435791016\n",
            "epoch: 246, training loss: 13.305603981018066, validation loss: 17.421663284301758\n",
            "epoch: 247, training loss: 13.29808235168457, validation loss: 17.415246963500977\n",
            "epoch: 248, training loss: 13.290574073791504, validation loss: 17.408859252929688\n",
            "epoch: 249, training loss: 13.283080101013184, validation loss: 17.402563095092773\n",
            "epoch: 250, training loss: 13.27562427520752, validation loss: 17.396318435668945\n",
            "epoch: 251, training loss: 13.260201454162598, validation loss: 17.376474380493164\n",
            "epoch: 252, training loss: 13.25279426574707, validation loss: 17.372211456298828\n",
            "epoch: 253, training loss: 13.245695114135742, validation loss: 17.367103576660156\n",
            "epoch: 254, training loss: 13.238762855529785, validation loss: 17.361736297607422\n",
            "epoch: 255, training loss: 13.231943130493164, validation loss: 17.356361389160156\n",
            "epoch: 256, training loss: 13.225204467773438, validation loss: 17.350860595703125\n",
            "epoch: 257, training loss: 13.218530654907227, validation loss: 17.34528923034668\n",
            "epoch: 258, training loss: 13.211894035339355, validation loss: 17.33975601196289\n",
            "epoch: 259, training loss: 13.205303192138672, validation loss: 17.334260940551758\n",
            "epoch: 260, training loss: 13.198736190795898, validation loss: 17.328752517700195\n",
            "epoch: 261, training loss: 13.192185401916504, validation loss: 17.323270797729492\n",
            "epoch: 262, training loss: 13.185662269592285, validation loss: 17.31783103942871\n",
            "epoch: 263, training loss: 13.179153442382812, validation loss: 17.31239128112793\n",
            "epoch: 264, training loss: 13.172679901123047, validation loss: 17.306930541992188\n",
            "epoch: 265, training loss: 13.166215896606445, validation loss: 17.301490783691406\n",
            "epoch: 266, training loss: 13.159770965576172, validation loss: 17.29606056213379\n",
            "epoch: 267, training loss: 13.153356552124023, validation loss: 17.290658950805664\n",
            "epoch: 268, training loss: 13.146944046020508, validation loss: 17.28525733947754\n",
            "epoch: 269, training loss: 13.140547752380371, validation loss: 17.27988052368164\n",
            "epoch: 270, training loss: 13.134174346923828, validation loss: 17.274478912353516\n",
            "epoch: 271, training loss: 13.127808570861816, validation loss: 17.269100189208984\n",
            "epoch: 272, training loss: 13.12147331237793, validation loss: 17.263721466064453\n",
            "epoch: 273, training loss: 13.115160942077637, validation loss: 17.258365631103516\n",
            "epoch: 274, training loss: 13.108865737915039, validation loss: 17.25296974182129\n",
            "epoch: 275, training loss: 13.102582931518555, validation loss: 17.247562408447266\n",
            "epoch: 276, training loss: 13.087063789367676, validation loss: 17.235267639160156\n",
            "epoch: 277, training loss: 13.080728530883789, validation loss: 17.231592178344727\n",
            "epoch: 278, training loss: 13.074688911437988, validation loss: 17.227081298828125\n",
            "epoch: 279, training loss: 13.068778038024902, validation loss: 17.22234535217285\n",
            "epoch: 280, training loss: 13.062972068786621, validation loss: 17.21751594543457\n",
            "epoch: 281, training loss: 13.057228088378906, validation loss: 17.212627410888672\n",
            "epoch: 282, training loss: 13.051531791687012, validation loss: 17.207704544067383\n",
            "epoch: 283, training loss: 13.04588508605957, validation loss: 17.20275115966797\n",
            "epoch: 284, training loss: 13.04028034210205, validation loss: 17.197771072387695\n",
            "epoch: 285, training loss: 13.034707069396973, validation loss: 17.192750930786133\n",
            "epoch: 286, training loss: 13.029128074645996, validation loss: 17.187789916992188\n",
            "epoch: 287, training loss: 13.023578643798828, validation loss: 17.182809829711914\n",
            "epoch: 288, training loss: 13.018046379089355, validation loss: 17.177824020385742\n",
            "epoch: 289, training loss: 13.012516975402832, validation loss: 17.172842025756836\n",
            "epoch: 290, training loss: 13.007017135620117, validation loss: 17.16783332824707\n",
            "epoch: 291, training loss: 13.001522064208984, validation loss: 17.16280746459961\n",
            "epoch: 292, training loss: 12.996036529541016, validation loss: 17.15778350830078\n",
            "epoch: 293, training loss: 12.990599632263184, validation loss: 17.152767181396484\n",
            "epoch: 294, training loss: 12.9851655960083, validation loss: 17.147666931152344\n",
            "epoch: 295, training loss: 12.979743003845215, validation loss: 17.142620086669922\n",
            "epoch: 296, training loss: 12.97435474395752, validation loss: 17.137542724609375\n",
            "epoch: 297, training loss: 12.968973159790039, validation loss: 17.132461547851562\n",
            "epoch: 298, training loss: 12.963611602783203, validation loss: 17.12738800048828\n",
            "epoch: 299, training loss: 12.958267211914062, validation loss: 17.122303009033203\n",
            "epoch: 300, training loss: 12.952926635742188, validation loss: 17.1171875\n",
            "epoch: 301, training loss: 12.938162803649902, validation loss: 17.10936164855957\n",
            "epoch: 302, training loss: 12.932733535766602, validation loss: 17.10597038269043\n",
            "epoch: 303, training loss: 12.927590370178223, validation loss: 17.10166358947754\n",
            "epoch: 304, training loss: 12.922589302062988, validation loss: 17.097139358520508\n",
            "epoch: 305, training loss: 12.917677879333496, validation loss: 17.092470169067383\n",
            "epoch: 306, training loss: 12.912832260131836, validation loss: 17.087799072265625\n",
            "epoch: 307, training loss: 12.908039093017578, validation loss: 17.083093643188477\n",
            "epoch: 308, training loss: 12.903266906738281, validation loss: 17.07834815979004\n",
            "epoch: 309, training loss: 12.898550987243652, validation loss: 17.073591232299805\n",
            "epoch: 310, training loss: 12.893855094909668, validation loss: 17.06883430480957\n",
            "epoch: 311, training loss: 12.889165878295898, validation loss: 17.064062118530273\n",
            "epoch: 312, training loss: 12.884517669677734, validation loss: 17.05927085876465\n",
            "epoch: 313, training loss: 12.879876136779785, validation loss: 17.054489135742188\n",
            "epoch: 314, training loss: 12.875255584716797, validation loss: 17.04971694946289\n",
            "epoch: 315, training loss: 12.8706636428833, validation loss: 17.044939041137695\n",
            "epoch: 316, training loss: 12.866080284118652, validation loss: 17.040149688720703\n",
            "epoch: 317, training loss: 12.861533164978027, validation loss: 17.03538703918457\n",
            "epoch: 318, training loss: 12.856993675231934, validation loss: 17.030681610107422\n",
            "epoch: 319, training loss: 12.852459907531738, validation loss: 17.025943756103516\n",
            "epoch: 320, training loss: 12.84795093536377, validation loss: 17.021217346191406\n",
            "epoch: 321, training loss: 12.843440055847168, validation loss: 17.016508102416992\n",
            "epoch: 322, training loss: 12.838963508605957, validation loss: 17.011789321899414\n",
            "epoch: 323, training loss: 12.834474563598633, validation loss: 17.007078170776367\n",
            "epoch: 324, training loss: 12.830021858215332, validation loss: 17.002347946166992\n",
            "epoch: 325, training loss: 12.825590133666992, validation loss: 16.99761962890625\n",
            "epoch: 326, training loss: 12.812297821044922, validation loss: 16.992406845092773\n",
            "epoch: 327, training loss: 12.80769157409668, validation loss: 16.989337921142578\n",
            "epoch: 328, training loss: 12.803377151489258, validation loss: 16.985393524169922\n",
            "epoch: 329, training loss: 12.799182891845703, validation loss: 16.981229782104492\n",
            "epoch: 330, training loss: 12.795062065124512, validation loss: 16.977039337158203\n",
            "epoch: 331, training loss: 12.79098892211914, validation loss: 16.972749710083008\n",
            "epoch: 332, training loss: 12.786940574645996, validation loss: 16.968528747558594\n",
            "epoch: 333, training loss: 12.782952308654785, validation loss: 16.964292526245117\n",
            "epoch: 334, training loss: 12.778975486755371, validation loss: 16.96000099182129\n",
            "epoch: 335, training loss: 12.775018692016602, validation loss: 16.95574188232422\n",
            "epoch: 336, training loss: 12.771075248718262, validation loss: 16.951507568359375\n",
            "epoch: 337, training loss: 12.767167091369629, validation loss: 16.947250366210938\n",
            "epoch: 338, training loss: 12.763264656066895, validation loss: 16.94295883178711\n",
            "epoch: 339, training loss: 12.759374618530273, validation loss: 16.938701629638672\n",
            "epoch: 340, training loss: 12.755500793457031, validation loss: 16.934423446655273\n",
            "epoch: 341, training loss: 12.751632690429688, validation loss: 16.93017578125\n",
            "epoch: 342, training loss: 12.74777603149414, validation loss: 16.925922393798828\n",
            "epoch: 343, training loss: 12.743953704833984, validation loss: 16.921640396118164\n",
            "epoch: 344, training loss: 12.740129470825195, validation loss: 16.91739273071289\n",
            "epoch: 345, training loss: 12.736326217651367, validation loss: 16.913105010986328\n",
            "epoch: 346, training loss: 12.73252010345459, validation loss: 16.908828735351562\n",
            "epoch: 347, training loss: 12.728744506835938, validation loss: 16.904563903808594\n",
            "epoch: 348, training loss: 12.724987030029297, validation loss: 16.90032196044922\n",
            "epoch: 349, training loss: 12.721227645874023, validation loss: 16.896055221557617\n",
            "epoch: 350, training loss: 12.717482566833496, validation loss: 16.891826629638672\n",
            "epoch: 351, training loss: 12.706103324890137, validation loss: 16.88751983642578\n",
            "epoch: 352, training loss: 12.70213508605957, validation loss: 16.885005950927734\n",
            "epoch: 353, training loss: 12.698486328125, validation loss: 16.8815860748291\n",
            "epoch: 354, training loss: 12.694964408874512, validation loss: 16.87795066833496\n",
            "epoch: 355, training loss: 12.69149112701416, validation loss: 16.874237060546875\n",
            "epoch: 356, training loss: 12.688063621520996, validation loss: 16.870485305786133\n",
            "epoch: 357, training loss: 12.684662818908691, validation loss: 16.866718292236328\n",
            "epoch: 358, training loss: 12.68131160736084, validation loss: 16.862939834594727\n",
            "epoch: 359, training loss: 12.677983283996582, validation loss: 16.859149932861328\n",
            "epoch: 360, training loss: 12.674659729003906, validation loss: 16.855297088623047\n",
            "epoch: 361, training loss: 12.671368598937988, validation loss: 16.851476669311523\n",
            "epoch: 362, training loss: 12.668092727661133, validation loss: 16.847640991210938\n",
            "epoch: 363, training loss: 12.664831161499023, validation loss: 16.843799591064453\n",
            "epoch: 364, training loss: 12.661577224731445, validation loss: 16.839981079101562\n",
            "epoch: 365, training loss: 12.658345222473145, validation loss: 16.836149215698242\n",
            "epoch: 366, training loss: 12.65511703491211, validation loss: 16.832319259643555\n",
            "epoch: 367, training loss: 12.651912689208984, validation loss: 16.828479766845703\n",
            "epoch: 368, training loss: 12.648674011230469, validation loss: 16.82463264465332\n",
            "epoch: 369, training loss: 12.64547061920166, validation loss: 16.82080078125\n",
            "epoch: 370, training loss: 12.642269134521484, validation loss: 16.816926956176758\n",
            "epoch: 371, training loss: 12.63907241821289, validation loss: 16.81307029724121\n",
            "epoch: 372, training loss: 12.635889053344727, validation loss: 16.809236526489258\n",
            "epoch: 373, training loss: 12.632705688476562, validation loss: 16.805374145507812\n",
            "epoch: 374, training loss: 12.62952995300293, validation loss: 16.801530838012695\n",
            "epoch: 375, training loss: 12.62636661529541, validation loss: 16.79770851135254\n",
            "epoch: 376, training loss: 12.616843223571777, validation loss: 16.7928524017334\n",
            "epoch: 377, training loss: 12.613326072692871, validation loss: 16.790714263916016\n",
            "epoch: 378, training loss: 12.610142707824707, validation loss: 16.78768539428711\n",
            "epoch: 379, training loss: 12.607077598571777, validation loss: 16.78437614440918\n",
            "epoch: 380, training loss: 12.604069709777832, validation loss: 16.78097152709961\n",
            "epoch: 381, training loss: 12.601114273071289, validation loss: 16.777503967285156\n",
            "epoch: 382, training loss: 12.598187446594238, validation loss: 16.77400016784668\n",
            "epoch: 383, training loss: 12.595280647277832, validation loss: 16.77049446105957\n",
            "epoch: 384, training loss: 12.592395782470703, validation loss: 16.76694679260254\n",
            "epoch: 385, training loss: 12.589518547058105, validation loss: 16.76341438293457\n",
            "epoch: 386, training loss: 12.586654663085938, validation loss: 16.759872436523438\n",
            "epoch: 387, training loss: 12.583806037902832, validation loss: 16.756309509277344\n",
            "epoch: 388, training loss: 12.580965042114258, validation loss: 16.75273895263672\n",
            "epoch: 389, training loss: 12.578126907348633, validation loss: 16.74920654296875\n",
            "epoch: 390, training loss: 12.575311660766602, validation loss: 16.745641708374023\n",
            "epoch: 391, training loss: 12.572490692138672, validation loss: 16.742097854614258\n",
            "epoch: 392, training loss: 12.569679260253906, validation loss: 16.738567352294922\n",
            "epoch: 393, training loss: 12.566879272460938, validation loss: 16.735015869140625\n",
            "epoch: 394, training loss: 12.56408977508545, validation loss: 16.73150062561035\n",
            "epoch: 395, training loss: 12.561299324035645, validation loss: 16.72797966003418\n",
            "epoch: 396, training loss: 12.558505058288574, validation loss: 16.72446632385254\n",
            "epoch: 397, training loss: 12.555730819702148, validation loss: 16.72095489501953\n",
            "epoch: 398, training loss: 12.552961349487305, validation loss: 16.717477798461914\n",
            "epoch: 399, training loss: 12.55018138885498, validation loss: 16.713966369628906\n",
            "epoch: 400, training loss: 12.54741096496582, validation loss: 16.710445404052734\n",
            "epoch: 401, training loss: 12.539787292480469, validation loss: 16.704309463500977\n",
            "epoch: 402, training loss: 12.536670684814453, validation loss: 16.702556610107422\n",
            "epoch: 403, training loss: 12.533864974975586, validation loss: 16.699892044067383\n",
            "epoch: 404, training loss: 12.531181335449219, validation loss: 16.6970272064209\n",
            "epoch: 405, training loss: 12.528552055358887, validation loss: 16.69401741027832\n",
            "epoch: 406, training loss: 12.525956153869629, validation loss: 16.690990447998047\n",
            "epoch: 407, training loss: 12.523394584655762, validation loss: 16.68789291381836\n",
            "epoch: 408, training loss: 12.520862579345703, validation loss: 16.68483543395996\n",
            "epoch: 409, training loss: 12.518339157104492, validation loss: 16.681781768798828\n",
            "epoch: 410, training loss: 12.515830993652344, validation loss: 16.678688049316406\n",
            "epoch: 411, training loss: 12.513331413269043, validation loss: 16.67561912536621\n",
            "epoch: 412, training loss: 12.51085090637207, validation loss: 16.672500610351562\n",
            "epoch: 413, training loss: 12.508376121520996, validation loss: 16.669408798217773\n",
            "epoch: 414, training loss: 12.505918502807617, validation loss: 16.66631317138672\n",
            "epoch: 415, training loss: 12.50344181060791, validation loss: 16.663211822509766\n",
            "epoch: 416, training loss: 12.500991821289062, validation loss: 16.660120010375977\n",
            "epoch: 417, training loss: 12.49853515625, validation loss: 16.65704917907715\n",
            "epoch: 418, training loss: 12.49610424041748, validation loss: 16.653926849365234\n",
            "epoch: 419, training loss: 12.493671417236328, validation loss: 16.650854110717773\n",
            "epoch: 420, training loss: 12.491226196289062, validation loss: 16.647781372070312\n",
            "epoch: 421, training loss: 12.488792419433594, validation loss: 16.64470100402832\n",
            "epoch: 422, training loss: 12.48637866973877, validation loss: 16.641618728637695\n",
            "epoch: 423, training loss: 12.483953475952148, validation loss: 16.63854217529297\n",
            "epoch: 424, training loss: 12.481561660766602, validation loss: 16.635482788085938\n",
            "epoch: 425, training loss: 12.479142189025879, validation loss: 16.63241195678711\n",
            "epoch: 426, training loss: 12.473219871520996, validation loss: 16.624792098999023\n",
            "epoch: 427, training loss: 12.470429420471191, validation loss: 16.62344741821289\n",
            "epoch: 428, training loss: 12.467972755432129, validation loss: 16.621238708496094\n",
            "epoch: 429, training loss: 12.465609550476074, validation loss: 16.61878204345703\n",
            "epoch: 430, training loss: 12.463316917419434, validation loss: 16.616186141967773\n",
            "epoch: 431, training loss: 12.461050987243652, validation loss: 16.61359977722168\n",
            "epoch: 432, training loss: 12.458820343017578, validation loss: 16.61091423034668\n",
            "epoch: 433, training loss: 12.456612586975098, validation loss: 16.60824966430664\n",
            "epoch: 434, training loss: 12.454416275024414, validation loss: 16.605571746826172\n",
            "epoch: 435, training loss: 12.452240943908691, validation loss: 16.602903366088867\n",
            "epoch: 436, training loss: 12.450072288513184, validation loss: 16.600170135498047\n",
            "epoch: 437, training loss: 12.44791030883789, validation loss: 16.597475051879883\n",
            "epoch: 438, training loss: 12.44577693939209, validation loss: 16.594768524169922\n",
            "epoch: 439, training loss: 12.44364070892334, validation loss: 16.592056274414062\n",
            "epoch: 440, training loss: 12.44151782989502, validation loss: 16.589330673217773\n",
            "epoch: 441, training loss: 12.439408302307129, validation loss: 16.586578369140625\n",
            "epoch: 442, training loss: 12.437307357788086, validation loss: 16.583864212036133\n",
            "epoch: 443, training loss: 12.435205459594727, validation loss: 16.58113670349121\n",
            "epoch: 444, training loss: 12.433128356933594, validation loss: 16.57839584350586\n",
            "epoch: 445, training loss: 12.43105697631836, validation loss: 16.575664520263672\n",
            "epoch: 446, training loss: 12.428977012634277, validation loss: 16.57292938232422\n",
            "epoch: 447, training loss: 12.426922798156738, validation loss: 16.570173263549805\n",
            "epoch: 448, training loss: 12.424861907958984, validation loss: 16.56743049621582\n",
            "epoch: 449, training loss: 12.422807693481445, validation loss: 16.564699172973633\n",
            "epoch: 450, training loss: 12.420760154724121, validation loss: 16.561969757080078\n",
            "epoch: 451, training loss: 12.416396141052246, validation loss: 16.552600860595703\n",
            "epoch: 452, training loss: 12.413888931274414, validation loss: 16.551485061645508\n",
            "epoch: 453, training loss: 12.411693572998047, validation loss: 16.54957389831543\n",
            "epoch: 454, training loss: 12.409624099731445, validation loss: 16.54737091064453\n",
            "epoch: 455, training loss: 12.407613754272461, validation loss: 16.545045852661133\n",
            "epoch: 456, training loss: 12.405647277832031, validation loss: 16.54267120361328\n",
            "epoch: 457, training loss: 12.403700828552246, validation loss: 16.540246963500977\n",
            "epoch: 458, training loss: 12.401786804199219, validation loss: 16.537830352783203\n",
            "epoch: 459, training loss: 12.399895668029785, validation loss: 16.53538703918457\n",
            "epoch: 460, training loss: 12.397997856140137, validation loss: 16.532949447631836\n",
            "epoch: 461, training loss: 12.396130561828613, validation loss: 16.530481338500977\n",
            "epoch: 462, training loss: 12.394257545471191, validation loss: 16.52797508239746\n",
            "epoch: 463, training loss: 12.392399787902832, validation loss: 16.525564193725586\n",
            "epoch: 464, training loss: 12.390539169311523, validation loss: 16.523054122924805\n",
            "epoch: 465, training loss: 12.388691902160645, validation loss: 16.52056312561035\n",
            "epoch: 466, training loss: 12.386858940124512, validation loss: 16.518095016479492\n",
            "epoch: 467, training loss: 12.38502311706543, validation loss: 16.515592575073242\n",
            "epoch: 468, training loss: 12.383188247680664, validation loss: 16.51311492919922\n",
            "epoch: 469, training loss: 12.38137149810791, validation loss: 16.510595321655273\n",
            "epoch: 470, training loss: 12.379542350769043, validation loss: 16.50813102722168\n",
            "epoch: 471, training loss: 12.37773323059082, validation loss: 16.50562286376953\n",
            "epoch: 472, training loss: 12.3759183883667, validation loss: 16.503110885620117\n",
            "epoch: 473, training loss: 12.37411117553711, validation loss: 16.500640869140625\n",
            "epoch: 474, training loss: 12.372296333312988, validation loss: 16.49816131591797\n",
            "epoch: 475, training loss: 12.370495796203613, validation loss: 16.495649337768555\n",
            "epoch: 476, training loss: 12.367443084716797, validation loss: 16.485170364379883\n",
            "epoch: 477, training loss: 12.365221977233887, validation loss: 16.484272003173828\n",
            "epoch: 478, training loss: 12.363265991210938, validation loss: 16.482643127441406\n",
            "epoch: 479, training loss: 12.361433982849121, validation loss: 16.480731964111328\n",
            "epoch: 480, training loss: 12.359649658203125, validation loss: 16.478721618652344\n",
            "epoch: 481, training loss: 12.357904434204102, validation loss: 16.476621627807617\n",
            "epoch: 482, training loss: 12.356179237365723, validation loss: 16.474502563476562\n",
            "epoch: 483, training loss: 12.35446834564209, validation loss: 16.47235107421875\n",
            "epoch: 484, training loss: 12.352784156799316, validation loss: 16.470190048217773\n",
            "epoch: 485, training loss: 12.351096153259277, validation loss: 16.4680233001709\n",
            "epoch: 486, training loss: 12.34941577911377, validation loss: 16.46586799621582\n",
            "epoch: 487, training loss: 12.347744941711426, validation loss: 16.46369743347168\n",
            "epoch: 488, training loss: 12.346096992492676, validation loss: 16.461524963378906\n",
            "epoch: 489, training loss: 12.344438552856445, validation loss: 16.459346771240234\n",
            "epoch: 490, training loss: 12.34278392791748, validation loss: 16.457183837890625\n",
            "epoch: 491, training loss: 12.341134071350098, validation loss: 16.455007553100586\n",
            "epoch: 492, training loss: 12.339492797851562, validation loss: 16.45280647277832\n",
            "epoch: 493, training loss: 12.337847709655762, validation loss: 16.450611114501953\n",
            "epoch: 494, training loss: 12.336212158203125, validation loss: 16.448429107666016\n",
            "epoch: 495, training loss: 12.33459758758545, validation loss: 16.446239471435547\n",
            "epoch: 496, training loss: 12.332964897155762, validation loss: 16.44403076171875\n",
            "epoch: 497, training loss: 12.331334114074707, validation loss: 16.441844940185547\n",
            "epoch: 498, training loss: 12.32970905303955, validation loss: 16.43960952758789\n",
            "epoch: 499, training loss: 12.328099250793457, validation loss: 16.437435150146484\n",
            "epoch: 500, training loss: 12.326461791992188, validation loss: 16.435222625732422\n",
            "Predictions for pittsburgh generated!\n",
            "\n",
            "Done printing pittsburgh predictions\n",
            "----------------------------------------------------------------------\n",
            "epoch: 1, training loss: 23.14165687561035, validation loss: 11.327366828918457\n",
            "epoch: 2, training loss: 23.009225845336914, validation loss: 11.110092163085938\n",
            "epoch: 3, training loss: 22.933059692382812, validation loss: 10.994901657104492\n",
            "epoch: 4, training loss: 22.878908157348633, validation loss: 10.930418968200684\n",
            "epoch: 5, training loss: 22.837522506713867, validation loss: 10.892863273620605\n",
            "epoch: 6, training loss: 22.803550720214844, validation loss: 10.871917724609375\n",
            "epoch: 7, training loss: 22.77375030517578, validation loss: 10.86144733428955\n",
            "epoch: 8, training loss: 22.74650764465332, validation loss: 10.85754108428955\n",
            "epoch: 9, training loss: 22.721046447753906, validation loss: 10.857839584350586\n",
            "epoch: 10, training loss: 22.696914672851562, validation loss: 10.860838890075684\n",
            "epoch: 11, training loss: 22.673755645751953, validation loss: 10.865689277648926\n",
            "epoch: 12, training loss: 22.651369094848633, validation loss: 10.871685981750488\n",
            "epoch: 13, training loss: 22.62961196899414, validation loss: 10.878369331359863\n",
            "epoch: 14, training loss: 22.60837745666504, validation loss: 10.885367393493652\n",
            "epoch: 15, training loss: 22.58763313293457, validation loss: 10.892547607421875\n",
            "epoch: 16, training loss: 22.567367553710938, validation loss: 10.89977741241455\n",
            "epoch: 17, training loss: 22.54749870300293, validation loss: 10.906941413879395\n",
            "epoch: 18, training loss: 22.527935028076172, validation loss: 10.913948059082031\n",
            "epoch: 19, training loss: 22.50871467590332, validation loss: 10.920743942260742\n",
            "epoch: 20, training loss: 22.489837646484375, validation loss: 10.927342414855957\n",
            "epoch: 21, training loss: 22.471271514892578, validation loss: 10.933704376220703\n",
            "epoch: 22, training loss: 22.452951431274414, validation loss: 10.939884185791016\n",
            "epoch: 23, training loss: 22.434955596923828, validation loss: 10.94580078125\n",
            "epoch: 24, training loss: 22.41726303100586, validation loss: 10.951458930969238\n",
            "epoch: 25, training loss: 22.399860382080078, validation loss: 10.956876754760742\n",
            "epoch: 26, training loss: 22.384689331054688, validation loss: 10.961997032165527\n",
            "epoch: 27, training loss: 22.3693790435791, validation loss: 10.966647148132324\n",
            "epoch: 28, training loss: 22.354305267333984, validation loss: 10.97109603881836\n",
            "epoch: 29, training loss: 22.339452743530273, validation loss: 10.97533893585205\n",
            "epoch: 30, training loss: 22.324819564819336, validation loss: 10.979426383972168\n",
            "epoch: 31, training loss: 22.31037712097168, validation loss: 10.983328819274902\n",
            "epoch: 32, training loss: 22.2961368560791, validation loss: 10.987082481384277\n",
            "epoch: 33, training loss: 22.282115936279297, validation loss: 10.990678787231445\n",
            "epoch: 34, training loss: 22.268325805664062, validation loss: 10.994095802307129\n",
            "epoch: 35, training loss: 22.254735946655273, validation loss: 10.997373580932617\n",
            "epoch: 36, training loss: 22.241342544555664, validation loss: 11.000506401062012\n",
            "epoch: 37, training loss: 22.228134155273438, validation loss: 11.0035400390625\n",
            "epoch: 38, training loss: 22.2150936126709, validation loss: 11.006449699401855\n",
            "epoch: 39, training loss: 22.20224952697754, validation loss: 11.009235382080078\n",
            "epoch: 40, training loss: 22.1895694732666, validation loss: 11.0118989944458\n",
            "epoch: 41, training loss: 22.177091598510742, validation loss: 11.014464378356934\n",
            "epoch: 42, training loss: 22.164777755737305, validation loss: 11.016895294189453\n",
            "epoch: 43, training loss: 22.152647018432617, validation loss: 11.019230842590332\n",
            "epoch: 44, training loss: 22.140697479248047, validation loss: 11.021463394165039\n",
            "epoch: 45, training loss: 22.128910064697266, validation loss: 11.023608207702637\n",
            "epoch: 46, training loss: 22.117279052734375, validation loss: 11.025689125061035\n",
            "epoch: 47, training loss: 22.105810165405273, validation loss: 11.02771282196045\n",
            "epoch: 48, training loss: 22.094484329223633, validation loss: 11.02967643737793\n",
            "epoch: 49, training loss: 22.083345413208008, validation loss: 11.031571388244629\n",
            "epoch: 50, training loss: 22.072372436523438, validation loss: 11.03341293334961\n",
            "epoch: 51, training loss: 22.06401824951172, validation loss: 11.034375190734863\n",
            "epoch: 52, training loss: 22.05430793762207, validation loss: 11.036043167114258\n",
            "epoch: 53, training loss: 22.044748306274414, validation loss: 11.03760051727295\n",
            "epoch: 54, training loss: 22.035308837890625, validation loss: 11.03909683227539\n",
            "epoch: 55, training loss: 22.025978088378906, validation loss: 11.040538787841797\n",
            "epoch: 56, training loss: 22.016775131225586, validation loss: 11.041897773742676\n",
            "epoch: 57, training loss: 22.00765037536621, validation loss: 11.04321575164795\n",
            "epoch: 58, training loss: 21.998634338378906, validation loss: 11.044472694396973\n",
            "epoch: 59, training loss: 21.989713668823242, validation loss: 11.045670509338379\n",
            "epoch: 60, training loss: 21.98089027404785, validation loss: 11.04680061340332\n",
            "epoch: 61, training loss: 21.97216033935547, validation loss: 11.047883033752441\n",
            "epoch: 62, training loss: 21.963510513305664, validation loss: 11.048942565917969\n",
            "epoch: 63, training loss: 21.95494842529297, validation loss: 11.049970626831055\n",
            "epoch: 64, training loss: 21.94645881652832, validation loss: 11.050942420959473\n",
            "epoch: 65, training loss: 21.938072204589844, validation loss: 11.051885604858398\n",
            "epoch: 66, training loss: 21.929767608642578, validation loss: 11.052790641784668\n",
            "epoch: 67, training loss: 21.921560287475586, validation loss: 11.053653717041016\n",
            "epoch: 68, training loss: 21.91341781616211, validation loss: 11.054484367370605\n",
            "epoch: 69, training loss: 21.905351638793945, validation loss: 11.055302619934082\n",
            "epoch: 70, training loss: 21.897371292114258, validation loss: 11.056081771850586\n",
            "epoch: 71, training loss: 21.889463424682617, validation loss: 11.056854248046875\n",
            "epoch: 72, training loss: 21.881624221801758, validation loss: 11.057592391967773\n",
            "epoch: 73, training loss: 21.873872756958008, validation loss: 11.058314323425293\n",
            "epoch: 74, training loss: 21.866178512573242, validation loss: 11.059030532836914\n",
            "epoch: 75, training loss: 21.858551025390625, validation loss: 11.059714317321777\n",
            "epoch: 76, training loss: 21.853757858276367, validation loss: 11.059179306030273\n",
            "epoch: 77, training loss: 21.846942901611328, validation loss: 11.059894561767578\n",
            "epoch: 78, training loss: 21.840208053588867, validation loss: 11.06055736541748\n",
            "epoch: 79, training loss: 21.83354377746582, validation loss: 11.061188697814941\n",
            "epoch: 80, training loss: 21.826921463012695, validation loss: 11.061768531799316\n",
            "epoch: 81, training loss: 21.82038116455078, validation loss: 11.062315940856934\n",
            "epoch: 82, training loss: 21.81393814086914, validation loss: 11.062810897827148\n",
            "epoch: 83, training loss: 21.807546615600586, validation loss: 11.06326961517334\n",
            "epoch: 84, training loss: 21.801197052001953, validation loss: 11.063712120056152\n",
            "epoch: 85, training loss: 21.794923782348633, validation loss: 11.06412124633789\n",
            "epoch: 86, training loss: 21.788705825805664, validation loss: 11.0645112991333\n",
            "epoch: 87, training loss: 21.782543182373047, validation loss: 11.064886093139648\n",
            "epoch: 88, training loss: 21.77643394470215, validation loss: 11.065238952636719\n",
            "epoch: 89, training loss: 21.77037239074707, validation loss: 11.06556224822998\n",
            "epoch: 90, training loss: 21.76434898376465, validation loss: 11.06586742401123\n",
            "epoch: 91, training loss: 21.758399963378906, validation loss: 11.066157341003418\n",
            "epoch: 92, training loss: 21.75251007080078, validation loss: 11.066417694091797\n",
            "epoch: 93, training loss: 21.74665069580078, validation loss: 11.066666603088379\n",
            "epoch: 94, training loss: 21.740848541259766, validation loss: 11.066888809204102\n",
            "epoch: 95, training loss: 21.735097885131836, validation loss: 11.067089080810547\n",
            "epoch: 96, training loss: 21.729394912719727, validation loss: 11.06725025177002\n",
            "epoch: 97, training loss: 21.723745346069336, validation loss: 11.06739616394043\n",
            "epoch: 98, training loss: 21.7181339263916, validation loss: 11.067523956298828\n",
            "epoch: 99, training loss: 21.71257209777832, validation loss: 11.067631721496582\n",
            "epoch: 100, training loss: 21.70705795288086, validation loss: 11.067737579345703\n",
            "epoch: 101, training loss: 21.70440101623535, validation loss: 11.06661319732666\n",
            "epoch: 102, training loss: 21.699440002441406, validation loss: 11.066805839538574\n",
            "epoch: 103, training loss: 21.694562911987305, validation loss: 11.066941261291504\n",
            "epoch: 104, training loss: 21.689708709716797, validation loss: 11.067041397094727\n",
            "epoch: 105, training loss: 21.684900283813477, validation loss: 11.067102432250977\n",
            "epoch: 106, training loss: 21.680131912231445, validation loss: 11.06713581085205\n",
            "epoch: 107, training loss: 21.67540168762207, validation loss: 11.067151069641113\n",
            "epoch: 108, training loss: 21.670692443847656, validation loss: 11.067131996154785\n",
            "epoch: 109, training loss: 21.66600227355957, validation loss: 11.067127227783203\n",
            "epoch: 110, training loss: 21.661344528198242, validation loss: 11.067099571228027\n",
            "epoch: 111, training loss: 21.656721115112305, validation loss: 11.067061424255371\n",
            "epoch: 112, training loss: 21.652124404907227, validation loss: 11.067008018493652\n",
            "epoch: 113, training loss: 21.647550582885742, validation loss: 11.066951751708984\n",
            "epoch: 114, training loss: 21.64301109313965, validation loss: 11.066892623901367\n",
            "epoch: 115, training loss: 21.638486862182617, validation loss: 11.066810607910156\n",
            "epoch: 116, training loss: 21.63400650024414, validation loss: 11.066734313964844\n",
            "epoch: 117, training loss: 21.62954330444336, validation loss: 11.066643714904785\n",
            "epoch: 118, training loss: 21.625099182128906, validation loss: 11.066540718078613\n",
            "epoch: 119, training loss: 21.620685577392578, validation loss: 11.06644344329834\n",
            "epoch: 120, training loss: 21.616300582885742, validation loss: 11.066341400146484\n",
            "epoch: 121, training loss: 21.611936569213867, validation loss: 11.066247940063477\n",
            "epoch: 122, training loss: 21.607601165771484, validation loss: 11.066136360168457\n",
            "epoch: 123, training loss: 21.60328483581543, validation loss: 11.066015243530273\n",
            "epoch: 124, training loss: 21.5989990234375, validation loss: 11.065896987915039\n",
            "epoch: 125, training loss: 21.594736099243164, validation loss: 11.065777778625488\n",
            "epoch: 126, training loss: 21.593189239501953, validation loss: 11.064616203308105\n",
            "epoch: 127, training loss: 21.589366912841797, validation loss: 11.064576148986816\n",
            "epoch: 128, training loss: 21.585561752319336, validation loss: 11.064517974853516\n",
            "epoch: 129, training loss: 21.581783294677734, validation loss: 11.064435005187988\n",
            "epoch: 130, training loss: 21.578027725219727, validation loss: 11.064332008361816\n",
            "epoch: 131, training loss: 21.574291229248047, validation loss: 11.064209938049316\n",
            "epoch: 132, training loss: 21.570587158203125, validation loss: 11.06408977508545\n",
            "epoch: 133, training loss: 21.566896438598633, validation loss: 11.063963890075684\n",
            "epoch: 134, training loss: 21.563232421875, validation loss: 11.063833236694336\n",
            "epoch: 135, training loss: 21.559574127197266, validation loss: 11.06370735168457\n",
            "epoch: 136, training loss: 21.555953979492188, validation loss: 11.063584327697754\n",
            "epoch: 137, training loss: 21.552349090576172, validation loss: 11.063436508178711\n",
            "epoch: 138, training loss: 21.548749923706055, validation loss: 11.063301086425781\n",
            "epoch: 139, training loss: 21.54518699645996, validation loss: 11.063154220581055\n",
            "epoch: 140, training loss: 21.541627883911133, validation loss: 11.063028335571289\n",
            "epoch: 141, training loss: 21.538097381591797, validation loss: 11.06287956237793\n",
            "epoch: 142, training loss: 21.534576416015625, validation loss: 11.062742233276367\n",
            "epoch: 143, training loss: 21.53107452392578, validation loss: 11.062599182128906\n",
            "epoch: 144, training loss: 21.527603149414062, validation loss: 11.062453269958496\n",
            "epoch: 145, training loss: 21.524150848388672, validation loss: 11.062277793884277\n",
            "epoch: 146, training loss: 21.52071189880371, validation loss: 11.062125205993652\n",
            "epoch: 147, training loss: 21.517295837402344, validation loss: 11.061967849731445\n",
            "epoch: 148, training loss: 21.513900756835938, validation loss: 11.061795234680176\n",
            "epoch: 149, training loss: 21.510515213012695, validation loss: 11.061626434326172\n",
            "epoch: 150, training loss: 21.50716209411621, validation loss: 11.06142807006836\n",
            "epoch: 151, training loss: 21.506214141845703, validation loss: 11.060586929321289\n",
            "epoch: 152, training loss: 21.503192901611328, validation loss: 11.060447692871094\n",
            "epoch: 153, training loss: 21.500198364257812, validation loss: 11.060318946838379\n",
            "epoch: 154, training loss: 21.497234344482422, validation loss: 11.060155868530273\n",
            "epoch: 155, training loss: 21.49428939819336, validation loss: 11.059981346130371\n",
            "epoch: 156, training loss: 21.491371154785156, validation loss: 11.059791564941406\n",
            "epoch: 157, training loss: 21.488462448120117, validation loss: 11.059592247009277\n",
            "epoch: 158, training loss: 21.48558235168457, validation loss: 11.059379577636719\n",
            "epoch: 159, training loss: 21.482723236083984, validation loss: 11.059170722961426\n",
            "epoch: 160, training loss: 21.47987174987793, validation loss: 11.05894660949707\n",
            "epoch: 161, training loss: 21.47704315185547, validation loss: 11.05872631072998\n",
            "epoch: 162, training loss: 21.474233627319336, validation loss: 11.058484077453613\n",
            "epoch: 163, training loss: 21.471431732177734, validation loss: 11.05824089050293\n",
            "epoch: 164, training loss: 21.468656539916992, validation loss: 11.057999610900879\n",
            "epoch: 165, training loss: 21.465885162353516, validation loss: 11.057744979858398\n",
            "epoch: 166, training loss: 21.463134765625, validation loss: 11.057482719421387\n",
            "epoch: 167, training loss: 21.46039390563965, validation loss: 11.057215690612793\n",
            "epoch: 168, training loss: 21.457674026489258, validation loss: 11.056943893432617\n",
            "epoch: 169, training loss: 21.4549560546875, validation loss: 11.056674003601074\n",
            "epoch: 170, training loss: 21.452266693115234, validation loss: 11.056395530700684\n",
            "epoch: 171, training loss: 21.449583053588867, validation loss: 11.056113243103027\n",
            "epoch: 172, training loss: 21.44692039489746, validation loss: 11.055830001831055\n",
            "epoch: 173, training loss: 21.444284439086914, validation loss: 11.055536270141602\n",
            "epoch: 174, training loss: 21.441638946533203, validation loss: 11.055246353149414\n",
            "epoch: 175, training loss: 21.43902015686035, validation loss: 11.054946899414062\n",
            "epoch: 176, training loss: 21.438467025756836, validation loss: 11.054431915283203\n",
            "epoch: 177, training loss: 21.436155319213867, validation loss: 11.05420207977295\n",
            "epoch: 178, training loss: 21.433818817138672, validation loss: 11.053972244262695\n",
            "epoch: 179, training loss: 21.43151092529297, validation loss: 11.053729057312012\n",
            "epoch: 180, training loss: 21.429222106933594, validation loss: 11.053479194641113\n",
            "epoch: 181, training loss: 21.426944732666016, validation loss: 11.053210258483887\n",
            "epoch: 182, training loss: 21.424663543701172, validation loss: 11.052956581115723\n",
            "epoch: 183, training loss: 21.422407150268555, validation loss: 11.052677154541016\n",
            "epoch: 184, training loss: 21.420137405395508, validation loss: 11.052400588989258\n",
            "epoch: 185, training loss: 21.417892456054688, validation loss: 11.05211067199707\n",
            "epoch: 186, training loss: 21.415664672851562, validation loss: 11.051819801330566\n",
            "epoch: 187, training loss: 21.413427352905273, validation loss: 11.051519393920898\n",
            "epoch: 188, training loss: 21.411218643188477, validation loss: 11.051223754882812\n",
            "epoch: 189, training loss: 21.40901756286621, validation loss: 11.050919532775879\n",
            "epoch: 190, training loss: 21.406816482543945, validation loss: 11.050619125366211\n",
            "epoch: 191, training loss: 21.404638290405273, validation loss: 11.05030345916748\n",
            "epoch: 192, training loss: 21.402456283569336, validation loss: 11.04998779296875\n",
            "epoch: 193, training loss: 21.400297164916992, validation loss: 11.049686431884766\n",
            "epoch: 194, training loss: 21.398136138916016, validation loss: 11.049365043640137\n",
            "epoch: 195, training loss: 21.3959903717041, validation loss: 11.049063682556152\n",
            "epoch: 196, training loss: 21.393861770629883, validation loss: 11.048749923706055\n",
            "epoch: 197, training loss: 21.391733169555664, validation loss: 11.048430442810059\n",
            "epoch: 198, training loss: 21.38960838317871, validation loss: 11.048120498657227\n",
            "epoch: 199, training loss: 21.387500762939453, validation loss: 11.047808647155762\n",
            "epoch: 200, training loss: 21.385398864746094, validation loss: 11.047492980957031\n",
            "epoch: 201, training loss: 21.384967803955078, validation loss: 11.047418594360352\n",
            "epoch: 202, training loss: 21.383075714111328, validation loss: 11.047142028808594\n",
            "epoch: 203, training loss: 21.381174087524414, validation loss: 11.046896934509277\n",
            "epoch: 204, training loss: 21.379276275634766, validation loss: 11.046643257141113\n",
            "epoch: 205, training loss: 21.377395629882812, validation loss: 11.046374320983887\n",
            "epoch: 206, training loss: 21.37552833557129, validation loss: 11.046099662780762\n",
            "epoch: 207, training loss: 21.373666763305664, validation loss: 11.045805931091309\n",
            "epoch: 208, training loss: 21.371807098388672, validation loss: 11.045523643493652\n",
            "epoch: 209, training loss: 21.369976043701172, validation loss: 11.045218467712402\n",
            "epoch: 210, training loss: 21.368135452270508, validation loss: 11.044919967651367\n",
            "epoch: 211, training loss: 21.366308212280273, validation loss: 11.044621467590332\n",
            "epoch: 212, training loss: 21.364484786987305, validation loss: 11.04432201385498\n",
            "epoch: 213, training loss: 21.362661361694336, validation loss: 11.043997764587402\n",
            "epoch: 214, training loss: 21.36086082458496, validation loss: 11.043696403503418\n",
            "epoch: 215, training loss: 21.35905647277832, validation loss: 11.043391227722168\n",
            "epoch: 216, training loss: 21.35724639892578, validation loss: 11.043083190917969\n",
            "epoch: 217, training loss: 21.35546112060547, validation loss: 11.042752265930176\n",
            "epoch: 218, training loss: 21.353675842285156, validation loss: 11.042441368103027\n",
            "epoch: 219, training loss: 21.351892471313477, validation loss: 11.042110443115234\n",
            "epoch: 220, training loss: 21.350112915039062, validation loss: 11.041783332824707\n",
            "epoch: 221, training loss: 21.34834098815918, validation loss: 11.041446685791016\n",
            "epoch: 222, training loss: 21.34657096862793, validation loss: 11.041111946105957\n",
            "epoch: 223, training loss: 21.344812393188477, validation loss: 11.040775299072266\n",
            "epoch: 224, training loss: 21.343040466308594, validation loss: 11.040436744689941\n",
            "epoch: 225, training loss: 21.341299057006836, validation loss: 11.040085792541504\n",
            "epoch: 226, training loss: 21.340892791748047, validation loss: 11.040297508239746\n",
            "epoch: 227, training loss: 21.339336395263672, validation loss: 11.03992748260498\n",
            "epoch: 228, training loss: 21.337739944458008, validation loss: 11.039620399475098\n",
            "epoch: 229, training loss: 21.336143493652344, validation loss: 11.03927993774414\n",
            "epoch: 230, training loss: 21.334575653076172, validation loss: 11.038949966430664\n",
            "epoch: 231, training loss: 21.332992553710938, validation loss: 11.038606643676758\n",
            "epoch: 232, training loss: 21.3314266204834, validation loss: 11.038261413574219\n",
            "epoch: 233, training loss: 21.32987403869629, validation loss: 11.037921905517578\n",
            "epoch: 234, training loss: 21.328323364257812, validation loss: 11.037567138671875\n",
            "epoch: 235, training loss: 21.326772689819336, validation loss: 11.037221908569336\n",
            "epoch: 236, training loss: 21.325233459472656, validation loss: 11.036850929260254\n",
            "epoch: 237, training loss: 21.323698043823242, validation loss: 11.0364990234375\n",
            "epoch: 238, training loss: 21.322166442871094, validation loss: 11.036133766174316\n",
            "epoch: 239, training loss: 21.320646286010742, validation loss: 11.035776138305664\n",
            "epoch: 240, training loss: 21.31913185119629, validation loss: 11.035396575927734\n",
            "epoch: 241, training loss: 21.31761360168457, validation loss: 11.0350341796875\n",
            "epoch: 242, training loss: 21.316102981567383, validation loss: 11.034648895263672\n",
            "epoch: 243, training loss: 21.31460189819336, validation loss: 11.034278869628906\n",
            "epoch: 244, training loss: 21.313093185424805, validation loss: 11.033899307250977\n",
            "epoch: 245, training loss: 21.31159210205078, validation loss: 11.03350830078125\n",
            "epoch: 246, training loss: 21.310102462768555, validation loss: 11.033133506774902\n",
            "epoch: 247, training loss: 21.30861473083496, validation loss: 11.032735824584961\n",
            "epoch: 248, training loss: 21.307125091552734, validation loss: 11.03235912322998\n",
            "epoch: 249, training loss: 21.305648803710938, validation loss: 11.031961441040039\n",
            "epoch: 250, training loss: 21.30417251586914, validation loss: 11.031557083129883\n",
            "epoch: 251, training loss: 21.303735733032227, validation loss: 11.032151222229004\n",
            "epoch: 252, training loss: 21.302478790283203, validation loss: 11.03174877166748\n",
            "epoch: 253, training loss: 21.3011531829834, validation loss: 11.031408309936523\n",
            "epoch: 254, training loss: 21.299833297729492, validation loss: 11.031061172485352\n",
            "epoch: 255, training loss: 21.298526763916016, validation loss: 11.030715942382812\n",
            "epoch: 256, training loss: 21.29721450805664, validation loss: 11.030356407165527\n",
            "epoch: 257, training loss: 21.295923233032227, validation loss: 11.029993057250977\n",
            "epoch: 258, training loss: 21.294633865356445, validation loss: 11.02962875366211\n",
            "epoch: 259, training loss: 21.2933406829834, validation loss: 11.029258728027344\n",
            "epoch: 260, training loss: 21.292068481445312, validation loss: 11.028890609741211\n",
            "epoch: 261, training loss: 21.290796279907227, validation loss: 11.028522491455078\n",
            "epoch: 262, training loss: 21.28951644897461, validation loss: 11.028138160705566\n",
            "epoch: 263, training loss: 21.288240432739258, validation loss: 11.027763366699219\n",
            "epoch: 264, training loss: 21.28697395324707, validation loss: 11.027386665344238\n",
            "epoch: 265, training loss: 21.285717010498047, validation loss: 11.027008056640625\n",
            "epoch: 266, training loss: 21.28444480895996, validation loss: 11.026613235473633\n",
            "epoch: 267, training loss: 21.283191680908203, validation loss: 11.026239395141602\n",
            "epoch: 268, training loss: 21.281946182250977, validation loss: 11.02585220336914\n",
            "epoch: 269, training loss: 21.280696868896484, validation loss: 11.025471687316895\n",
            "epoch: 270, training loss: 21.27945327758789, validation loss: 11.025065422058105\n",
            "epoch: 271, training loss: 21.278207778930664, validation loss: 11.024679183959961\n",
            "epoch: 272, training loss: 21.276973724365234, validation loss: 11.024286270141602\n",
            "epoch: 273, training loss: 21.275733947753906, validation loss: 11.023887634277344\n",
            "epoch: 274, training loss: 21.27451515197754, validation loss: 11.023496627807617\n",
            "epoch: 275, training loss: 21.27327537536621, validation loss: 11.023109436035156\n",
            "epoch: 276, training loss: 21.272857666015625, validation loss: 11.023900985717773\n",
            "epoch: 277, training loss: 21.271835327148438, validation loss: 11.023507118225098\n",
            "epoch: 278, training loss: 21.270727157592773, validation loss: 11.023172378540039\n",
            "epoch: 279, training loss: 21.269624710083008, validation loss: 11.02284049987793\n",
            "epoch: 280, training loss: 21.268522262573242, validation loss: 11.022499084472656\n",
            "epoch: 281, training loss: 21.267425537109375, validation loss: 11.022156715393066\n",
            "epoch: 282, training loss: 21.26633644104004, validation loss: 11.021814346313477\n",
            "epoch: 283, training loss: 21.265241622924805, validation loss: 11.021468162536621\n",
            "epoch: 284, training loss: 21.264162063598633, validation loss: 11.021129608154297\n",
            "epoch: 285, training loss: 21.263090133666992, validation loss: 11.020781517028809\n",
            "epoch: 286, training loss: 21.262012481689453, validation loss: 11.02043628692627\n",
            "epoch: 287, training loss: 21.260942459106445, validation loss: 11.020094871520996\n",
            "epoch: 288, training loss: 21.259870529174805, validation loss: 11.01973819732666\n",
            "epoch: 289, training loss: 21.258804321289062, validation loss: 11.019378662109375\n",
            "epoch: 290, training loss: 21.25773811340332, validation loss: 11.01902961730957\n",
            "epoch: 291, training loss: 21.256671905517578, validation loss: 11.018682479858398\n",
            "epoch: 292, training loss: 21.25560760498047, validation loss: 11.01833438873291\n",
            "epoch: 293, training loss: 21.254554748535156, validation loss: 11.017989158630371\n",
            "epoch: 294, training loss: 21.253490447998047, validation loss: 11.0176362991333\n",
            "epoch: 295, training loss: 21.252431869506836, validation loss: 11.01728630065918\n",
            "epoch: 296, training loss: 21.251380920410156, validation loss: 11.016931533813477\n",
            "epoch: 297, training loss: 21.250337600708008, validation loss: 11.016582489013672\n",
            "epoch: 298, training loss: 21.249286651611328, validation loss: 11.016228675842285\n",
            "epoch: 299, training loss: 21.248239517211914, validation loss: 11.015876770019531\n",
            "epoch: 300, training loss: 21.2471981048584, validation loss: 11.015522003173828\n",
            "epoch: 301, training loss: 21.24674415588379, validation loss: 11.016565322875977\n",
            "epoch: 302, training loss: 21.245878219604492, validation loss: 11.016234397888184\n",
            "epoch: 303, training loss: 21.244943618774414, validation loss: 11.015958786010742\n",
            "epoch: 304, training loss: 21.24399757385254, validation loss: 11.015661239624023\n",
            "epoch: 305, training loss: 21.243045806884766, validation loss: 11.01537799835205\n",
            "epoch: 306, training loss: 21.24212074279785, validation loss: 11.01507568359375\n",
            "epoch: 307, training loss: 21.241193771362305, validation loss: 11.014789581298828\n",
            "epoch: 308, training loss: 21.240276336669922, validation loss: 11.014482498168945\n",
            "epoch: 309, training loss: 21.239349365234375, validation loss: 11.014177322387695\n",
            "epoch: 310, training loss: 21.238420486450195, validation loss: 11.013883590698242\n",
            "epoch: 311, training loss: 21.23750877380371, validation loss: 11.01358413696289\n",
            "epoch: 312, training loss: 21.236587524414062, validation loss: 11.013260841369629\n",
            "epoch: 313, training loss: 21.235671997070312, validation loss: 11.012954711914062\n",
            "epoch: 314, training loss: 21.234758377075195, validation loss: 11.012643814086914\n",
            "epoch: 315, training loss: 21.233854293823242, validation loss: 11.0123291015625\n",
            "epoch: 316, training loss: 21.232933044433594, validation loss: 11.01202392578125\n",
            "epoch: 317, training loss: 21.232030868530273, validation loss: 11.011700630187988\n",
            "epoch: 318, training loss: 21.23113250732422, validation loss: 11.011397361755371\n",
            "epoch: 319, training loss: 21.230228424072266, validation loss: 11.011073112487793\n",
            "epoch: 320, training loss: 21.229326248168945, validation loss: 11.010757446289062\n",
            "epoch: 321, training loss: 21.228437423706055, validation loss: 11.010443687438965\n",
            "epoch: 322, training loss: 21.22753143310547, validation loss: 11.0101318359375\n",
            "epoch: 323, training loss: 21.22662925720215, validation loss: 11.009807586669922\n",
            "epoch: 324, training loss: 21.225736618041992, validation loss: 11.009488105773926\n",
            "epoch: 325, training loss: 21.2248477935791, validation loss: 11.009175300598145\n",
            "epoch: 326, training loss: 21.224443435668945, validation loss: 11.010293960571289\n",
            "epoch: 327, training loss: 21.223737716674805, validation loss: 11.00999641418457\n",
            "epoch: 328, training loss: 21.222951889038086, validation loss: 11.009700775146484\n",
            "epoch: 329, training loss: 21.22215461730957, validation loss: 11.00943374633789\n",
            "epoch: 330, training loss: 21.221345901489258, validation loss: 11.00915241241455\n",
            "epoch: 331, training loss: 21.220552444458008, validation loss: 11.008861541748047\n",
            "epoch: 332, training loss: 21.219764709472656, validation loss: 11.008580207824707\n",
            "epoch: 333, training loss: 21.218969345092773, validation loss: 11.008296012878418\n",
            "epoch: 334, training loss: 21.218183517456055, validation loss: 11.008016586303711\n",
            "epoch: 335, training loss: 21.217391967773438, validation loss: 11.007728576660156\n",
            "epoch: 336, training loss: 21.216602325439453, validation loss: 11.00743293762207\n",
            "epoch: 337, training loss: 21.215818405151367, validation loss: 11.007150650024414\n",
            "epoch: 338, training loss: 21.215036392211914, validation loss: 11.006866455078125\n",
            "epoch: 339, training loss: 21.21424674987793, validation loss: 11.006576538085938\n",
            "epoch: 340, training loss: 21.213464736938477, validation loss: 11.0062894821167\n",
            "epoch: 341, training loss: 21.212675094604492, validation loss: 11.005998611450195\n",
            "epoch: 342, training loss: 21.211898803710938, validation loss: 11.005704879760742\n",
            "epoch: 343, training loss: 21.211135864257812, validation loss: 11.005414009094238\n",
            "epoch: 344, training loss: 21.210346221923828, validation loss: 11.005125999450684\n",
            "epoch: 345, training loss: 21.209571838378906, validation loss: 11.004839897155762\n",
            "epoch: 346, training loss: 21.208805084228516, validation loss: 11.00455093383789\n",
            "epoch: 347, training loss: 21.208030700683594, validation loss: 11.004244804382324\n",
            "epoch: 348, training loss: 21.207246780395508, validation loss: 11.003969192504883\n",
            "epoch: 349, training loss: 21.206483840942383, validation loss: 11.003669738769531\n",
            "epoch: 350, training loss: 21.205707550048828, validation loss: 11.003379821777344\n",
            "epoch: 351, training loss: 21.20524787902832, validation loss: 11.0045166015625\n",
            "epoch: 352, training loss: 21.204633712768555, validation loss: 11.004236221313477\n",
            "epoch: 353, training loss: 21.203947067260742, validation loss: 11.003951072692871\n",
            "epoch: 354, training loss: 21.2032413482666, validation loss: 11.003684043884277\n",
            "epoch: 355, training loss: 21.202537536621094, validation loss: 11.00340747833252\n",
            "epoch: 356, training loss: 21.201831817626953, validation loss: 11.003131866455078\n",
            "epoch: 357, training loss: 21.201143264770508, validation loss: 11.00285816192627\n",
            "epoch: 358, training loss: 21.200441360473633, validation loss: 11.00259017944336\n",
            "epoch: 359, training loss: 21.199748992919922, validation loss: 11.002320289611816\n",
            "epoch: 360, training loss: 21.19906234741211, validation loss: 11.002039909362793\n",
            "epoch: 361, training loss: 21.1983699798584, validation loss: 11.001770973205566\n",
            "epoch: 362, training loss: 21.19767951965332, validation loss: 11.001495361328125\n",
            "epoch: 363, training loss: 21.19700813293457, validation loss: 11.001219749450684\n",
            "epoch: 364, training loss: 21.19631576538086, validation loss: 11.000932693481445\n",
            "epoch: 365, training loss: 21.195634841918945, validation loss: 11.000664710998535\n",
            "epoch: 366, training loss: 21.194950103759766, validation loss: 11.00039291381836\n",
            "epoch: 367, training loss: 21.19428062438965, validation loss: 11.000102996826172\n",
            "epoch: 368, training loss: 21.1935977935791, validation loss: 10.99982738494873\n",
            "epoch: 369, training loss: 21.192914962768555, validation loss: 10.999551773071289\n",
            "epoch: 370, training loss: 21.19224739074707, validation loss: 10.999281883239746\n",
            "epoch: 371, training loss: 21.191570281982422, validation loss: 10.999007225036621\n",
            "epoch: 372, training loss: 21.190900802612305, validation loss: 10.998720169067383\n",
            "epoch: 373, training loss: 21.190227508544922, validation loss: 10.99844741821289\n",
            "epoch: 374, training loss: 21.189559936523438, validation loss: 10.99816608428955\n",
            "epoch: 375, training loss: 21.18890380859375, validation loss: 10.997880935668945\n",
            "epoch: 376, training loss: 21.188447952270508, validation loss: 10.999028205871582\n",
            "epoch: 377, training loss: 21.187923431396484, validation loss: 10.998809814453125\n",
            "epoch: 378, training loss: 21.18734359741211, validation loss: 10.99856185913086\n",
            "epoch: 379, training loss: 21.186731338500977, validation loss: 10.998306274414062\n",
            "epoch: 380, training loss: 21.186132431030273, validation loss: 10.998053550720215\n",
            "epoch: 381, training loss: 21.185531616210938, validation loss: 10.997815132141113\n",
            "epoch: 382, training loss: 21.1849308013916, validation loss: 10.997553825378418\n",
            "epoch: 383, training loss: 21.184326171875, validation loss: 10.997312545776367\n",
            "epoch: 384, training loss: 21.183725357055664, validation loss: 10.997062683105469\n",
            "epoch: 385, training loss: 21.18313980102539, validation loss: 10.996805191040039\n",
            "epoch: 386, training loss: 21.182552337646484, validation loss: 10.996554374694824\n",
            "epoch: 387, training loss: 21.181949615478516, validation loss: 10.996304512023926\n",
            "epoch: 388, training loss: 21.18136215209961, validation loss: 10.996048927307129\n",
            "epoch: 389, training loss: 21.1807804107666, validation loss: 10.995790481567383\n",
            "epoch: 390, training loss: 21.18019676208496, validation loss: 10.995542526245117\n",
            "epoch: 391, training loss: 21.179594039916992, validation loss: 10.995292663574219\n",
            "epoch: 392, training loss: 21.179014205932617, validation loss: 10.99502944946289\n",
            "epoch: 393, training loss: 21.178434371948242, validation loss: 10.99477767944336\n",
            "epoch: 394, training loss: 21.1778564453125, validation loss: 10.994526863098145\n",
            "epoch: 395, training loss: 21.177257537841797, validation loss: 10.994279861450195\n",
            "epoch: 396, training loss: 21.176685333251953, validation loss: 10.994019508361816\n",
            "epoch: 397, training loss: 21.176101684570312, validation loss: 10.993762969970703\n",
            "epoch: 398, training loss: 21.175519943237305, validation loss: 10.993514060974121\n",
            "epoch: 399, training loss: 21.1749324798584, validation loss: 10.993254661560059\n",
            "epoch: 400, training loss: 21.174365997314453, validation loss: 10.992993354797363\n",
            "epoch: 401, training loss: 21.1739444732666, validation loss: 10.994138717651367\n",
            "epoch: 402, training loss: 21.173500061035156, validation loss: 10.99398136138916\n",
            "epoch: 403, training loss: 21.172996520996094, validation loss: 10.993753433227539\n",
            "epoch: 404, training loss: 21.172475814819336, validation loss: 10.99350643157959\n",
            "epoch: 405, training loss: 21.171951293945312, validation loss: 10.993290901184082\n",
            "epoch: 406, training loss: 21.17142105102539, validation loss: 10.993050575256348\n",
            "epoch: 407, training loss: 21.170896530151367, validation loss: 10.992814064025879\n",
            "epoch: 408, training loss: 21.170379638671875, validation loss: 10.992585182189941\n",
            "epoch: 409, training loss: 21.16986846923828, validation loss: 10.992351531982422\n",
            "epoch: 410, training loss: 21.169355392456055, validation loss: 10.992122650146484\n",
            "epoch: 411, training loss: 21.168834686279297, validation loss: 10.991896629333496\n",
            "epoch: 412, training loss: 21.16832733154297, validation loss: 10.991660118103027\n",
            "epoch: 413, training loss: 21.16780662536621, validation loss: 10.99142837524414\n",
            "epoch: 414, training loss: 21.167295455932617, validation loss: 10.99120044708252\n",
            "epoch: 415, training loss: 21.16678237915039, validation loss: 10.99097728729248\n",
            "epoch: 416, training loss: 21.16627311706543, validation loss: 10.990741729736328\n",
            "epoch: 417, training loss: 21.165767669677734, validation loss: 10.990513801574707\n",
            "epoch: 418, training loss: 21.165267944335938, validation loss: 10.990285873413086\n",
            "epoch: 419, training loss: 21.16476058959961, validation loss: 10.990046501159668\n",
            "epoch: 420, training loss: 21.164257049560547, validation loss: 10.989821434020996\n",
            "epoch: 421, training loss: 21.16374969482422, validation loss: 10.989596366882324\n",
            "epoch: 422, training loss: 21.163249969482422, validation loss: 10.989351272583008\n",
            "epoch: 423, training loss: 21.16275405883789, validation loss: 10.98912525177002\n",
            "epoch: 424, training loss: 21.162248611450195, validation loss: 10.988895416259766\n",
            "epoch: 425, training loss: 21.16175079345703, validation loss: 10.988680839538574\n",
            "epoch: 426, training loss: 21.161361694335938, validation loss: 10.989738464355469\n",
            "epoch: 427, training loss: 21.160959243774414, validation loss: 10.989659309387207\n",
            "epoch: 428, training loss: 21.16051483154297, validation loss: 10.989480018615723\n",
            "epoch: 429, training loss: 21.160053253173828, validation loss: 10.98929214477539\n",
            "epoch: 430, training loss: 21.159582138061523, validation loss: 10.989127159118652\n",
            "epoch: 431, training loss: 21.15912437438965, validation loss: 10.988941192626953\n",
            "epoch: 432, training loss: 21.15865707397461, validation loss: 10.988763809204102\n",
            "epoch: 433, training loss: 21.158199310302734, validation loss: 10.988577842712402\n",
            "epoch: 434, training loss: 21.15773582458496, validation loss: 10.988395690917969\n",
            "epoch: 435, training loss: 21.15728187561035, validation loss: 10.988211631774902\n",
            "epoch: 436, training loss: 21.15683364868164, validation loss: 10.988035202026367\n",
            "epoch: 437, training loss: 21.156375885009766, validation loss: 10.987852096557617\n",
            "epoch: 438, training loss: 21.15593147277832, validation loss: 10.987667083740234\n",
            "epoch: 439, training loss: 21.15547752380371, validation loss: 10.9874906539917\n",
            "epoch: 440, training loss: 21.155031204223633, validation loss: 10.987290382385254\n",
            "epoch: 441, training loss: 21.15458106994629, validation loss: 10.987110137939453\n",
            "epoch: 442, training loss: 21.15414047241211, validation loss: 10.986936569213867\n",
            "epoch: 443, training loss: 21.153690338134766, validation loss: 10.986732482910156\n",
            "epoch: 444, training loss: 21.153249740600586, validation loss: 10.98654842376709\n",
            "epoch: 445, training loss: 21.15280532836914, validation loss: 10.986359596252441\n",
            "epoch: 446, training loss: 21.152359008789062, validation loss: 10.98617172241211\n",
            "epoch: 447, training loss: 21.15191650390625, validation loss: 10.985986709594727\n",
            "epoch: 448, training loss: 21.15148162841797, validation loss: 10.98580265045166\n",
            "epoch: 449, training loss: 21.151046752929688, validation loss: 10.985618591308594\n",
            "epoch: 450, training loss: 21.150611877441406, validation loss: 10.985427856445312\n",
            "epoch: 451, training loss: 21.1502742767334, validation loss: 10.986368179321289\n",
            "epoch: 452, training loss: 21.149925231933594, validation loss: 10.986361503601074\n",
            "epoch: 453, training loss: 21.149532318115234, validation loss: 10.98620891571045\n",
            "epoch: 454, training loss: 21.149124145507812, validation loss: 10.986072540283203\n",
            "epoch: 455, training loss: 21.14872169494629, validation loss: 10.985919952392578\n",
            "epoch: 456, training loss: 21.14830780029297, validation loss: 10.985769271850586\n",
            "epoch: 457, training loss: 21.147903442382812, validation loss: 10.985628128051758\n",
            "epoch: 458, training loss: 21.147485733032227, validation loss: 10.985489845275879\n",
            "epoch: 459, training loss: 21.147071838378906, validation loss: 10.985346794128418\n",
            "epoch: 460, training loss: 21.146677017211914, validation loss: 10.985186576843262\n",
            "epoch: 461, training loss: 21.146270751953125, validation loss: 10.985036849975586\n",
            "epoch: 462, training loss: 21.14586067199707, validation loss: 10.984895706176758\n",
            "epoch: 463, training loss: 21.145458221435547, validation loss: 10.984750747680664\n",
            "epoch: 464, training loss: 21.145061492919922, validation loss: 10.984597206115723\n",
            "epoch: 465, training loss: 21.144655227661133, validation loss: 10.98444652557373\n",
            "epoch: 466, training loss: 21.144256591796875, validation loss: 10.984296798706055\n",
            "epoch: 467, training loss: 21.143857955932617, validation loss: 10.984148025512695\n",
            "epoch: 468, training loss: 21.14346694946289, validation loss: 10.983997344970703\n",
            "epoch: 469, training loss: 21.143062591552734, validation loss: 10.983844757080078\n",
            "epoch: 470, training loss: 21.14266586303711, validation loss: 10.9837007522583\n",
            "epoch: 471, training loss: 21.14227294921875, validation loss: 10.983555793762207\n",
            "epoch: 472, training loss: 21.14188575744629, validation loss: 10.983396530151367\n",
            "epoch: 473, training loss: 21.141475677490234, validation loss: 10.983240127563477\n",
            "epoch: 474, training loss: 21.14109230041504, validation loss: 10.983088493347168\n",
            "epoch: 475, training loss: 21.14069938659668, validation loss: 10.982935905456543\n",
            "epoch: 476, training loss: 21.140310287475586, validation loss: 10.983805656433105\n",
            "epoch: 477, training loss: 21.13997459411621, validation loss: 10.983848571777344\n",
            "epoch: 478, training loss: 21.139619827270508, validation loss: 10.98375415802002\n",
            "epoch: 479, training loss: 21.139245986938477, validation loss: 10.983635902404785\n",
            "epoch: 480, training loss: 21.138877868652344, validation loss: 10.983510971069336\n",
            "epoch: 481, training loss: 21.13850975036621, validation loss: 10.98340129852295\n",
            "epoch: 482, training loss: 21.138132095336914, validation loss: 10.983290672302246\n",
            "epoch: 483, training loss: 21.137779235839844, validation loss: 10.983171463012695\n",
            "epoch: 484, training loss: 21.137399673461914, validation loss: 10.983052253723145\n",
            "epoch: 485, training loss: 21.137033462524414, validation loss: 10.982930183410645\n",
            "epoch: 486, training loss: 21.13667869567871, validation loss: 10.982810974121094\n",
            "epoch: 487, training loss: 21.136310577392578, validation loss: 10.98268985748291\n",
            "epoch: 488, training loss: 21.135953903198242, validation loss: 10.982556343078613\n",
            "epoch: 489, training loss: 21.13558578491211, validation loss: 10.982439994812012\n",
            "epoch: 490, training loss: 21.13522720336914, validation loss: 10.98232650756836\n",
            "epoch: 491, training loss: 21.13486671447754, validation loss: 10.982205390930176\n",
            "epoch: 492, training loss: 21.134521484375, validation loss: 10.982067108154297\n",
            "epoch: 493, training loss: 21.134153366088867, validation loss: 10.981955528259277\n",
            "epoch: 494, training loss: 21.13380241394043, validation loss: 10.98183822631836\n",
            "epoch: 495, training loss: 21.13344383239746, validation loss: 10.98171329498291\n",
            "epoch: 496, training loss: 21.13309097290039, validation loss: 10.981584548950195\n",
            "epoch: 497, training loss: 21.132740020751953, validation loss: 10.981450080871582\n",
            "epoch: 498, training loss: 21.13237762451172, validation loss: 10.98132610321045\n",
            "epoch: 499, training loss: 21.132038116455078, validation loss: 10.981185913085938\n",
            "epoch: 500, training loss: 21.131671905517578, validation loss: 10.98107624053955\n",
            "Predictions for dearborn generated!\n",
            "\n",
            "Done printing dearborn predictions\n",
            "----------------------------------------------------------------------\n",
            "epoch: 1, training loss: 16.382001876831055, validation loss: 19.67474365234375\n",
            "epoch: 2, training loss: 16.327333450317383, validation loss: 19.693859100341797\n",
            "epoch: 3, training loss: 16.289047241210938, validation loss: 19.69184112548828\n",
            "epoch: 4, training loss: 16.256040573120117, validation loss: 19.683307647705078\n",
            "epoch: 5, training loss: 16.224929809570312, validation loss: 19.673612594604492\n",
            "epoch: 6, training loss: 16.194841384887695, validation loss: 19.664535522460938\n",
            "epoch: 7, training loss: 16.16566276550293, validation loss: 19.656299591064453\n",
            "epoch: 8, training loss: 16.13755989074707, validation loss: 19.648971557617188\n",
            "epoch: 9, training loss: 16.11056137084961, validation loss: 19.642536163330078\n",
            "epoch: 10, training loss: 16.0847110748291, validation loss: 19.636911392211914\n",
            "epoch: 11, training loss: 16.06013298034668, validation loss: 19.631900787353516\n",
            "epoch: 12, training loss: 16.03678321838379, validation loss: 19.62735939025879\n",
            "epoch: 13, training loss: 16.01466178894043, validation loss: 19.6231632232666\n",
            "epoch: 14, training loss: 15.99372673034668, validation loss: 19.619400024414062\n",
            "epoch: 15, training loss: 15.97397232055664, validation loss: 19.616025924682617\n",
            "epoch: 16, training loss: 15.955318450927734, validation loss: 19.61305809020996\n",
            "epoch: 17, training loss: 15.937746047973633, validation loss: 19.610393524169922\n",
            "epoch: 18, training loss: 15.921182632446289, validation loss: 19.6080322265625\n",
            "epoch: 19, training loss: 15.90557861328125, validation loss: 19.605989456176758\n",
            "epoch: 20, training loss: 15.890876770019531, validation loss: 19.604215621948242\n",
            "epoch: 21, training loss: 15.877065658569336, validation loss: 19.6026668548584\n",
            "epoch: 22, training loss: 15.864105224609375, validation loss: 19.6013240814209\n",
            "epoch: 23, training loss: 15.85193920135498, validation loss: 19.6002197265625\n",
            "epoch: 24, training loss: 15.840523719787598, validation loss: 19.59930419921875\n",
            "epoch: 25, training loss: 15.829814910888672, validation loss: 19.598569869995117\n",
            "epoch: 26, training loss: 15.8204984664917, validation loss: 19.59807777404785\n",
            "epoch: 27, training loss: 15.811797142028809, validation loss: 19.597763061523438\n",
            "epoch: 28, training loss: 15.803622245788574, validation loss: 19.597578048706055\n",
            "epoch: 29, training loss: 15.795905113220215, validation loss: 19.59751319885254\n",
            "epoch: 30, training loss: 15.788629531860352, validation loss: 19.59758949279785\n",
            "epoch: 31, training loss: 15.781743049621582, validation loss: 19.597715377807617\n",
            "epoch: 32, training loss: 15.775250434875488, validation loss: 19.597965240478516\n",
            "epoch: 33, training loss: 15.769124984741211, validation loss: 19.59830093383789\n",
            "epoch: 34, training loss: 15.763335227966309, validation loss: 19.59870719909668\n",
            "epoch: 35, training loss: 15.757869720458984, validation loss: 19.599180221557617\n",
            "epoch: 36, training loss: 15.752699851989746, validation loss: 19.599727630615234\n",
            "epoch: 37, training loss: 15.747827529907227, validation loss: 19.600332260131836\n",
            "epoch: 38, training loss: 15.743217468261719, validation loss: 19.601001739501953\n",
            "epoch: 39, training loss: 15.738872528076172, validation loss: 19.601722717285156\n",
            "epoch: 40, training loss: 15.734772682189941, validation loss: 19.602523803710938\n",
            "epoch: 41, training loss: 15.730905532836914, validation loss: 19.603330612182617\n",
            "epoch: 42, training loss: 15.727261543273926, validation loss: 19.60422706604004\n",
            "epoch: 43, training loss: 15.723822593688965, validation loss: 19.605161666870117\n",
            "epoch: 44, training loss: 15.720579147338867, validation loss: 19.606143951416016\n",
            "epoch: 45, training loss: 15.71753215789795, validation loss: 19.607145309448242\n",
            "epoch: 46, training loss: 15.714654922485352, validation loss: 19.608213424682617\n",
            "epoch: 47, training loss: 15.711945533752441, validation loss: 19.609285354614258\n",
            "epoch: 48, training loss: 15.709404945373535, validation loss: 19.61041831970215\n",
            "epoch: 49, training loss: 15.706992149353027, validation loss: 19.611583709716797\n",
            "epoch: 50, training loss: 15.704727172851562, validation loss: 19.612764358520508\n",
            "epoch: 51, training loss: 15.702451705932617, validation loss: 19.614229202270508\n",
            "epoch: 52, training loss: 15.700433731079102, validation loss: 19.615530014038086\n",
            "epoch: 53, training loss: 15.69859790802002, validation loss: 19.616783142089844\n",
            "epoch: 54, training loss: 15.696892738342285, validation loss: 19.617996215820312\n",
            "epoch: 55, training loss: 15.695300102233887, validation loss: 19.619239807128906\n",
            "epoch: 56, training loss: 15.69379997253418, validation loss: 19.620450973510742\n",
            "epoch: 57, training loss: 15.692397117614746, validation loss: 19.62165641784668\n",
            "epoch: 58, training loss: 15.69107723236084, validation loss: 19.62291717529297\n",
            "epoch: 59, training loss: 15.689826965332031, validation loss: 19.62411117553711\n",
            "epoch: 60, training loss: 15.68864917755127, validation loss: 19.62535285949707\n",
            "epoch: 61, training loss: 15.687540054321289, validation loss: 19.626588821411133\n",
            "epoch: 62, training loss: 15.686502456665039, validation loss: 19.627798080444336\n",
            "epoch: 63, training loss: 15.685524940490723, validation loss: 19.629045486450195\n",
            "epoch: 64, training loss: 15.684608459472656, validation loss: 19.630279541015625\n",
            "epoch: 65, training loss: 15.683754920959473, validation loss: 19.63150978088379\n",
            "epoch: 66, training loss: 15.682951927185059, validation loss: 19.632753372192383\n",
            "epoch: 67, training loss: 15.682205200195312, validation loss: 19.63396644592285\n",
            "epoch: 68, training loss: 15.681504249572754, validation loss: 19.63519287109375\n",
            "epoch: 69, training loss: 15.680852890014648, validation loss: 19.63641929626465\n",
            "epoch: 70, training loss: 15.680249214172363, validation loss: 19.637645721435547\n",
            "epoch: 71, training loss: 15.679682731628418, validation loss: 19.638872146606445\n",
            "epoch: 72, training loss: 15.679157257080078, validation loss: 19.640071868896484\n",
            "epoch: 73, training loss: 15.67867660522461, validation loss: 19.64130210876465\n",
            "epoch: 74, training loss: 15.678238868713379, validation loss: 19.642499923706055\n",
            "epoch: 75, training loss: 15.677827835083008, validation loss: 19.643686294555664\n",
            "epoch: 76, training loss: 15.677088737487793, validation loss: 19.645259857177734\n",
            "epoch: 77, training loss: 15.676532745361328, validation loss: 19.646591186523438\n",
            "epoch: 78, training loss: 15.676109313964844, validation loss: 19.647815704345703\n",
            "epoch: 79, training loss: 15.67573070526123, validation loss: 19.64894676208496\n",
            "epoch: 80, training loss: 15.67542839050293, validation loss: 19.650062561035156\n",
            "epoch: 81, training loss: 15.67515754699707, validation loss: 19.651134490966797\n",
            "epoch: 82, training loss: 15.674908638000488, validation loss: 19.652206420898438\n",
            "epoch: 83, training loss: 15.67470932006836, validation loss: 19.653261184692383\n",
            "epoch: 84, training loss: 15.674516677856445, validation loss: 19.654287338256836\n",
            "epoch: 85, training loss: 15.674358367919922, validation loss: 19.655311584472656\n",
            "epoch: 86, training loss: 15.674215316772461, validation loss: 19.656330108642578\n",
            "epoch: 87, training loss: 15.674081802368164, validation loss: 19.65732765197754\n",
            "epoch: 88, training loss: 15.673978805541992, validation loss: 19.65833854675293\n",
            "epoch: 89, training loss: 15.6738920211792, validation loss: 19.65929412841797\n",
            "epoch: 90, training loss: 15.673805236816406, validation loss: 19.660259246826172\n",
            "epoch: 91, training loss: 15.673742294311523, validation loss: 19.661251068115234\n",
            "epoch: 92, training loss: 15.673698425292969, validation loss: 19.66219711303711\n",
            "epoch: 93, training loss: 15.67365837097168, validation loss: 19.663135528564453\n",
            "epoch: 94, training loss: 15.673633575439453, validation loss: 19.664077758789062\n",
            "epoch: 95, training loss: 15.673626899719238, validation loss: 19.66500473022461\n",
            "epoch: 96, training loss: 15.673626899719238, validation loss: 19.665925979614258\n",
            "epoch: 97, training loss: 15.673640251159668, validation loss: 19.66680145263672\n",
            "epoch: 98, training loss: 15.673654556274414, validation loss: 19.66770362854004\n",
            "epoch: 99, training loss: 15.673690795898438, validation loss: 19.668582916259766\n",
            "epoch: 100, training loss: 15.673730850219727, validation loss: 19.669464111328125\n",
            "epoch: 101, training loss: 15.673388481140137, validation loss: 19.670637130737305\n",
            "epoch: 102, training loss: 15.673226356506348, validation loss: 19.671630859375\n",
            "epoch: 103, training loss: 15.673148155212402, validation loss: 19.672561645507812\n",
            "epoch: 104, training loss: 15.673105239868164, validation loss: 19.67339324951172\n",
            "epoch: 105, training loss: 15.673101425170898, validation loss: 19.674222946166992\n",
            "epoch: 106, training loss: 15.673114776611328, validation loss: 19.675004959106445\n",
            "epoch: 107, training loss: 15.673151016235352, validation loss: 19.67576789855957\n",
            "epoch: 108, training loss: 15.673203468322754, validation loss: 19.676551818847656\n",
            "epoch: 109, training loss: 15.673262596130371, validation loss: 19.67728614807129\n",
            "epoch: 110, training loss: 15.673331260681152, validation loss: 19.67801284790039\n",
            "epoch: 111, training loss: 15.673404693603516, validation loss: 19.67874526977539\n",
            "epoch: 112, training loss: 15.673491477966309, validation loss: 19.679447174072266\n",
            "epoch: 113, training loss: 15.673579216003418, validation loss: 19.680118560791016\n",
            "epoch: 114, training loss: 15.673676490783691, validation loss: 19.680809020996094\n",
            "epoch: 115, training loss: 15.673771858215332, validation loss: 19.68147850036621\n",
            "epoch: 116, training loss: 15.673880577087402, validation loss: 19.68214988708496\n",
            "epoch: 117, training loss: 15.67398738861084, validation loss: 19.682798385620117\n",
            "epoch: 118, training loss: 15.674092292785645, validation loss: 19.683454513549805\n",
            "epoch: 119, training loss: 15.674210548400879, validation loss: 19.68408966064453\n",
            "epoch: 120, training loss: 15.674327850341797, validation loss: 19.684730529785156\n",
            "epoch: 121, training loss: 15.674442291259766, validation loss: 19.685344696044922\n",
            "epoch: 122, training loss: 15.674568176269531, validation loss: 19.68596839904785\n",
            "epoch: 123, training loss: 15.674692153930664, validation loss: 19.68657684326172\n",
            "epoch: 124, training loss: 15.674817085266113, validation loss: 19.68718147277832\n",
            "epoch: 125, training loss: 15.67495059967041, validation loss: 19.687782287597656\n",
            "epoch: 126, training loss: 15.674711227416992, validation loss: 19.688833236694336\n",
            "epoch: 127, training loss: 15.67462158203125, validation loss: 19.689672470092773\n",
            "epoch: 128, training loss: 15.67458724975586, validation loss: 19.6904296875\n",
            "epoch: 129, training loss: 15.674598693847656, validation loss: 19.691110610961914\n",
            "epoch: 130, training loss: 15.674641609191895, validation loss: 19.691747665405273\n",
            "epoch: 131, training loss: 15.674714088439941, validation loss: 19.692340850830078\n",
            "epoch: 132, training loss: 15.674787521362305, validation loss: 19.69291877746582\n",
            "epoch: 133, training loss: 15.67487907409668, validation loss: 19.693458557128906\n",
            "epoch: 134, training loss: 15.67498779296875, validation loss: 19.694002151489258\n",
            "epoch: 135, training loss: 15.675094604492188, validation loss: 19.694536209106445\n",
            "epoch: 136, training loss: 15.675193786621094, validation loss: 19.695035934448242\n",
            "epoch: 137, training loss: 15.675314903259277, validation loss: 19.6955623626709\n",
            "epoch: 138, training loss: 15.675433158874512, validation loss: 19.696062088012695\n",
            "epoch: 139, training loss: 15.67554759979248, validation loss: 19.696557998657227\n",
            "epoch: 140, training loss: 15.675667762756348, validation loss: 19.697040557861328\n",
            "epoch: 141, training loss: 15.675793647766113, validation loss: 19.697509765625\n",
            "epoch: 142, training loss: 15.675923347473145, validation loss: 19.69799041748047\n",
            "epoch: 143, training loss: 15.676042556762695, validation loss: 19.698436737060547\n",
            "epoch: 144, training loss: 15.676172256469727, validation loss: 19.698917388916016\n",
            "epoch: 145, training loss: 15.676291465759277, validation loss: 19.699371337890625\n",
            "epoch: 146, training loss: 15.676421165466309, validation loss: 19.699817657470703\n",
            "epoch: 147, training loss: 15.676551818847656, validation loss: 19.700254440307617\n",
            "epoch: 148, training loss: 15.676677703857422, validation loss: 19.700687408447266\n",
            "epoch: 149, training loss: 15.676807403564453, validation loss: 19.701120376586914\n",
            "epoch: 150, training loss: 15.676939010620117, validation loss: 19.701539993286133\n",
            "epoch: 151, training loss: 15.676774978637695, validation loss: 19.702285766601562\n",
            "epoch: 152, training loss: 15.676713943481445, validation loss: 19.702909469604492\n",
            "epoch: 153, training loss: 15.676711082458496, validation loss: 19.703462600708008\n",
            "epoch: 154, training loss: 15.67673397064209, validation loss: 19.703954696655273\n",
            "epoch: 155, training loss: 15.676770210266113, validation loss: 19.704456329345703\n",
            "epoch: 156, training loss: 15.676826477050781, validation loss: 19.70487403869629\n",
            "epoch: 157, training loss: 15.676901817321777, validation loss: 19.705318450927734\n",
            "epoch: 158, training loss: 15.676982879638672, validation loss: 19.705724716186523\n",
            "epoch: 159, training loss: 15.677066802978516, validation loss: 19.70612907409668\n",
            "epoch: 160, training loss: 15.677155494689941, validation loss: 19.706533432006836\n",
            "epoch: 161, training loss: 15.677253723144531, validation loss: 19.70692253112793\n",
            "epoch: 162, training loss: 15.677349090576172, validation loss: 19.707290649414062\n",
            "epoch: 163, training loss: 15.677433967590332, validation loss: 19.70765495300293\n",
            "epoch: 164, training loss: 15.677552223205566, validation loss: 19.708023071289062\n",
            "epoch: 165, training loss: 15.677641868591309, validation loss: 19.7083683013916\n",
            "epoch: 166, training loss: 15.67773723602295, validation loss: 19.708723068237305\n",
            "epoch: 167, training loss: 15.677834510803223, validation loss: 19.709074020385742\n",
            "epoch: 168, training loss: 15.67794132232666, validation loss: 19.70944595336914\n",
            "epoch: 169, training loss: 15.678040504455566, validation loss: 19.70978355407715\n",
            "epoch: 170, training loss: 15.678139686584473, validation loss: 19.71010398864746\n",
            "epoch: 171, training loss: 15.678241729736328, validation loss: 19.710447311401367\n",
            "epoch: 172, training loss: 15.6783447265625, validation loss: 19.710763931274414\n",
            "epoch: 173, training loss: 15.678447723388672, validation loss: 19.71108627319336\n",
            "epoch: 174, training loss: 15.678552627563477, validation loss: 19.711389541625977\n",
            "epoch: 175, training loss: 15.6786470413208, validation loss: 19.71170997619629\n",
            "epoch: 176, training loss: 15.678572654724121, validation loss: 19.71213150024414\n",
            "epoch: 177, training loss: 15.678556442260742, validation loss: 19.712482452392578\n",
            "epoch: 178, training loss: 15.678549766540527, validation loss: 19.712858200073242\n",
            "epoch: 179, training loss: 15.678577423095703, validation loss: 19.71320915222168\n",
            "epoch: 180, training loss: 15.678617477416992, validation loss: 19.713510513305664\n",
            "epoch: 181, training loss: 15.678671836853027, validation loss: 19.713851928710938\n",
            "epoch: 182, training loss: 15.678730010986328, validation loss: 19.714160919189453\n",
            "epoch: 183, training loss: 15.678786277770996, validation loss: 19.714427947998047\n",
            "epoch: 184, training loss: 15.678853034973145, validation loss: 19.714731216430664\n",
            "epoch: 185, training loss: 15.678912162780762, validation loss: 19.715009689331055\n",
            "epoch: 186, training loss: 15.67900276184082, validation loss: 19.71527099609375\n",
            "epoch: 187, training loss: 15.679075241088867, validation loss: 19.71554946899414\n",
            "epoch: 188, training loss: 15.679142951965332, validation loss: 19.71579933166504\n",
            "epoch: 189, training loss: 15.679222106933594, validation loss: 19.71607780456543\n",
            "epoch: 190, training loss: 15.67929458618164, validation loss: 19.716320037841797\n",
            "epoch: 191, training loss: 15.679367065429688, validation loss: 19.716583251953125\n",
            "epoch: 192, training loss: 15.679449081420898, validation loss: 19.71681022644043\n",
            "epoch: 193, training loss: 15.679523468017578, validation loss: 19.717052459716797\n",
            "epoch: 194, training loss: 15.679600715637207, validation loss: 19.717308044433594\n",
            "epoch: 195, training loss: 15.679677963256836, validation loss: 19.71752166748047\n",
            "epoch: 196, training loss: 15.679750442504883, validation loss: 19.717784881591797\n",
            "epoch: 197, training loss: 15.679832458496094, validation loss: 19.718013763427734\n",
            "epoch: 198, training loss: 15.679899215698242, validation loss: 19.718225479125977\n",
            "epoch: 199, training loss: 15.679980278015137, validation loss: 19.71845817565918\n",
            "epoch: 200, training loss: 15.680049896240234, validation loss: 19.718679428100586\n",
            "epoch: 201, training loss: 15.680038452148438, validation loss: 19.718948364257812\n",
            "epoch: 202, training loss: 15.6800537109375, validation loss: 19.719167709350586\n",
            "epoch: 203, training loss: 15.680073738098145, validation loss: 19.719406127929688\n",
            "epoch: 204, training loss: 15.680103302001953, validation loss: 19.719676971435547\n",
            "epoch: 205, training loss: 15.680139541625977, validation loss: 19.719877243041992\n",
            "epoch: 206, training loss: 15.68018913269043, validation loss: 19.720115661621094\n",
            "epoch: 207, training loss: 15.68023681640625, validation loss: 19.720346450805664\n",
            "epoch: 208, training loss: 15.680282592773438, validation loss: 19.720577239990234\n",
            "epoch: 209, training loss: 15.680325508117676, validation loss: 19.720794677734375\n",
            "epoch: 210, training loss: 15.680377006530762, validation loss: 19.721017837524414\n",
            "epoch: 211, training loss: 15.680431365966797, validation loss: 19.721202850341797\n",
            "epoch: 212, training loss: 15.680481910705566, validation loss: 19.72144317626953\n",
            "epoch: 213, training loss: 15.68053150177002, validation loss: 19.721641540527344\n",
            "epoch: 214, training loss: 15.680590629577637, validation loss: 19.72187042236328\n",
            "epoch: 215, training loss: 15.680642127990723, validation loss: 19.722049713134766\n",
            "epoch: 216, training loss: 15.680706024169922, validation loss: 19.722261428833008\n",
            "epoch: 217, training loss: 15.680756568908691, validation loss: 19.72246742248535\n",
            "epoch: 218, training loss: 15.680808067321777, validation loss: 19.722660064697266\n",
            "epoch: 219, training loss: 15.680862426757812, validation loss: 19.72283172607422\n",
            "epoch: 220, training loss: 15.680925369262695, validation loss: 19.723024368286133\n",
            "epoch: 221, training loss: 15.680980682373047, validation loss: 19.723222732543945\n",
            "epoch: 222, training loss: 15.681034088134766, validation loss: 19.723419189453125\n",
            "epoch: 223, training loss: 15.68108081817627, validation loss: 19.723581314086914\n",
            "epoch: 224, training loss: 15.68114185333252, validation loss: 19.723764419555664\n",
            "epoch: 225, training loss: 15.681193351745605, validation loss: 19.72397232055664\n",
            "epoch: 226, training loss: 15.681192398071289, validation loss: 19.724199295043945\n",
            "epoch: 227, training loss: 15.681203842163086, validation loss: 19.724395751953125\n",
            "epoch: 228, training loss: 15.681233406066895, validation loss: 19.72460174560547\n",
            "epoch: 229, training loss: 15.68126106262207, validation loss: 19.72477912902832\n",
            "epoch: 230, training loss: 15.681292533874512, validation loss: 19.724973678588867\n",
            "epoch: 231, training loss: 15.681325912475586, validation loss: 19.725133895874023\n",
            "epoch: 232, training loss: 15.681366920471191, validation loss: 19.725318908691406\n",
            "epoch: 233, training loss: 15.681407928466797, validation loss: 19.72547149658203\n",
            "epoch: 234, training loss: 15.681452751159668, validation loss: 19.72563362121582\n",
            "epoch: 235, training loss: 15.681488037109375, validation loss: 19.725799560546875\n",
            "epoch: 236, training loss: 15.681522369384766, validation loss: 19.7259521484375\n",
            "epoch: 237, training loss: 15.681578636169434, validation loss: 19.72612190246582\n",
            "epoch: 238, training loss: 15.681618690490723, validation loss: 19.726274490356445\n",
            "epoch: 239, training loss: 15.681654930114746, validation loss: 19.72641372680664\n",
            "epoch: 240, training loss: 15.681702613830566, validation loss: 19.72654151916504\n",
            "epoch: 241, training loss: 15.681751251220703, validation loss: 19.726688385009766\n",
            "epoch: 242, training loss: 15.681783676147461, validation loss: 19.72684097290039\n",
            "epoch: 243, training loss: 15.6818265914917, validation loss: 19.72698974609375\n",
            "epoch: 244, training loss: 15.681872367858887, validation loss: 19.72711944580078\n",
            "epoch: 245, training loss: 15.68192195892334, validation loss: 19.72726058959961\n",
            "epoch: 246, training loss: 15.68195915222168, validation loss: 19.727420806884766\n",
            "epoch: 247, training loss: 15.682003021240234, validation loss: 19.72752571105957\n",
            "epoch: 248, training loss: 15.682042121887207, validation loss: 19.727664947509766\n",
            "epoch: 249, training loss: 15.682087898254395, validation loss: 19.727806091308594\n",
            "epoch: 250, training loss: 15.682132720947266, validation loss: 19.72793197631836\n",
            "epoch: 251, training loss: 15.68215274810791, validation loss: 19.727998733520508\n",
            "epoch: 252, training loss: 15.682193756103516, validation loss: 19.72807502746582\n",
            "epoch: 253, training loss: 15.682229995727539, validation loss: 19.72815704345703\n",
            "epoch: 254, training loss: 15.68226146697998, validation loss: 19.728235244750977\n",
            "epoch: 255, training loss: 15.68229866027832, validation loss: 19.72834014892578\n",
            "epoch: 256, training loss: 15.682327270507812, validation loss: 19.728418350219727\n",
            "epoch: 257, training loss: 15.682368278503418, validation loss: 19.72850227355957\n",
            "epoch: 258, training loss: 15.682394981384277, validation loss: 19.728609085083008\n",
            "epoch: 259, training loss: 15.682422637939453, validation loss: 19.728713989257812\n",
            "epoch: 260, training loss: 15.682452201843262, validation loss: 19.728818893432617\n",
            "epoch: 261, training loss: 15.682483673095703, validation loss: 19.72890853881836\n",
            "epoch: 262, training loss: 15.682515144348145, validation loss: 19.729000091552734\n",
            "epoch: 263, training loss: 15.682538032531738, validation loss: 19.72908592224121\n",
            "epoch: 264, training loss: 15.682573318481445, validation loss: 19.729198455810547\n",
            "epoch: 265, training loss: 15.682599067687988, validation loss: 19.729280471801758\n",
            "epoch: 266, training loss: 15.68262004852295, validation loss: 19.72939109802246\n",
            "epoch: 267, training loss: 15.682650566101074, validation loss: 19.729480743408203\n",
            "epoch: 268, training loss: 15.68267822265625, validation loss: 19.729576110839844\n",
            "epoch: 269, training loss: 15.682703018188477, validation loss: 19.72967529296875\n",
            "epoch: 270, training loss: 15.682730674743652, validation loss: 19.729772567749023\n",
            "epoch: 271, training loss: 15.68275260925293, validation loss: 19.729862213134766\n",
            "epoch: 272, training loss: 15.682780265808105, validation loss: 19.729965209960938\n",
            "epoch: 273, training loss: 15.682806968688965, validation loss: 19.730073928833008\n",
            "epoch: 274, training loss: 15.682822227478027, validation loss: 19.730154037475586\n",
            "epoch: 275, training loss: 15.682846069335938, validation loss: 19.730241775512695\n",
            "epoch: 276, training loss: 15.682851791381836, validation loss: 19.73026466369629\n",
            "epoch: 277, training loss: 15.682861328125, validation loss: 19.730318069458008\n",
            "epoch: 278, training loss: 15.682893753051758, validation loss: 19.730388641357422\n",
            "epoch: 279, training loss: 15.682904243469238, validation loss: 19.730432510375977\n",
            "epoch: 280, training loss: 15.682924270629883, validation loss: 19.730497360229492\n",
            "epoch: 281, training loss: 15.682945251464844, validation loss: 19.730573654174805\n",
            "epoch: 282, training loss: 15.682961463928223, validation loss: 19.73065185546875\n",
            "epoch: 283, training loss: 15.68298053741455, validation loss: 19.73072052001953\n",
            "epoch: 284, training loss: 15.682999610900879, validation loss: 19.730802536010742\n",
            "epoch: 285, training loss: 15.683015823364258, validation loss: 19.730876922607422\n",
            "epoch: 286, training loss: 15.683029174804688, validation loss: 19.730958938598633\n",
            "epoch: 287, training loss: 15.683053016662598, validation loss: 19.73102569580078\n",
            "epoch: 288, training loss: 15.683067321777344, validation loss: 19.731103897094727\n",
            "epoch: 289, training loss: 15.683085441589355, validation loss: 19.731182098388672\n",
            "epoch: 290, training loss: 15.68310832977295, validation loss: 19.731264114379883\n",
            "epoch: 291, training loss: 15.68311882019043, validation loss: 19.731342315673828\n",
            "epoch: 292, training loss: 15.683141708374023, validation loss: 19.731433868408203\n",
            "epoch: 293, training loss: 15.683156967163086, validation loss: 19.731504440307617\n",
            "epoch: 294, training loss: 15.683172225952148, validation loss: 19.73157501220703\n",
            "epoch: 295, training loss: 15.68319034576416, validation loss: 19.73164939880371\n",
            "epoch: 296, training loss: 15.68320369720459, validation loss: 19.731740951538086\n",
            "epoch: 297, training loss: 15.683221817016602, validation loss: 19.731815338134766\n",
            "epoch: 298, training loss: 15.683228492736816, validation loss: 19.731910705566406\n",
            "epoch: 299, training loss: 15.683250427246094, validation loss: 19.731962203979492\n",
            "epoch: 300, training loss: 15.683262825012207, validation loss: 19.732030868530273\n",
            "epoch: 301, training loss: 15.68321704864502, validation loss: 19.73217010498047\n",
            "epoch: 302, training loss: 15.683192253112793, validation loss: 19.732290267944336\n",
            "epoch: 303, training loss: 15.683178901672363, validation loss: 19.732404708862305\n",
            "epoch: 304, training loss: 15.683151245117188, validation loss: 19.732521057128906\n",
            "epoch: 305, training loss: 15.683137893676758, validation loss: 19.73261070251465\n",
            "epoch: 306, training loss: 15.683128356933594, validation loss: 19.73272132873535\n",
            "epoch: 307, training loss: 15.683117866516113, validation loss: 19.732826232910156\n",
            "epoch: 308, training loss: 15.683106422424316, validation loss: 19.732927322387695\n",
            "epoch: 309, training loss: 15.68310546875, validation loss: 19.733009338378906\n",
            "epoch: 310, training loss: 15.683099746704102, validation loss: 19.733108520507812\n",
            "epoch: 311, training loss: 15.68309497833252, validation loss: 19.733184814453125\n",
            "epoch: 312, training loss: 15.683091163635254, validation loss: 19.7332820892334\n",
            "epoch: 313, training loss: 15.683088302612305, validation loss: 19.733366012573242\n",
            "epoch: 314, training loss: 15.683095932006836, validation loss: 19.73344612121582\n",
            "epoch: 315, training loss: 15.683094024658203, validation loss: 19.733535766601562\n",
            "epoch: 316, training loss: 15.683099746704102, validation loss: 19.73361587524414\n",
            "epoch: 317, training loss: 15.683095932006836, validation loss: 19.73370361328125\n",
            "epoch: 318, training loss: 15.683094024658203, validation loss: 19.73379135131836\n",
            "epoch: 319, training loss: 15.683099746704102, validation loss: 19.733869552612305\n",
            "epoch: 320, training loss: 15.683101654052734, validation loss: 19.73396110534668\n",
            "epoch: 321, training loss: 15.683099746704102, validation loss: 19.7340030670166\n",
            "epoch: 322, training loss: 15.683107376098633, validation loss: 19.734094619750977\n",
            "epoch: 323, training loss: 15.683115005493164, validation loss: 19.734182357788086\n",
            "epoch: 324, training loss: 15.68311595916748, validation loss: 19.73422622680664\n",
            "epoch: 325, training loss: 15.683113098144531, validation loss: 19.734329223632812\n",
            "epoch: 326, training loss: 15.683058738708496, validation loss: 19.7344913482666\n",
            "epoch: 327, training loss: 15.683025360107422, validation loss: 19.734628677368164\n",
            "epoch: 328, training loss: 15.682988166809082, validation loss: 19.73478126525879\n",
            "epoch: 329, training loss: 15.682958602905273, validation loss: 19.73493194580078\n",
            "epoch: 330, training loss: 15.6829252243042, validation loss: 19.735048294067383\n",
            "epoch: 331, training loss: 15.682904243469238, validation loss: 19.735183715820312\n",
            "epoch: 332, training loss: 15.68288516998291, validation loss: 19.735300064086914\n",
            "epoch: 333, training loss: 15.682865142822266, validation loss: 19.735410690307617\n",
            "epoch: 334, training loss: 15.682846069335938, validation loss: 19.73552894592285\n",
            "epoch: 335, training loss: 15.68283462524414, validation loss: 19.735631942749023\n",
            "epoch: 336, training loss: 15.682811737060547, validation loss: 19.735740661621094\n",
            "epoch: 337, training loss: 15.6828031539917, validation loss: 19.735822677612305\n",
            "epoch: 338, training loss: 15.682794570922852, validation loss: 19.735942840576172\n",
            "epoch: 339, training loss: 15.682777404785156, validation loss: 19.736045837402344\n",
            "epoch: 340, training loss: 15.682766914367676, validation loss: 19.736143112182617\n",
            "epoch: 341, training loss: 15.682757377624512, validation loss: 19.736238479614258\n",
            "epoch: 342, training loss: 15.682755470275879, validation loss: 19.736328125\n",
            "epoch: 343, training loss: 15.6827392578125, validation loss: 19.736427307128906\n",
            "epoch: 344, training loss: 15.682727813720703, validation loss: 19.736522674560547\n",
            "epoch: 345, training loss: 15.68271541595459, validation loss: 19.73660659790039\n",
            "epoch: 346, training loss: 15.682709693908691, validation loss: 19.7367000579834\n",
            "epoch: 347, training loss: 15.68270492553711, validation loss: 19.73674964904785\n",
            "epoch: 348, training loss: 15.682701110839844, validation loss: 19.736858367919922\n",
            "epoch: 349, training loss: 15.682694435119629, validation loss: 19.736934661865234\n",
            "epoch: 350, training loss: 15.682686805725098, validation loss: 19.737018585205078\n",
            "epoch: 351, training loss: 15.682642936706543, validation loss: 19.73712730407715\n",
            "epoch: 352, training loss: 15.68261432647705, validation loss: 19.73723030090332\n",
            "epoch: 353, training loss: 15.682585716247559, validation loss: 19.737340927124023\n",
            "epoch: 354, training loss: 15.6825590133667, validation loss: 19.737428665161133\n",
            "epoch: 355, training loss: 15.682540893554688, validation loss: 19.737525939941406\n",
            "epoch: 356, training loss: 15.682515144348145, validation loss: 19.737613677978516\n",
            "epoch: 357, training loss: 15.68249225616455, validation loss: 19.73771858215332\n",
            "epoch: 358, training loss: 15.682478904724121, validation loss: 19.737791061401367\n",
            "epoch: 359, training loss: 15.68246078491211, validation loss: 19.73786735534668\n",
            "epoch: 360, training loss: 15.682443618774414, validation loss: 19.737957000732422\n",
            "epoch: 361, training loss: 15.682426452636719, validation loss: 19.738052368164062\n",
            "epoch: 362, training loss: 15.682417869567871, validation loss: 19.738142013549805\n",
            "epoch: 363, training loss: 15.682404518127441, validation loss: 19.73819351196289\n",
            "epoch: 364, training loss: 15.682390213012695, validation loss: 19.73827362060547\n",
            "epoch: 365, training loss: 15.68237590789795, validation loss: 19.738353729248047\n",
            "epoch: 366, training loss: 15.682363510131836, validation loss: 19.738412857055664\n",
            "epoch: 367, training loss: 15.682356834411621, validation loss: 19.738479614257812\n",
            "epoch: 368, training loss: 15.682351112365723, validation loss: 19.738544464111328\n",
            "epoch: 369, training loss: 15.68233871459961, validation loss: 19.738624572753906\n",
            "epoch: 370, training loss: 15.682327270507812, validation loss: 19.738691329956055\n",
            "epoch: 371, training loss: 15.682311058044434, validation loss: 19.7387638092041\n",
            "epoch: 372, training loss: 15.682307243347168, validation loss: 19.738815307617188\n",
            "epoch: 373, training loss: 15.682297706604004, validation loss: 19.738895416259766\n",
            "epoch: 374, training loss: 15.682296752929688, validation loss: 19.73895835876465\n",
            "epoch: 375, training loss: 15.68228530883789, validation loss: 19.739017486572266\n",
            "epoch: 376, training loss: 15.682241439819336, validation loss: 19.73912239074707\n",
            "epoch: 377, training loss: 15.68221664428711, validation loss: 19.73920249938965\n",
            "epoch: 378, training loss: 15.682190895080566, validation loss: 19.739286422729492\n",
            "epoch: 379, training loss: 15.682164192199707, validation loss: 19.73937225341797\n",
            "epoch: 380, training loss: 15.682140350341797, validation loss: 19.739439010620117\n",
            "epoch: 381, training loss: 15.682123184204102, validation loss: 19.73952865600586\n",
            "epoch: 382, training loss: 15.682095527648926, validation loss: 19.739587783813477\n",
            "epoch: 383, training loss: 15.682084083557129, validation loss: 19.73967170715332\n",
            "epoch: 384, training loss: 15.682062149047852, validation loss: 19.73975372314453\n",
            "epoch: 385, training loss: 15.682043075561523, validation loss: 19.73981475830078\n",
            "epoch: 386, training loss: 15.682025909423828, validation loss: 19.73988914489746\n",
            "epoch: 387, training loss: 15.68200969696045, validation loss: 19.739952087402344\n",
            "epoch: 388, training loss: 15.68199348449707, validation loss: 19.740018844604492\n",
            "epoch: 389, training loss: 15.68198299407959, validation loss: 19.740079879760742\n",
            "epoch: 390, training loss: 15.681963920593262, validation loss: 19.740150451660156\n",
            "epoch: 391, training loss: 15.681951522827148, validation loss: 19.740211486816406\n",
            "epoch: 392, training loss: 15.681941986083984, validation loss: 19.740264892578125\n",
            "epoch: 393, training loss: 15.68191909790039, validation loss: 19.7403507232666\n",
            "epoch: 394, training loss: 15.681915283203125, validation loss: 19.740375518798828\n",
            "epoch: 395, training loss: 15.681899070739746, validation loss: 19.740467071533203\n",
            "epoch: 396, training loss: 15.681883811950684, validation loss: 19.74050521850586\n",
            "epoch: 397, training loss: 15.681868553161621, validation loss: 19.74057960510254\n",
            "epoch: 398, training loss: 15.681857109069824, validation loss: 19.740615844726562\n",
            "epoch: 399, training loss: 15.681849479675293, validation loss: 19.74068832397461\n",
            "epoch: 400, training loss: 15.681839942932129, validation loss: 19.740745544433594\n",
            "epoch: 401, training loss: 15.681816101074219, validation loss: 19.74081802368164\n",
            "epoch: 402, training loss: 15.681795120239258, validation loss: 19.740867614746094\n",
            "epoch: 403, training loss: 15.681785583496094, validation loss: 19.74091148376465\n",
            "epoch: 404, training loss: 15.681764602661133, validation loss: 19.740968704223633\n",
            "epoch: 405, training loss: 15.681751251220703, validation loss: 19.741016387939453\n",
            "epoch: 406, training loss: 15.681741714477539, validation loss: 19.741050720214844\n",
            "epoch: 407, training loss: 15.681727409362793, validation loss: 19.741086959838867\n",
            "epoch: 408, training loss: 15.681720733642578, validation loss: 19.741134643554688\n",
            "epoch: 409, training loss: 15.681700706481934, validation loss: 19.74119758605957\n",
            "epoch: 410, training loss: 15.681684494018555, validation loss: 19.74123191833496\n",
            "epoch: 411, training loss: 15.681681632995605, validation loss: 19.741283416748047\n",
            "epoch: 412, training loss: 15.681661605834961, validation loss: 19.741302490234375\n",
            "epoch: 413, training loss: 15.681645393371582, validation loss: 19.741365432739258\n",
            "epoch: 414, training loss: 15.681633949279785, validation loss: 19.741397857666016\n",
            "epoch: 415, training loss: 15.681632041931152, validation loss: 19.741437911987305\n",
            "epoch: 416, training loss: 15.681619644165039, validation loss: 19.74148178100586\n",
            "epoch: 417, training loss: 15.681599617004395, validation loss: 19.741506576538086\n",
            "epoch: 418, training loss: 15.681586265563965, validation loss: 19.741554260253906\n",
            "epoch: 419, training loss: 15.681573867797852, validation loss: 19.741594314575195\n",
            "epoch: 420, training loss: 15.681571006774902, validation loss: 19.741634368896484\n",
            "epoch: 421, training loss: 15.681561470031738, validation loss: 19.741666793823242\n",
            "epoch: 422, training loss: 15.681548118591309, validation loss: 19.741701126098633\n",
            "epoch: 423, training loss: 15.68153190612793, validation loss: 19.74175453186035\n",
            "epoch: 424, training loss: 15.681525230407715, validation loss: 19.74177360534668\n",
            "epoch: 425, training loss: 15.681509971618652, validation loss: 19.741804122924805\n",
            "epoch: 426, training loss: 15.681500434875488, validation loss: 19.741806030273438\n",
            "epoch: 427, training loss: 15.681509017944336, validation loss: 19.741802215576172\n",
            "epoch: 428, training loss: 15.68150520324707, validation loss: 19.741769790649414\n",
            "epoch: 429, training loss: 15.681510925292969, validation loss: 19.74178123474121\n",
            "epoch: 430, training loss: 15.681507110595703, validation loss: 19.74178695678711\n",
            "epoch: 431, training loss: 15.681495666503906, validation loss: 19.741785049438477\n",
            "epoch: 432, training loss: 15.681498527526855, validation loss: 19.741777420043945\n",
            "epoch: 433, training loss: 15.681495666503906, validation loss: 19.74176597595215\n",
            "epoch: 434, training loss: 15.68149185180664, validation loss: 19.741771697998047\n",
            "epoch: 435, training loss: 15.681487083435059, validation loss: 19.741771697998047\n",
            "epoch: 436, training loss: 15.681490898132324, validation loss: 19.741783142089844\n",
            "epoch: 437, training loss: 15.681480407714844, validation loss: 19.741769790649414\n",
            "epoch: 438, training loss: 15.681468963623047, validation loss: 19.741802215576172\n",
            "epoch: 439, training loss: 15.68146800994873, validation loss: 19.741792678833008\n",
            "epoch: 440, training loss: 15.681456565856934, validation loss: 19.741802215576172\n",
            "epoch: 441, training loss: 15.681452751159668, validation loss: 19.741819381713867\n",
            "epoch: 442, training loss: 15.681446075439453, validation loss: 19.741823196411133\n",
            "epoch: 443, training loss: 15.68144416809082, validation loss: 19.74184226989746\n",
            "epoch: 444, training loss: 15.68143081665039, validation loss: 19.741859436035156\n",
            "epoch: 445, training loss: 15.681431770324707, validation loss: 19.741857528686523\n",
            "epoch: 446, training loss: 15.681419372558594, validation loss: 19.741849899291992\n",
            "epoch: 447, training loss: 15.68140983581543, validation loss: 19.741886138916016\n",
            "epoch: 448, training loss: 15.681403160095215, validation loss: 19.741905212402344\n",
            "epoch: 449, training loss: 15.681391716003418, validation loss: 19.741910934448242\n",
            "epoch: 450, training loss: 15.681378364562988, validation loss: 19.741918563842773\n",
            "epoch: 451, training loss: 15.681382179260254, validation loss: 19.74193572998047\n",
            "epoch: 452, training loss: 15.681382179260254, validation loss: 19.74189567565918\n",
            "epoch: 453, training loss: 15.681389808654785, validation loss: 19.74189567565918\n",
            "epoch: 454, training loss: 15.681395530700684, validation loss: 19.741899490356445\n",
            "epoch: 455, training loss: 15.681396484375, validation loss: 19.741899490356445\n",
            "epoch: 456, training loss: 15.681394577026367, validation loss: 19.741918563842773\n",
            "epoch: 457, training loss: 15.681396484375, validation loss: 19.741912841796875\n",
            "epoch: 458, training loss: 15.681396484375, validation loss: 19.741893768310547\n",
            "epoch: 459, training loss: 15.681394577026367, validation loss: 19.741891860961914\n",
            "epoch: 460, training loss: 15.681398391723633, validation loss: 19.741899490356445\n",
            "epoch: 461, training loss: 15.681389808654785, validation loss: 19.741899490356445\n",
            "epoch: 462, training loss: 15.681386947631836, validation loss: 19.741918563842773\n",
            "epoch: 463, training loss: 15.681386947631836, validation loss: 19.74192237854004\n",
            "epoch: 464, training loss: 15.68138313293457, validation loss: 19.741926193237305\n",
            "epoch: 465, training loss: 15.681386947631836, validation loss: 19.741939544677734\n",
            "epoch: 466, training loss: 15.681378364562988, validation loss: 19.741939544677734\n",
            "epoch: 467, training loss: 15.681385040283203, validation loss: 19.741947174072266\n",
            "epoch: 468, training loss: 15.681377410888672, validation loss: 19.741968154907227\n",
            "epoch: 469, training loss: 15.681373596191406, validation loss: 19.741954803466797\n",
            "epoch: 470, training loss: 15.681371688842773, validation loss: 19.74197006225586\n",
            "epoch: 471, training loss: 15.681371688842773, validation loss: 19.741985321044922\n",
            "epoch: 472, training loss: 15.681360244750977, validation loss: 19.741989135742188\n",
            "epoch: 473, training loss: 15.681355476379395, validation loss: 19.742008209228516\n",
            "epoch: 474, training loss: 15.681353569030762, validation loss: 19.74201774597168\n",
            "epoch: 475, training loss: 15.681344032287598, validation loss: 19.742023468017578\n",
            "epoch: 476, training loss: 15.681333541870117, validation loss: 19.74204444885254\n",
            "epoch: 477, training loss: 15.681325912475586, validation loss: 19.742061614990234\n",
            "epoch: 478, training loss: 15.681317329406738, validation loss: 19.742084503173828\n",
            "epoch: 479, training loss: 15.681310653686523, validation loss: 19.742111206054688\n",
            "epoch: 480, training loss: 15.681291580200195, validation loss: 19.742109298706055\n",
            "epoch: 481, training loss: 15.68128776550293, validation loss: 19.74213218688965\n",
            "epoch: 482, training loss: 15.681281089782715, validation loss: 19.742151260375977\n",
            "epoch: 483, training loss: 15.68127155303955, validation loss: 19.742172241210938\n",
            "epoch: 484, training loss: 15.681262016296387, validation loss: 19.742172241210938\n",
            "epoch: 485, training loss: 15.681251525878906, validation loss: 19.74220085144043\n",
            "epoch: 486, training loss: 15.68124008178711, validation loss: 19.742212295532227\n",
            "epoch: 487, training loss: 15.68123722076416, validation loss: 19.742237091064453\n",
            "epoch: 488, training loss: 15.681229591369629, validation loss: 19.74225425720215\n",
            "epoch: 489, training loss: 15.681224822998047, validation loss: 19.742273330688477\n",
            "epoch: 490, training loss: 15.681208610534668, validation loss: 19.74227523803711\n",
            "epoch: 491, training loss: 15.681206703186035, validation loss: 19.7423038482666\n",
            "epoch: 492, training loss: 15.681198120117188, validation loss: 19.74231719970703\n",
            "epoch: 493, training loss: 15.681180953979492, validation loss: 19.742326736450195\n",
            "epoch: 494, training loss: 15.68117904663086, validation loss: 19.742353439331055\n",
            "epoch: 495, training loss: 15.68116283416748, validation loss: 19.74237060546875\n",
            "epoch: 496, training loss: 15.68115520477295, validation loss: 19.742389678955078\n",
            "epoch: 497, training loss: 15.681146621704102, validation loss: 19.742412567138672\n",
            "epoch: 498, training loss: 15.681140899658203, validation loss: 19.742429733276367\n",
            "epoch: 499, training loss: 15.681126594543457, validation loss: 19.742446899414062\n",
            "epoch: 500, training loss: 15.681117057800293, validation loss: 19.742475509643555\n",
            "Predictions for washington-dc generated!\n",
            "\n",
            "Done printing washington-dc predictions\n",
            "----------------------------------------------------------------------\n",
            "epoch: 1, training loss: 23.0749568939209, validation loss: 22.700841903686523\n",
            "epoch: 2, training loss: 23.07090950012207, validation loss: 22.68762969970703\n",
            "epoch: 3, training loss: 23.067434310913086, validation loss: 22.67584800720215\n",
            "epoch: 4, training loss: 23.064416885375977, validation loss: 22.665231704711914\n",
            "epoch: 5, training loss: 23.061765670776367, validation loss: 22.65557289123535\n",
            "epoch: 6, training loss: 23.059431076049805, validation loss: 22.646684646606445\n",
            "epoch: 7, training loss: 23.057331085205078, validation loss: 22.638471603393555\n",
            "epoch: 8, training loss: 23.05544662475586, validation loss: 22.630800247192383\n",
            "epoch: 9, training loss: 23.05373764038086, validation loss: 22.62362289428711\n",
            "epoch: 10, training loss: 23.052165985107422, validation loss: 22.616836547851562\n",
            "epoch: 11, training loss: 23.05072593688965, validation loss: 22.610410690307617\n",
            "epoch: 12, training loss: 23.04939842224121, validation loss: 22.604305267333984\n",
            "epoch: 13, training loss: 23.048173904418945, validation loss: 22.598468780517578\n",
            "epoch: 14, training loss: 23.047033309936523, validation loss: 22.5928897857666\n",
            "epoch: 15, training loss: 23.04596519470215, validation loss: 22.587520599365234\n",
            "epoch: 16, training loss: 23.044958114624023, validation loss: 22.582361221313477\n",
            "epoch: 17, training loss: 23.044017791748047, validation loss: 22.57737922668457\n",
            "epoch: 18, training loss: 23.043123245239258, validation loss: 22.57256317138672\n",
            "epoch: 19, training loss: 23.04227066040039, validation loss: 22.56789207458496\n",
            "epoch: 20, training loss: 23.041467666625977, validation loss: 22.56336212158203\n",
            "epoch: 21, training loss: 23.040691375732422, validation loss: 22.558963775634766\n",
            "epoch: 22, training loss: 23.03995132446289, validation loss: 22.554683685302734\n",
            "epoch: 23, training loss: 23.03923797607422, validation loss: 22.550508499145508\n",
            "epoch: 24, training loss: 23.038558959960938, validation loss: 22.546432495117188\n",
            "epoch: 25, training loss: 23.03788948059082, validation loss: 22.54245376586914\n",
            "epoch: 26, training loss: 23.037334442138672, validation loss: 22.539165496826172\n",
            "epoch: 27, training loss: 23.036792755126953, validation loss: 22.535932540893555\n",
            "epoch: 28, training loss: 23.036266326904297, validation loss: 22.532752990722656\n",
            "epoch: 29, training loss: 23.03574562072754, validation loss: 22.529638290405273\n",
            "epoch: 30, training loss: 23.035242080688477, validation loss: 22.526569366455078\n",
            "epoch: 31, training loss: 23.034738540649414, validation loss: 22.523550033569336\n",
            "epoch: 32, training loss: 23.03424644470215, validation loss: 22.520578384399414\n",
            "epoch: 33, training loss: 23.033763885498047, validation loss: 22.51765251159668\n",
            "epoch: 34, training loss: 23.033273696899414, validation loss: 22.514766693115234\n",
            "epoch: 35, training loss: 23.03280258178711, validation loss: 22.511930465698242\n",
            "epoch: 36, training loss: 23.032331466674805, validation loss: 22.509122848510742\n",
            "epoch: 37, training loss: 23.031869888305664, validation loss: 22.506357192993164\n",
            "epoch: 38, training loss: 23.031402587890625, validation loss: 22.503623962402344\n",
            "epoch: 39, training loss: 23.03093719482422, validation loss: 22.500930786132812\n",
            "epoch: 40, training loss: 23.030479431152344, validation loss: 22.498275756835938\n",
            "epoch: 41, training loss: 23.030027389526367, validation loss: 22.495641708374023\n",
            "epoch: 42, training loss: 23.029573440551758, validation loss: 22.4930419921875\n",
            "epoch: 43, training loss: 23.029115676879883, validation loss: 22.490474700927734\n",
            "epoch: 44, training loss: 23.028667449951172, validation loss: 22.487934112548828\n",
            "epoch: 45, training loss: 23.028215408325195, validation loss: 22.485431671142578\n",
            "epoch: 46, training loss: 23.02776527404785, validation loss: 22.48293685913086\n",
            "epoch: 47, training loss: 23.027315139770508, validation loss: 22.480480194091797\n",
            "epoch: 48, training loss: 23.02686309814453, validation loss: 22.478038787841797\n",
            "epoch: 49, training loss: 23.026411056518555, validation loss: 22.47563362121582\n",
            "epoch: 50, training loss: 23.02595329284668, validation loss: 22.473249435424805\n",
            "epoch: 51, training loss: 23.025541305541992, validation loss: 22.471250534057617\n",
            "epoch: 52, training loss: 23.025136947631836, validation loss: 22.469276428222656\n",
            "epoch: 53, training loss: 23.02472686767578, validation loss: 22.46731948852539\n",
            "epoch: 54, training loss: 23.024314880371094, validation loss: 22.465375900268555\n",
            "epoch: 55, training loss: 23.023906707763672, validation loss: 22.46343231201172\n",
            "epoch: 56, training loss: 23.02349853515625, validation loss: 22.461517333984375\n",
            "epoch: 57, training loss: 23.02308464050293, validation loss: 22.459606170654297\n",
            "epoch: 58, training loss: 23.022680282592773, validation loss: 22.457717895507812\n",
            "epoch: 59, training loss: 23.02226448059082, validation loss: 22.455841064453125\n",
            "epoch: 60, training loss: 23.0218563079834, validation loss: 22.45396614074707\n",
            "epoch: 61, training loss: 23.021442413330078, validation loss: 22.45210838317871\n",
            "epoch: 62, training loss: 23.021032333374023, validation loss: 22.45026969909668\n",
            "epoch: 63, training loss: 23.02062225341797, validation loss: 22.448436737060547\n",
            "epoch: 64, training loss: 23.020217895507812, validation loss: 22.446619033813477\n",
            "epoch: 65, training loss: 23.01979637145996, validation loss: 22.44481658935547\n",
            "epoch: 66, training loss: 23.019384384155273, validation loss: 22.44301414489746\n",
            "epoch: 67, training loss: 23.01896858215332, validation loss: 22.44122314453125\n",
            "epoch: 68, training loss: 23.0185604095459, validation loss: 22.439456939697266\n",
            "epoch: 69, training loss: 23.018144607543945, validation loss: 22.43768310546875\n",
            "epoch: 70, training loss: 23.01772117614746, validation loss: 22.435932159423828\n",
            "epoch: 71, training loss: 23.01731300354004, validation loss: 22.43418312072754\n",
            "epoch: 72, training loss: 23.01688575744629, validation loss: 22.432451248168945\n",
            "epoch: 73, training loss: 23.01646614074707, validation loss: 22.43072509765625\n",
            "epoch: 74, training loss: 23.01604652404785, validation loss: 22.429014205932617\n",
            "epoch: 75, training loss: 23.015625, validation loss: 22.42730712890625\n",
            "epoch: 76, training loss: 23.015233993530273, validation loss: 22.425888061523438\n",
            "epoch: 77, training loss: 23.014867782592773, validation loss: 22.424474716186523\n",
            "epoch: 78, training loss: 23.014493942260742, validation loss: 22.423070907592773\n",
            "epoch: 79, training loss: 23.014116287231445, validation loss: 22.421669006347656\n",
            "epoch: 80, training loss: 23.013748168945312, validation loss: 22.42027473449707\n",
            "epoch: 81, training loss: 23.01336669921875, validation loss: 22.418882369995117\n",
            "epoch: 82, training loss: 23.01298713684082, validation loss: 22.41750144958496\n",
            "epoch: 83, training loss: 23.012603759765625, validation loss: 22.41612434387207\n",
            "epoch: 84, training loss: 23.01224136352539, validation loss: 22.41475486755371\n",
            "epoch: 85, training loss: 23.011852264404297, validation loss: 22.41338539123535\n",
            "epoch: 86, training loss: 23.011472702026367, validation loss: 22.412029266357422\n",
            "epoch: 87, training loss: 23.011091232299805, validation loss: 22.410663604736328\n",
            "epoch: 88, training loss: 23.01071548461914, validation loss: 22.40931510925293\n",
            "epoch: 89, training loss: 23.010332107543945, validation loss: 22.407970428466797\n",
            "epoch: 90, training loss: 23.009958267211914, validation loss: 22.406635284423828\n",
            "epoch: 91, training loss: 23.00957679748535, validation loss: 22.40529441833496\n",
            "epoch: 92, training loss: 23.009191513061523, validation loss: 22.403966903686523\n",
            "epoch: 93, training loss: 23.008811950683594, validation loss: 22.402647018432617\n",
            "epoch: 94, training loss: 23.0084285736084, validation loss: 22.401323318481445\n",
            "epoch: 95, training loss: 23.008054733276367, validation loss: 22.400007247924805\n",
            "epoch: 96, training loss: 23.007667541503906, validation loss: 22.398698806762695\n",
            "epoch: 97, training loss: 23.00728988647461, validation loss: 22.39739418029785\n",
            "epoch: 98, training loss: 23.00690460205078, validation loss: 22.396089553833008\n",
            "epoch: 99, training loss: 23.006519317626953, validation loss: 22.394798278808594\n",
            "epoch: 100, training loss: 23.006128311157227, validation loss: 22.393505096435547\n",
            "epoch: 101, training loss: 23.00580596923828, validation loss: 22.39244270324707\n",
            "epoch: 102, training loss: 23.005481719970703, validation loss: 22.391387939453125\n",
            "epoch: 103, training loss: 23.005155563354492, validation loss: 22.39033317565918\n",
            "epoch: 104, training loss: 23.00482940673828, validation loss: 22.389280319213867\n",
            "epoch: 105, training loss: 23.004505157470703, validation loss: 22.38823699951172\n",
            "epoch: 106, training loss: 23.00417137145996, validation loss: 22.387191772460938\n",
            "epoch: 107, training loss: 23.00384521484375, validation loss: 22.386146545410156\n",
            "epoch: 108, training loss: 23.00351905822754, validation loss: 22.385108947753906\n",
            "epoch: 109, training loss: 23.00319480895996, validation loss: 22.384069442749023\n",
            "epoch: 110, training loss: 23.002870559692383, validation loss: 22.383037567138672\n",
            "epoch: 111, training loss: 23.00253677368164, validation loss: 22.382009506225586\n",
            "epoch: 112, training loss: 23.002212524414062, validation loss: 22.3809814453125\n",
            "epoch: 113, training loss: 23.001888275146484, validation loss: 22.379953384399414\n",
            "epoch: 114, training loss: 23.001562118530273, validation loss: 22.378934860229492\n",
            "epoch: 115, training loss: 23.00123405456543, validation loss: 22.377904891967773\n",
            "epoch: 116, training loss: 23.000905990600586, validation loss: 22.376890182495117\n",
            "epoch: 117, training loss: 23.000577926635742, validation loss: 22.37587547302246\n",
            "epoch: 118, training loss: 23.000247955322266, validation loss: 22.374862670898438\n",
            "epoch: 119, training loss: 22.999919891357422, validation loss: 22.373855590820312\n",
            "epoch: 120, training loss: 22.99959373474121, validation loss: 22.37284278869629\n",
            "epoch: 121, training loss: 22.999265670776367, validation loss: 22.371845245361328\n",
            "epoch: 122, training loss: 22.998937606811523, validation loss: 22.370830535888672\n",
            "epoch: 123, training loss: 22.99860954284668, validation loss: 22.369836807250977\n",
            "epoch: 124, training loss: 22.998275756835938, validation loss: 22.36884117126465\n",
            "epoch: 125, training loss: 22.997957229614258, validation loss: 22.367843627929688\n",
            "epoch: 126, training loss: 22.997684478759766, validation loss: 22.367042541503906\n",
            "epoch: 127, training loss: 22.997419357299805, validation loss: 22.366243362426758\n",
            "epoch: 128, training loss: 22.997148513793945, validation loss: 22.365440368652344\n",
            "epoch: 129, training loss: 22.996896743774414, validation loss: 22.36463737487793\n",
            "epoch: 130, training loss: 22.996623992919922, validation loss: 22.363842010498047\n",
            "epoch: 131, training loss: 22.996360778808594, validation loss: 22.36304473876953\n",
            "epoch: 132, training loss: 22.996097564697266, validation loss: 22.362253189086914\n",
            "epoch: 133, training loss: 22.995830535888672, validation loss: 22.361467361450195\n",
            "epoch: 134, training loss: 22.995574951171875, validation loss: 22.360658645629883\n",
            "epoch: 135, training loss: 22.995304107666016, validation loss: 22.359878540039062\n",
            "epoch: 136, training loss: 22.99503517150879, validation loss: 22.359088897705078\n",
            "epoch: 137, training loss: 22.994775772094727, validation loss: 22.358301162719727\n",
            "epoch: 138, training loss: 22.994504928588867, validation loss: 22.35751724243164\n",
            "epoch: 139, training loss: 22.994245529174805, validation loss: 22.356725692749023\n",
            "epoch: 140, training loss: 22.993972778320312, validation loss: 22.355947494506836\n",
            "epoch: 141, training loss: 22.99370765686035, validation loss: 22.35516357421875\n",
            "epoch: 142, training loss: 22.993450164794922, validation loss: 22.354389190673828\n",
            "epoch: 143, training loss: 22.993183135986328, validation loss: 22.353607177734375\n",
            "epoch: 144, training loss: 22.992916107177734, validation loss: 22.352827072143555\n",
            "epoch: 145, training loss: 22.992647171020508, validation loss: 22.3520565032959\n",
            "epoch: 146, training loss: 22.992387771606445, validation loss: 22.35128402709961\n",
            "epoch: 147, training loss: 22.992109298706055, validation loss: 22.350507736206055\n",
            "epoch: 148, training loss: 22.991846084594727, validation loss: 22.3497314453125\n",
            "epoch: 149, training loss: 22.9915828704834, validation loss: 22.34896469116211\n",
            "epoch: 150, training loss: 22.991317749023438, validation loss: 22.34819793701172\n",
            "epoch: 151, training loss: 22.991107940673828, validation loss: 22.347578048706055\n",
            "epoch: 152, training loss: 22.99089241027832, validation loss: 22.346960067749023\n",
            "epoch: 153, training loss: 22.99068260192871, validation loss: 22.346351623535156\n",
            "epoch: 154, training loss: 22.990467071533203, validation loss: 22.345735549926758\n",
            "epoch: 155, training loss: 22.99025535583496, validation loss: 22.345117568969727\n",
            "epoch: 156, training loss: 22.990047454833984, validation loss: 22.344512939453125\n",
            "epoch: 157, training loss: 22.989837646484375, validation loss: 22.343896865844727\n",
            "epoch: 158, training loss: 22.989622116088867, validation loss: 22.34328842163086\n",
            "epoch: 159, training loss: 22.98941421508789, validation loss: 22.342676162719727\n",
            "epoch: 160, training loss: 22.989200592041016, validation loss: 22.342065811157227\n",
            "epoch: 161, training loss: 22.988985061645508, validation loss: 22.341447830200195\n",
            "epoch: 162, training loss: 22.98877716064453, validation loss: 22.340845108032227\n",
            "epoch: 163, training loss: 22.988563537597656, validation loss: 22.340234756469727\n",
            "epoch: 164, training loss: 22.988359451293945, validation loss: 22.339635848999023\n",
            "epoch: 165, training loss: 22.988142013549805, validation loss: 22.339021682739258\n",
            "epoch: 166, training loss: 22.987932205200195, validation loss: 22.33842658996582\n",
            "epoch: 167, training loss: 22.98772621154785, validation loss: 22.33781623840332\n",
            "epoch: 168, training loss: 22.987506866455078, validation loss: 22.337215423583984\n",
            "epoch: 169, training loss: 22.987287521362305, validation loss: 22.336610794067383\n",
            "epoch: 170, training loss: 22.98708724975586, validation loss: 22.336013793945312\n",
            "epoch: 171, training loss: 22.986873626708984, validation loss: 22.33540916442871\n",
            "epoch: 172, training loss: 22.986656188964844, validation loss: 22.334808349609375\n",
            "epoch: 173, training loss: 22.9864444732666, validation loss: 22.334213256835938\n",
            "epoch: 174, training loss: 22.98623275756836, validation loss: 22.333614349365234\n",
            "epoch: 175, training loss: 22.98601531982422, validation loss: 22.333011627197266\n",
            "epoch: 176, training loss: 22.985843658447266, validation loss: 22.332529067993164\n",
            "epoch: 177, training loss: 22.985673904418945, validation loss: 22.332042694091797\n",
            "epoch: 178, training loss: 22.98550796508789, validation loss: 22.331565856933594\n",
            "epoch: 179, training loss: 22.9853458404541, validation loss: 22.331077575683594\n",
            "epoch: 180, training loss: 22.98516273498535, validation loss: 22.33060073852539\n",
            "epoch: 181, training loss: 22.98499870300293, validation loss: 22.33011817932129\n",
            "epoch: 182, training loss: 22.98482322692871, validation loss: 22.32964515686035\n",
            "epoch: 183, training loss: 22.984657287597656, validation loss: 22.329160690307617\n",
            "epoch: 184, training loss: 22.98448944091797, validation loss: 22.328676223754883\n",
            "epoch: 185, training loss: 22.984315872192383, validation loss: 22.32819175720215\n",
            "epoch: 186, training loss: 22.98413848876953, validation loss: 22.327720642089844\n",
            "epoch: 187, training loss: 22.983970642089844, validation loss: 22.32724380493164\n",
            "epoch: 188, training loss: 22.98379898071289, validation loss: 22.326765060424805\n",
            "epoch: 189, training loss: 22.98363494873047, validation loss: 22.326282501220703\n",
            "epoch: 190, training loss: 22.98346519470215, validation loss: 22.325815200805664\n",
            "epoch: 191, training loss: 22.983291625976562, validation loss: 22.325336456298828\n",
            "epoch: 192, training loss: 22.983123779296875, validation loss: 22.324861526489258\n",
            "epoch: 193, training loss: 22.982954025268555, validation loss: 22.324382781982422\n",
            "epoch: 194, training loss: 22.982784271240234, validation loss: 22.32390785217285\n",
            "epoch: 195, training loss: 22.98261260986328, validation loss: 22.323434829711914\n",
            "epoch: 196, training loss: 22.982439041137695, validation loss: 22.322956085205078\n",
            "epoch: 197, training loss: 22.982271194458008, validation loss: 22.322484970092773\n",
            "epoch: 198, training loss: 22.982105255126953, validation loss: 22.322006225585938\n",
            "epoch: 199, training loss: 22.9819278717041, validation loss: 22.3215389251709\n",
            "epoch: 200, training loss: 22.98175811767578, validation loss: 22.321067810058594\n",
            "epoch: 201, training loss: 22.981611251831055, validation loss: 22.3206787109375\n",
            "epoch: 202, training loss: 22.98147201538086, validation loss: 22.32029151916504\n",
            "epoch: 203, training loss: 22.981332778930664, validation loss: 22.319902420043945\n",
            "epoch: 204, training loss: 22.981191635131836, validation loss: 22.31951904296875\n",
            "epoch: 205, training loss: 22.981046676635742, validation loss: 22.319133758544922\n",
            "epoch: 206, training loss: 22.98090934753418, validation loss: 22.318737030029297\n",
            "epoch: 207, training loss: 22.980770111083984, validation loss: 22.318359375\n",
            "epoch: 208, training loss: 22.98063087463379, validation loss: 22.317970275878906\n",
            "epoch: 209, training loss: 22.980491638183594, validation loss: 22.317584991455078\n",
            "epoch: 210, training loss: 22.9803466796875, validation loss: 22.317195892333984\n",
            "epoch: 211, training loss: 22.980213165283203, validation loss: 22.31682014465332\n",
            "epoch: 212, training loss: 22.980064392089844, validation loss: 22.316429138183594\n",
            "epoch: 213, training loss: 22.979921340942383, validation loss: 22.3160457611084\n",
            "epoch: 214, training loss: 22.979785919189453, validation loss: 22.315662384033203\n",
            "epoch: 215, training loss: 22.979637145996094, validation loss: 22.315279006958008\n",
            "epoch: 216, training loss: 22.979496002197266, validation loss: 22.314897537231445\n",
            "epoch: 217, training loss: 22.9793643951416, validation loss: 22.314510345458984\n",
            "epoch: 218, training loss: 22.97922134399414, validation loss: 22.314132690429688\n",
            "epoch: 219, training loss: 22.979076385498047, validation loss: 22.313743591308594\n",
            "epoch: 220, training loss: 22.978939056396484, validation loss: 22.313358306884766\n",
            "epoch: 221, training loss: 22.978797912597656, validation loss: 22.312969207763672\n",
            "epoch: 222, training loss: 22.978654861450195, validation loss: 22.312597274780273\n",
            "epoch: 223, training loss: 22.97850799560547, validation loss: 22.312217712402344\n",
            "epoch: 224, training loss: 22.978368759155273, validation loss: 22.31182861328125\n",
            "epoch: 225, training loss: 22.978229522705078, validation loss: 22.311450958251953\n",
            "epoch: 226, training loss: 22.978111267089844, validation loss: 22.31113624572754\n",
            "epoch: 227, training loss: 22.97799301147461, validation loss: 22.310823440551758\n",
            "epoch: 228, training loss: 22.97787094116211, validation loss: 22.31050682067871\n",
            "epoch: 229, training loss: 22.977752685546875, validation loss: 22.310190200805664\n",
            "epoch: 230, training loss: 22.977632522583008, validation loss: 22.309877395629883\n",
            "epoch: 231, training loss: 22.977516174316406, validation loss: 22.309558868408203\n",
            "epoch: 232, training loss: 22.97739601135254, validation loss: 22.309247970581055\n",
            "epoch: 233, training loss: 22.977279663085938, validation loss: 22.308935165405273\n",
            "epoch: 234, training loss: 22.977161407470703, validation loss: 22.308618545532227\n",
            "epoch: 235, training loss: 22.97703742980957, validation loss: 22.308305740356445\n",
            "epoch: 236, training loss: 22.97692108154297, validation loss: 22.30799102783203\n",
            "epoch: 237, training loss: 22.976804733276367, validation loss: 22.30767822265625\n",
            "epoch: 238, training loss: 22.976686477661133, validation loss: 22.307361602783203\n",
            "epoch: 239, training loss: 22.9765682220459, validation loss: 22.307048797607422\n",
            "epoch: 240, training loss: 22.9764404296875, validation loss: 22.30673599243164\n",
            "epoch: 241, training loss: 22.976329803466797, validation loss: 22.30642318725586\n",
            "epoch: 242, training loss: 22.976207733154297, validation loss: 22.306108474731445\n",
            "epoch: 243, training loss: 22.97608184814453, validation loss: 22.305797576904297\n",
            "epoch: 244, training loss: 22.975967407226562, validation loss: 22.305484771728516\n",
            "epoch: 245, training loss: 22.975849151611328, validation loss: 22.30517578125\n",
            "epoch: 246, training loss: 22.975730895996094, validation loss: 22.30486297607422\n",
            "epoch: 247, training loss: 22.97561264038086, validation loss: 22.304553985595703\n",
            "epoch: 248, training loss: 22.975492477416992, validation loss: 22.30423927307129\n",
            "epoch: 249, training loss: 22.97537612915039, validation loss: 22.303930282592773\n",
            "epoch: 250, training loss: 22.97525405883789, validation loss: 22.30362319946289\n",
            "epoch: 251, training loss: 22.975160598754883, validation loss: 22.303361892700195\n",
            "epoch: 252, training loss: 22.97505760192871, validation loss: 22.303098678588867\n",
            "epoch: 253, training loss: 22.974958419799805, validation loss: 22.3028507232666\n",
            "epoch: 254, training loss: 22.974864959716797, validation loss: 22.302597045898438\n",
            "epoch: 255, training loss: 22.974761962890625, validation loss: 22.302337646484375\n",
            "epoch: 256, training loss: 22.974666595458984, validation loss: 22.302082061767578\n",
            "epoch: 257, training loss: 22.97456932067871, validation loss: 22.30183219909668\n",
            "epoch: 258, training loss: 22.974472045898438, validation loss: 22.301576614379883\n",
            "epoch: 259, training loss: 22.974367141723633, validation loss: 22.30132293701172\n",
            "epoch: 260, training loss: 22.974267959594727, validation loss: 22.301063537597656\n",
            "epoch: 261, training loss: 22.97416877746582, validation loss: 22.300809860229492\n",
            "epoch: 262, training loss: 22.974069595336914, validation loss: 22.300556182861328\n",
            "epoch: 263, training loss: 22.973974227905273, validation loss: 22.300302505493164\n",
            "epoch: 264, training loss: 22.973873138427734, validation loss: 22.300046920776367\n",
            "epoch: 265, training loss: 22.97378158569336, validation loss: 22.299795150756836\n",
            "epoch: 266, training loss: 22.973682403564453, validation loss: 22.299537658691406\n",
            "epoch: 267, training loss: 22.973583221435547, validation loss: 22.299285888671875\n",
            "epoch: 268, training loss: 22.973485946655273, validation loss: 22.29903221130371\n",
            "epoch: 269, training loss: 22.973384857177734, validation loss: 22.298778533935547\n",
            "epoch: 270, training loss: 22.973283767700195, validation loss: 22.298532485961914\n",
            "epoch: 271, training loss: 22.973182678222656, validation loss: 22.298274993896484\n",
            "epoch: 272, training loss: 22.97308921813965, validation loss: 22.29802131652832\n",
            "epoch: 273, training loss: 22.972990036010742, validation loss: 22.297771453857422\n",
            "epoch: 274, training loss: 22.97289276123047, validation loss: 22.297517776489258\n",
            "epoch: 275, training loss: 22.97279167175293, validation loss: 22.297266006469727\n",
            "epoch: 276, training loss: 22.972713470458984, validation loss: 22.297060012817383\n",
            "epoch: 277, training loss: 22.972633361816406, validation loss: 22.296855926513672\n",
            "epoch: 278, training loss: 22.97255516052246, validation loss: 22.296648025512695\n",
            "epoch: 279, training loss: 22.97248077392578, validation loss: 22.29644203186035\n",
            "epoch: 280, training loss: 22.972393035888672, validation loss: 22.296239852905273\n",
            "epoch: 281, training loss: 22.972314834594727, validation loss: 22.296035766601562\n",
            "epoch: 282, training loss: 22.97223472595215, validation loss: 22.29582977294922\n",
            "epoch: 283, training loss: 22.97215461730957, validation loss: 22.295625686645508\n",
            "epoch: 284, training loss: 22.972074508666992, validation loss: 22.29542350769043\n",
            "epoch: 285, training loss: 22.97199821472168, validation loss: 22.295223236083984\n",
            "epoch: 286, training loss: 22.971912384033203, validation loss: 22.295019149780273\n",
            "epoch: 287, training loss: 22.971832275390625, validation loss: 22.294815063476562\n",
            "epoch: 288, training loss: 22.971755981445312, validation loss: 22.29461097717285\n",
            "epoch: 289, training loss: 22.971675872802734, validation loss: 22.29440689086914\n",
            "epoch: 290, training loss: 22.971595764160156, validation loss: 22.294206619262695\n",
            "epoch: 291, training loss: 22.97151756286621, validation loss: 22.29400062561035\n",
            "epoch: 292, training loss: 22.97144317626953, validation loss: 22.29380226135254\n",
            "epoch: 293, training loss: 22.97136116027832, validation loss: 22.293594360351562\n",
            "epoch: 294, training loss: 22.971282958984375, validation loss: 22.293397903442383\n",
            "epoch: 295, training loss: 22.9711971282959, validation loss: 22.29319190979004\n",
            "epoch: 296, training loss: 22.971120834350586, validation loss: 22.292987823486328\n",
            "epoch: 297, training loss: 22.971038818359375, validation loss: 22.292783737182617\n",
            "epoch: 298, training loss: 22.970958709716797, validation loss: 22.292583465576172\n",
            "epoch: 299, training loss: 22.970876693725586, validation loss: 22.292377471923828\n",
            "epoch: 300, training loss: 22.970800399780273, validation loss: 22.292179107666016\n",
            "epoch: 301, training loss: 22.970731735229492, validation loss: 22.292015075683594\n",
            "epoch: 302, training loss: 22.970680236816406, validation loss: 22.291852951049805\n",
            "epoch: 303, training loss: 22.970611572265625, validation loss: 22.29169464111328\n",
            "epoch: 304, training loss: 22.97054672241211, validation loss: 22.291532516479492\n",
            "epoch: 305, training loss: 22.970487594604492, validation loss: 22.2913761138916\n",
            "epoch: 306, training loss: 22.97042465209961, validation loss: 22.29121208190918\n",
            "epoch: 307, training loss: 22.970359802246094, validation loss: 22.29104995727539\n",
            "epoch: 308, training loss: 22.970298767089844, validation loss: 22.2908935546875\n",
            "epoch: 309, training loss: 22.97023582458496, validation loss: 22.29072380065918\n",
            "epoch: 310, training loss: 22.970172882080078, validation loss: 22.29056739807129\n",
            "epoch: 311, training loss: 22.970109939575195, validation loss: 22.290407180786133\n",
            "epoch: 312, training loss: 22.970048904418945, validation loss: 22.290239334106445\n",
            "epoch: 313, training loss: 22.969982147216797, validation loss: 22.290084838867188\n",
            "epoch: 314, training loss: 22.96991539001465, validation loss: 22.289918899536133\n",
            "epoch: 315, training loss: 22.969858169555664, validation loss: 22.289756774902344\n",
            "epoch: 316, training loss: 22.96979522705078, validation loss: 22.289596557617188\n",
            "epoch: 317, training loss: 22.969728469848633, validation loss: 22.289438247680664\n",
            "epoch: 318, training loss: 22.969663619995117, validation loss: 22.289278030395508\n",
            "epoch: 319, training loss: 22.969602584838867, validation loss: 22.28911590576172\n",
            "epoch: 320, training loss: 22.96954345703125, validation loss: 22.28895378112793\n",
            "epoch: 321, training loss: 22.969478607177734, validation loss: 22.288793563842773\n",
            "epoch: 322, training loss: 22.969417572021484, validation loss: 22.28863525390625\n",
            "epoch: 323, training loss: 22.969356536865234, validation loss: 22.28847312927246\n",
            "epoch: 324, training loss: 22.969287872314453, validation loss: 22.288312911987305\n",
            "epoch: 325, training loss: 22.969226837158203, validation loss: 22.288150787353516\n",
            "epoch: 326, training loss: 22.96917724609375, validation loss: 22.28802490234375\n",
            "epoch: 327, training loss: 22.969125747680664, validation loss: 22.28789520263672\n",
            "epoch: 328, training loss: 22.969079971313477, validation loss: 22.287763595581055\n",
            "epoch: 329, training loss: 22.96902847290039, validation loss: 22.287635803222656\n",
            "epoch: 330, training loss: 22.968978881835938, validation loss: 22.287513732910156\n",
            "epoch: 331, training loss: 22.96892738342285, validation loss: 22.287384033203125\n",
            "epoch: 332, training loss: 22.96887969970703, validation loss: 22.287254333496094\n",
            "epoch: 333, training loss: 22.968830108642578, validation loss: 22.28713035583496\n",
            "epoch: 334, training loss: 22.968780517578125, validation loss: 22.287002563476562\n",
            "epoch: 335, training loss: 22.96872901916504, validation loss: 22.2868709564209\n",
            "epoch: 336, training loss: 22.96867561340332, validation loss: 22.286746978759766\n",
            "epoch: 337, training loss: 22.9686336517334, validation loss: 22.286617279052734\n",
            "epoch: 338, training loss: 22.968582153320312, validation loss: 22.286495208740234\n",
            "epoch: 339, training loss: 22.968530654907227, validation loss: 22.286359786987305\n",
            "epoch: 340, training loss: 22.968481063842773, validation loss: 22.286237716674805\n",
            "epoch: 341, training loss: 22.968435287475586, validation loss: 22.28610610961914\n",
            "epoch: 342, training loss: 22.968387603759766, validation loss: 22.28598403930664\n",
            "epoch: 343, training loss: 22.96833610534668, validation loss: 22.285856246948242\n",
            "epoch: 344, training loss: 22.968284606933594, validation loss: 22.28572654724121\n",
            "epoch: 345, training loss: 22.968231201171875, validation loss: 22.285600662231445\n",
            "epoch: 346, training loss: 22.968185424804688, validation loss: 22.285472869873047\n",
            "epoch: 347, training loss: 22.9681339263916, validation loss: 22.28533935546875\n",
            "epoch: 348, training loss: 22.968080520629883, validation loss: 22.285215377807617\n",
            "epoch: 349, training loss: 22.96803855895996, validation loss: 22.28508949279785\n",
            "epoch: 350, training loss: 22.967987060546875, validation loss: 22.284963607788086\n",
            "epoch: 351, training loss: 22.96794319152832, validation loss: 22.28486442565918\n",
            "epoch: 352, training loss: 22.967905044555664, validation loss: 22.284759521484375\n",
            "epoch: 353, training loss: 22.967866897583008, validation loss: 22.28465461730957\n",
            "epoch: 354, training loss: 22.967824935913086, validation loss: 22.284549713134766\n",
            "epoch: 355, training loss: 22.967790603637695, validation loss: 22.284446716308594\n",
            "epoch: 356, training loss: 22.967750549316406, validation loss: 22.284347534179688\n",
            "epoch: 357, training loss: 22.96770477294922, validation loss: 22.284238815307617\n",
            "epoch: 358, training loss: 22.967666625976562, validation loss: 22.284133911132812\n",
            "epoch: 359, training loss: 22.96762466430664, validation loss: 22.28403663635254\n",
            "epoch: 360, training loss: 22.96758460998535, validation loss: 22.283931732177734\n",
            "epoch: 361, training loss: 22.96754264831543, validation loss: 22.28382682800293\n",
            "epoch: 362, training loss: 22.967504501342773, validation loss: 22.283727645874023\n",
            "epoch: 363, training loss: 22.96746063232422, validation loss: 22.28362464904785\n",
            "epoch: 364, training loss: 22.967422485351562, validation loss: 22.283519744873047\n",
            "epoch: 365, training loss: 22.967384338378906, validation loss: 22.28341293334961\n",
            "epoch: 366, training loss: 22.967350006103516, validation loss: 22.283315658569336\n",
            "epoch: 367, training loss: 22.967304229736328, validation loss: 22.28321075439453\n",
            "epoch: 368, training loss: 22.967262268066406, validation loss: 22.283111572265625\n",
            "epoch: 369, training loss: 22.967226028442383, validation loss: 22.28301239013672\n",
            "epoch: 370, training loss: 22.967180252075195, validation loss: 22.282901763916016\n",
            "epoch: 371, training loss: 22.96714210510254, validation loss: 22.282804489135742\n",
            "epoch: 372, training loss: 22.96710205078125, validation loss: 22.28270149230957\n",
            "epoch: 373, training loss: 22.967063903808594, validation loss: 22.2825984954834\n",
            "epoch: 374, training loss: 22.967021942138672, validation loss: 22.28249740600586\n",
            "epoch: 375, training loss: 22.966983795166016, validation loss: 22.282394409179688\n",
            "epoch: 376, training loss: 22.96695327758789, validation loss: 22.28230857849121\n",
            "epoch: 377, training loss: 22.966917037963867, validation loss: 22.282224655151367\n",
            "epoch: 378, training loss: 22.96688461303711, validation loss: 22.282140731811523\n",
            "epoch: 379, training loss: 22.96685028076172, validation loss: 22.282054901123047\n",
            "epoch: 380, training loss: 22.96681785583496, validation loss: 22.28196907043457\n",
            "epoch: 381, training loss: 22.966787338256836, validation loss: 22.281883239746094\n",
            "epoch: 382, training loss: 22.96674919128418, validation loss: 22.281803131103516\n",
            "epoch: 383, training loss: 22.966712951660156, validation loss: 22.28171730041504\n",
            "epoch: 384, training loss: 22.966678619384766, validation loss: 22.281631469726562\n",
            "epoch: 385, training loss: 22.966644287109375, validation loss: 22.28154945373535\n",
            "epoch: 386, training loss: 22.96660804748535, validation loss: 22.281463623046875\n",
            "epoch: 387, training loss: 22.966577529907227, validation loss: 22.2813777923584\n",
            "epoch: 388, training loss: 22.966543197631836, validation loss: 22.28129768371582\n",
            "epoch: 389, training loss: 22.966508865356445, validation loss: 22.281211853027344\n",
            "epoch: 390, training loss: 22.96647834777832, validation loss: 22.281126022338867\n",
            "epoch: 391, training loss: 22.966445922851562, validation loss: 22.28104019165039\n",
            "epoch: 392, training loss: 22.966411590576172, validation loss: 22.280960083007812\n",
            "epoch: 393, training loss: 22.96637725830078, validation loss: 22.28087615966797\n",
            "epoch: 394, training loss: 22.96634292602539, validation loss: 22.280790328979492\n",
            "epoch: 395, training loss: 22.966310501098633, validation loss: 22.28070640563965\n",
            "epoch: 396, training loss: 22.96627426147461, validation loss: 22.280620574951172\n",
            "epoch: 397, training loss: 22.966245651245117, validation loss: 22.280536651611328\n",
            "epoch: 398, training loss: 22.966211318969727, validation loss: 22.28044891357422\n",
            "epoch: 399, training loss: 22.966176986694336, validation loss: 22.280364990234375\n",
            "epoch: 400, training loss: 22.96613883972168, validation loss: 22.280282974243164\n",
            "epoch: 401, training loss: 22.966108322143555, validation loss: 22.280214309692383\n",
            "epoch: 402, training loss: 22.966079711914062, validation loss: 22.280141830444336\n",
            "epoch: 403, training loss: 22.966053009033203, validation loss: 22.28007698059082\n",
            "epoch: 404, training loss: 22.966026306152344, validation loss: 22.280006408691406\n",
            "epoch: 405, training loss: 22.965999603271484, validation loss: 22.279939651489258\n",
            "epoch: 406, training loss: 22.965970993041992, validation loss: 22.27986717224121\n",
            "epoch: 407, training loss: 22.9659423828125, validation loss: 22.279802322387695\n",
            "epoch: 408, training loss: 22.965911865234375, validation loss: 22.27973175048828\n",
            "epoch: 409, training loss: 22.96588706970215, validation loss: 22.2796630859375\n",
            "epoch: 410, training loss: 22.965858459472656, validation loss: 22.27959442138672\n",
            "epoch: 411, training loss: 22.96583366394043, validation loss: 22.27952003479004\n",
            "epoch: 412, training loss: 22.965801239013672, validation loss: 22.27945327758789\n",
            "epoch: 413, training loss: 22.965770721435547, validation loss: 22.27938461303711\n",
            "epoch: 414, training loss: 22.96574592590332, validation loss: 22.27931785583496\n",
            "epoch: 415, training loss: 22.965713500976562, validation loss: 22.279247283935547\n",
            "epoch: 416, training loss: 22.96569061279297, validation loss: 22.2791748046875\n",
            "epoch: 417, training loss: 22.965662002563477, validation loss: 22.279109954833984\n",
            "epoch: 418, training loss: 22.965635299682617, validation loss: 22.27903938293457\n",
            "epoch: 419, training loss: 22.965604782104492, validation loss: 22.27896499633789\n",
            "epoch: 420, training loss: 22.965578079223633, validation loss: 22.278900146484375\n",
            "epoch: 421, training loss: 22.96554946899414, validation loss: 22.278831481933594\n",
            "epoch: 422, training loss: 22.965518951416016, validation loss: 22.278766632080078\n",
            "epoch: 423, training loss: 22.96549415588379, validation loss: 22.278697967529297\n",
            "epoch: 424, training loss: 22.96546745300293, validation loss: 22.278629302978516\n",
            "epoch: 425, training loss: 22.965438842773438, validation loss: 22.2785587310791\n",
            "epoch: 426, training loss: 22.965415954589844, validation loss: 22.278499603271484\n",
            "epoch: 427, training loss: 22.965391159057617, validation loss: 22.278444290161133\n",
            "epoch: 428, training loss: 22.965370178222656, validation loss: 22.27838706970215\n",
            "epoch: 429, training loss: 22.96534538269043, validation loss: 22.278329849243164\n",
            "epoch: 430, training loss: 22.96532440185547, validation loss: 22.278270721435547\n",
            "epoch: 431, training loss: 22.96529769897461, validation loss: 22.278215408325195\n",
            "epoch: 432, training loss: 22.96527671813965, validation loss: 22.278160095214844\n",
            "epoch: 433, training loss: 22.96525001525879, validation loss: 22.278104782104492\n",
            "epoch: 434, training loss: 22.965225219726562, validation loss: 22.278045654296875\n",
            "epoch: 435, training loss: 22.965206146240234, validation loss: 22.277992248535156\n",
            "epoch: 436, training loss: 22.965179443359375, validation loss: 22.27793312072754\n",
            "epoch: 437, training loss: 22.965160369873047, validation loss: 22.277877807617188\n",
            "epoch: 438, training loss: 22.965137481689453, validation loss: 22.277820587158203\n",
            "epoch: 439, training loss: 22.965110778808594, validation loss: 22.27776336669922\n",
            "epoch: 440, training loss: 22.965084075927734, validation loss: 22.277708053588867\n",
            "epoch: 441, training loss: 22.965063095092773, validation loss: 22.27764892578125\n",
            "epoch: 442, training loss: 22.965038299560547, validation loss: 22.2775936126709\n",
            "epoch: 443, training loss: 22.96501922607422, validation loss: 22.277538299560547\n",
            "epoch: 444, training loss: 22.964996337890625, validation loss: 22.277481079101562\n",
            "epoch: 445, training loss: 22.964969635009766, validation loss: 22.277423858642578\n",
            "epoch: 446, training loss: 22.96494483947754, validation loss: 22.277368545532227\n",
            "epoch: 447, training loss: 22.964923858642578, validation loss: 22.277311325073242\n",
            "epoch: 448, training loss: 22.964906692504883, validation loss: 22.277257919311523\n",
            "epoch: 449, training loss: 22.96487808227539, validation loss: 22.277202606201172\n",
            "epoch: 450, training loss: 22.964853286743164, validation loss: 22.277145385742188\n",
            "epoch: 451, training loss: 22.964839935302734, validation loss: 22.277101516723633\n",
            "epoch: 452, training loss: 22.964818954467773, validation loss: 22.277053833007812\n",
            "epoch: 453, training loss: 22.964801788330078, validation loss: 22.277009963989258\n",
            "epoch: 454, training loss: 22.964784622192383, validation loss: 22.276966094970703\n",
            "epoch: 455, training loss: 22.964763641357422, validation loss: 22.27691650390625\n",
            "epoch: 456, training loss: 22.96474838256836, validation loss: 22.276872634887695\n",
            "epoch: 457, training loss: 22.96472930908203, validation loss: 22.27682876586914\n",
            "epoch: 458, training loss: 22.96470832824707, validation loss: 22.276782989501953\n",
            "epoch: 459, training loss: 22.96468734741211, validation loss: 22.27674102783203\n",
            "epoch: 460, training loss: 22.964670181274414, validation loss: 22.276691436767578\n",
            "epoch: 461, training loss: 22.96464729309082, validation loss: 22.27664566040039\n",
            "epoch: 462, training loss: 22.96463394165039, validation loss: 22.27660369873047\n",
            "epoch: 463, training loss: 22.964616775512695, validation loss: 22.276559829711914\n",
            "epoch: 464, training loss: 22.96459197998047, validation loss: 22.27651023864746\n",
            "epoch: 465, training loss: 22.964574813842773, validation loss: 22.27646255493164\n",
            "epoch: 466, training loss: 22.964553833007812, validation loss: 22.27642250061035\n",
            "epoch: 467, training loss: 22.964534759521484, validation loss: 22.27637481689453\n",
            "epoch: 468, training loss: 22.96451759338379, validation loss: 22.276330947875977\n",
            "epoch: 469, training loss: 22.964502334594727, validation loss: 22.276287078857422\n",
            "epoch: 470, training loss: 22.964481353759766, validation loss: 22.276235580444336\n",
            "epoch: 471, training loss: 22.96446418762207, validation loss: 22.276193618774414\n",
            "epoch: 472, training loss: 22.964447021484375, validation loss: 22.27614402770996\n",
            "epoch: 473, training loss: 22.96442985534668, validation loss: 22.276098251342773\n",
            "epoch: 474, training loss: 22.96441078186035, validation loss: 22.276058197021484\n",
            "epoch: 475, training loss: 22.964391708374023, validation loss: 22.276018142700195\n",
            "epoch: 476, training loss: 22.96437644958496, validation loss: 22.27597999572754\n",
            "epoch: 477, training loss: 22.96436309814453, validation loss: 22.275943756103516\n",
            "epoch: 478, training loss: 22.964345932006836, validation loss: 22.275907516479492\n",
            "epoch: 479, training loss: 22.964332580566406, validation loss: 22.275869369506836\n",
            "epoch: 480, training loss: 22.964319229125977, validation loss: 22.275833129882812\n",
            "epoch: 481, training loss: 22.96430015563965, validation loss: 22.275798797607422\n",
            "epoch: 482, training loss: 22.964284896850586, validation loss: 22.2757625579834\n",
            "epoch: 483, training loss: 22.964269638061523, validation loss: 22.275726318359375\n",
            "epoch: 484, training loss: 22.964252471923828, validation loss: 22.27568817138672\n",
            "epoch: 485, training loss: 22.96424102783203, validation loss: 22.275650024414062\n",
            "epoch: 486, training loss: 22.96422576904297, validation loss: 22.275617599487305\n",
            "epoch: 487, training loss: 22.96421241760254, validation loss: 22.27558135986328\n",
            "epoch: 488, training loss: 22.964197158813477, validation loss: 22.275545120239258\n",
            "epoch: 489, training loss: 22.964187622070312, validation loss: 22.275510787963867\n",
            "epoch: 490, training loss: 22.964168548583984, validation loss: 22.275476455688477\n",
            "epoch: 491, training loss: 22.964153289794922, validation loss: 22.275440216064453\n",
            "epoch: 492, training loss: 22.964139938354492, validation loss: 22.275405883789062\n",
            "epoch: 493, training loss: 22.964122772216797, validation loss: 22.275367736816406\n",
            "epoch: 494, training loss: 22.964107513427734, validation loss: 22.275333404541016\n",
            "epoch: 495, training loss: 22.964094161987305, validation loss: 22.275299072265625\n",
            "epoch: 496, training loss: 22.96407699584961, validation loss: 22.275259017944336\n",
            "epoch: 497, training loss: 22.96406364440918, validation loss: 22.27522087097168\n",
            "epoch: 498, training loss: 22.96405029296875, validation loss: 22.27518653869629\n",
            "epoch: 499, training loss: 22.964035034179688, validation loss: 22.27515411376953\n",
            "epoch: 500, training loss: 22.964019775390625, validation loss: 22.275117874145508\n",
            "Predictions for palo-alto generated!\n",
            "\n",
            "Done printing palo-alto predictions\n",
            "----------------------------------------------------------------------\n",
            "./submission.csv generated!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAJOCAYAAAAzn38vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXydZZ3///fnPluanKxNuqRNKW2htCwtUBYRFDcWgeKOuDsIDg4zP2cc+Y06Kv7G+f78OuI6g8rSLy5jGRdUUFxQBATLUmopBdpC6ZZuSZc0SdPs1/ePcxKS9KQJaZr7vs55PR+PPGzOOc39aUd7zfu+PvfnMuecAAAAAADhCsIuAAAAAABAOAMAAACASCCcAQAAAEAEEM4AAAAAIAIIZwAAAAAQAYQzAAAAAIgAwhkKgpldbGa/mOBr/szMLh3hM9eb2W4zazWzyRNVW/bas7LXjR2Dn/1pM7t9vH8uAGB8sT7mvDbrI0JjnHOGiWJmmyV9xDn3hxCuvVLSDc65x7LfO0mNkmqdc93Z1xKStkuqcc5Z9rWTJX1N0hJlbmZslPRZ59x9ZnahpAcktQ253JuccyvM7GxJ33bOnTlMTQlJzZLOdc49Pa5/YACAN1gfD6uJ9REFi50z5D0zO0tSed/CM8B+SQPv3F2afW2geyXdL2mapCmS/kGZBaPPDudcesjXCklyzj0hqczMlgxT2lRJRZKeHcOfycyM//0CAMaM9RGIHv7Li9CZWcrMvm5mO7JfXzezVPa9ajP7lZk1mdk+M/tz3z+6Zvb/mtl2M2sxs/Vm9oZhLnGppIdyvP4DSR8Y8P0HJH1/QF3Vko6XdJtzrjP79ahz7pFX8Md7UNJlOf7MJ0pan/22ycweyL5+npk9aWYHsv953oDf86CZ/buZParM3cg5OX7uZjP7pJmtMbODZnaHmU01s99k/57+YGaV2c/ONjNnZvHs9x82s+ezn3vJzD464OdeaGb1ZnajmTWY2U4ze4uZvdnMNmT/b/PpAZ+/ycx++Ar+ngAAQ7A+sj6i8BDOEAWfkXSupMWSFkk6W9K/Zt/7hKR6STXK3En7tCRnZvMl3SDpLOdcqaSLJW0e5uefqpf/oR/oF5JeY2YV2X+QL5D0ywHv75X0oqQfZv+hnTqGP9vz2T/TIM65DZJOzn5b4Zx7vZlVSfq1pG9Kmizpq5J+bYN77d8v6TpJpZK2DHPNt0t6k6QTJV0h6TfK/L3VKPO/+X8Y5vc1SLpcUpmkD0v6mpmdMeD9acrcyZwh6XOSbpP0PklnKvN391kzO36Ynw0AeOVYH1kfUWAIZ4iC90r6/5xzDc65RklfUOYfWUnqkjRd0nHOuS7n3J9d5kHJHkkpSQvNLOGc2+yc2zjMz6+Q1JLj9XZl2jKuyn7dk31NkpS9zuuUWdRulrTTzB42sxMG/Iza7F3LgV8lA95vyV5/NC6T9IJz7gfOuW7n3HJJ65RZQPrc6Zx7Nvt+1zA/51vOud3Oue2S/izpcefcX51z7ZJ+Lun0XL/JOfdr59xGl/GQpN8rs6j06ZL079nr3iWpWtI3nHMtzrlnJT2nHAstAGDMWB8zWB9RMAhniIJaDb7LtSX7miT9hzJ3536fbSX4F0lyzr0o6eOSbpLUYGZ3mVmtctuvzJ20XL6vTLvGoJaNPs65eufcDc65uZKOk3RwyOd2OOcqhnwdHPB+qaSm4f7gQwz9e1D2+xkDvt82ip+ze8CvD+X4Pp3rN5nZpWb2WLYFo0nSm5VZYPrsdc71DPg5ua6V82cDAMaE9TGD9REFg3CGKNihzD/sfWZlX1P2rtMnnHNzJC2V9E99vfPOuR85587P/l4n6X8P8/PXKNPCkMuflbnzOFXSEXvlnXPbJP2XpFNG84fKWiBptJOmhv49SJm/i+0Dy3gF1x617DMMP5P0FUlTnXMVku6TZMfiegCAUWF9zGB9RMEgnGGiJcysaMBXXNJySf9qZjXZh4w/J+mHkmRml5vZPDMzSQeUadfoNbP5Zvb67D+a7crcleod5pr3SXptrjeyrRlXSFqa/XU/M6s0sy9krx9ka/sbSUOnWh3Ja5XpaR+N+ySdaGbvMbO4mV0laaGkX72C641VUpk2mEZJ3ZY5f+aiCbguACCD9XF4rI8oGIQzTLT7lFko+r5ukvRFSSuVuYP3jKRV2dck6QRJf5DUKmmFpFucc39S5h/KL0naI2mXMmN8P5Xrgs65VZIOmNk5w7z/bLYnfKhOSbOz12+WtFZSh6QPDfhMrWUOqhz49Xapf0Rxa3Zk8Iicc3uVeeD4E8o8bH2jpMudc3tG8/uPhnOuRZkHoX+sTJvLe5R5xgAAMDFYH4fB+ohCwiHUKAhmdpGkjznn3jKB1/yZpDucc/dN1DUBAHglWB+BaCGcAQAAAEAE0NYIAAAAABFAOAMAAACACCCcAQAAAEAExCfyYtXV1W727NkTeUkAQAieeuqpPc65mrDr8AXrIwAUjiOtkRMazmbPnq2VK1dO5CUBACEwsy1h1+AT1kcAKBxHWiNpawQAAACACCCcAQAAAEAEEM4AAAAAIAIIZwAAAAAQAYQzAAAAAIgAwhkAAAAARADhDAAAAAAigHAGAAAAABFAOAMAAACACCCcAQAAAEAEEM4AAAAAIAIIZwAAAAAQAYQzAAAAAIgAwhkAAAAARADhDAAAAAAigHAGAAAAABFAOAMAAACACCCcAQAAAEAEEM4AAAAAIAIIZwAAAAAQAYQzAAAAAIgAwhkAAAAARIBX4ez/PLpJb/zqQ2GXAQBA5Lz5G3/WrQ9vDLsMAMBR8Cqc7W/r0osNrWGXAQBA5Gzac1CNLR1hlwEAOApehbPAMv/Z2+vCLQQAgIgJTGJ5BAC/eRXOYpZJZz2O1QcAgIGCwNRDOgMAr3kVzoLs1hmLDwAAg8UCUy83LwHAa36Fs+zOGWsPAACDxYxwBgC+8yqcxbLV0tYIAMBgZqae3rCrAAAcDa/CWd/OGW2NAAAMFgsYmAUAvvMqnMWCvrZGFh8AAAairREA/OdVOGPnDACA3MyMtn8A8Jxf4SxglD4AALnEAqOtEQA851U4izGtEQCAnGKBqYf1EQC85lU4y26c0dYIAMAQgYlnzgDAc36FMw6hBgAgp8BoawQA33kVzmhrBAAgt1hg3LwEAM95Fc4CDqEGACCnwExkMwDwm1/hjFH6AADkFAQ8cwYAvvMqnHEINQAAucWMtkYA8J1X4ax/54xwBgDAIEFg7JwBgOf8DGfcGQQAYJCYEc4AwHdehbOX2xpDLgQAgIgJaGsEAO95Fc44hBoAgNyCQOrtDbsKAMDR8CucBTxzBgBALjGeOQMA73kVzvoOoe5l5wwAgEECM25eAoDnvApnfQNByGYAAAwWmHHzEgA851c4y1bLM2cAAAwWC9g5AwDfeRXO+tsaWXwAABgkMAaCAIDv/ApnAeEMAIBcAs45AwDveRXOjEOoAQDIKRZwzhkA+M6rcMbOGQAAuQWM0gcA7/kVzvpH6YdcCAAAEZNpawy7CgDA0fAqnGWzGdOoAAAYIma0/QOA77wKZ/1tjSw+AAAMEvDMGQB4z89wxtoDAMAggZkcnSUA4DWvwllAWyMAADnFjEOoAcB3noUz2hoBAMgl09YYdhUAgKPhVThjlD4AALnFAtHWCACe8yqcBRxCDQBATgFtjQDgPb/CGTtnAADkFBjTGgHAd16Fs/5DqFl7AAAYJBaYuHcJAH7zKpz1T2sknQEAMEjAIdQA4D2/whltjQAA5BQEPHMGAL7zKpzFGKUPAEBOMTPWRwDwnFfhrH9aI2sPAACDxAKjswQAPOdXOMtWy51BAAAGMzP1Os46AwCfeRXO+g6hpqceAIDBmGgMAP7zKpwFxkAQAAByifV1l7BGAoC3/Axn3BYEAGAQ63sumzUSALzlVTjrb2vsDbkQAAAiJsZxMwDgPa/CWd8h1Cw8AAAMFmPnDAC851U4MzOZEc4AABgqCBgIAgC+GzGcmdkyM2sws7UDXltsZo+Z2WozW2lmZx/bMl8WM+OuIAAAQ/R3l7BGAoC3RrNzdqekS4a89mVJX3DOLZb0uez3EyIIjLuCAAAMwXEzAOC/EcOZc+5hSfuGviypLPvrckk7xrmuYQW0NQIAcBiOmwEA/8XH+Ps+Lul3ZvYVZQLeecN90Myuk3SdJM2aNWuMl3sZbY0AABzu5eNmQi4EADBmYx0Icr2kf3TO1Un6R0l3DPdB59ytzrklzrklNTU1Y7zcyzJtjYQzAAAG6juEmrZGAPDXWMPZByXdnf31TyRN2ECQwIyHnQEAGOLlnTPWSADw1VjD2Q5Jr83++vWSXhifckYWC4y7ggAADMEzZwDgvxGfOTOz5ZIulFRtZvWSPi/pWknfMLO4pHZlnymbCIExrREAgKH6pzWySAKAt0YMZ865q4d568xxrmVUAqNlAwCAoV4+hJo1EgB8Nda2xtDEAqY1AgCiwcyWmVmDma0d8Nr/mNnq7NdmM1s9EbXE+tsaJ+JqAIBjYayj9ENDWyMAIELulPSfkr7f94Jz7qq+X5vZzZIOTEQh2Y0zbmACgMf8C2cBLRsAgGhwzj1sZrNzvWdmJuldygzOOuYCnjkDAO/519bIIdQAAD9cIGm3cy7nRGMzu87MVprZysbGxqO+WIxpjQDgPe/CWcAofQCAH66WtHy4N51ztzrnljjnltTU1Bz1xYLsis79SwDwl39tjWZyhDMAQIRlj5p5myZwsnHfOWd0lwCAv7zbOaOtEQDggTdKWuecq5+oC8azW2eskQDgL//CGaP0AQARYWbLJa2QNN/M6s3smuxb79YRWhqPBQ6hBgD/edfWGI+Zull4AAAR4Jy7epjXPzTBpSgeI5wBgO+82zmLB6buHhYeAAAG6ts56+rtDbkSAMBY+RfOYoG6elh4AAAYKNH3zBk3MAHAW/6FM545AwDgMH07Z7T+A4C//AtnsUBdLDwAAAzS98xZN22NAOAt78JZIjB109YIAMAgcaY1AoD3vAtn8RgDQQAAGKrvnDPWSADwl4fhLKBlAwCAIWK0NQKA9/wLZwHnnAEAMFScgSAA4D0Pw1lAywYAAEPwzBkA+M+7cJaIGeecAQAwBM+cAYD/vAtn8RjnnAEAMBTPnAGA//wLZ0HAzhkAAEPwzBkA+M/DcMZAEAAAhup/5oy2RgDwln/hLMZAEAAAhoplw1kXNzABwFvehbNEzNRFPz0AAIOYmWKBqYc1EgC85V04iwUm56Re7gwCADAIrf8A4DfvwlkilimZ3TMAAAaLB8YzZwDgMe/CWf80KhYfAAAGibFzBgBe8y+cxThkEwCAXBKxgHPOAMBj3oWzBIdsAgCQU2YgCDcvAcBX3oWzGIdsAgCQUzwwddFZAgDe8i6cJYLsQJAeds4AABgoHgvYOQMAj3kXzuIxBoIAAJALo/QBwG8ehrPsQBCeOQMAYJBYYOqmswQAvOVfOOOZMwAAcmKUPgD4zd9wRlsjAACDJHjmDAC85l04S8QYCAIAQC7snAGA37wLZ/0DQVh8AAAYJM4zZwDgNe/CWYy2RgAAcorH2DkDAJ95F84STGsEACCneMAzZwDgM+/CGQNBAADIjVH6AOA378IZA0EAAMiNQ6gBwG/ehbO+gSC0bQAAMFg8ZqyPAOAx/8JZtq2xi8UHAIBB4kHAzhkAeMzDcJYdCEJbIwAAg/DMGQD4zb9wlm1r5JkzAAAGY5Q+APjNu3CWjPcNBGHxAQBgoHjAM2cA4DP/whnTGgEAyCkWBNy8BACPeRfOGKUPAEBuiZipu5f1EQB85W046+xm8QEAYKB4EKibnTMA8JaH4SwzEKSTxQcAgEEScVMnnSUA4C3vwpmZKRkLaGsEAGCIVHZ9dI4bmADgI+/CmZTZPeuirREAgEESsUDOiYmNAOApP8NZPKBtAwCAIRIcNwMAXvMznNHWCADAYfqHZrFGAoCXvAxnyVigzm7uCgIAMFAyOzSLG5gA4Cc/w1mcnTMAAIbiLFAA8JuX4SwRMxYeAACG6A9ndJcAgJc8DWcBh1ADADBE30AQnjkDAD/5G85YeAAAGIRnzgDAb16GM545AwDgcP3TGukuAQAv+RnOYgFnuAAAMAQDQQDAb16Gs0TMuCsIAMAQnHMGAH7zNJzR1ggAwFDJeN/OGd0lAOAjL8NZMs5AEAAAhkr2j9JnjQQAH/kZztg5AwDgMIk40xoBwGdehrNELOCATQAAhuCZMwDwm5/hLG4sPAAADNHf1sgzZwDgJT/DWSygnx4AgCEYpQ8AfvMynDEQBACAwyViPHMGAD4bMZyZ2TIzazCztQNe+x8zW5392mxmq49tmYMxEAQAgMMlsqP0OQsUAPw0mp2zOyVdMvAF59xVzrnFzrnFkn4m6e5jUNuwErFAvU7qJqABANCPZ84AwG8jhjPn3MOS9uV6z8xM0rskLR/nuo4oweIDAMBh+qc1snMGAF462mfOLpC02zn3wnAfMLPrzGylma1sbGw8ystl9PXUs/gAAPCyWGAKjGfOAMBXRxvOrtYIu2bOuVudc0ucc0tqamqO8nIZqURMktTR0zMuPw8AgHyR4LlsAPBWfKy/0czikt4m6czxK2d0irIPPHd0sfgAADBQMsZEYwDw1dHsnL1R0jrnXP14FTNaRdmds/Yuds4AABgoGWfnDAB8NZpR+sslrZA038zqzeya7Fvv1gQPAunzcjhj8QEAYKBELOCZbADw1Ihtjc65q4d5/UPjXs0opbJtje3d7JwBADBQMk44AwBfHe1AkFDQ1ggAQG5FiUAdhDMA8JKn4Sy7c0ZbIwAAg6TiMW5eAoCnPA1n7JwBAJBLKs7OGQD4ys9wFiecAQCQS1GCnTMA8JWf4ayvrZE7gwAADMLOGQD4y8twlsq2NXZwZxAAgEGKEjHCGQB4ystw1rdzxuIDAMBgqXhAWyMAeMrLcJaMBTLjmTMAAIZKMUofALzlZTgzMxUxKhgAgMMwSh8A/OVlOJMyrY2ccwYAwGDsnAGAvzwOZ9wZBABgqKJ4TJ3dvXLOhV0KAOAV8juccWcQAIBBUgzNAgBveRvOmEYFAMDhUvG+42YIZwDgG3/DGW2NAAAcpu+4mfZu1kgA8I234awoHnBXEACAIdg5AwB/eRvO0qm4Wju6wy4DAIBIKep/5oydMwDwjbfhrLQorpaOrrDLAAAgUvp2zjhuBgD843E4S6ilnZ0zAAAGSsXZOQMAX3kbzsomxdXS3s05LgAADFCUYOcMAHzlbTgrLUqop9fpEBMbAQDox84ZAPjL43AWlyRaGwEAGKBv54xDqAHAPx6Hs4QkqaWdoSAAAPTp2znjLFAA8I/H4Syzc9bMzhkAAP1S/aP02TkDAN94G87KaGsEAOAwRf2j9Nk5AwDfeBvOaGsEAOBw7JwBgL88DmfsnAEAMFTfIdQdjNIHAO94HM4yO2fNh9g5AwCgTywwJWKmdkbpA4B3vA1nJcmYkrFA+9o6wy4FAIBIScVj7JwBgIe8DWdmpqqSpPYfJJwBADBQUSJg5wwAPORtOJOkypKk9hHOAAAYhJ0zAPCT1+FscklSewlnAAAMkkoE6mDnDAC843U4q2LnDACAw6TiMbWzcwYA3vE/nLUSzgAAGCgVZ+cMAHzkfThr6ehWJwdtAgDQrygR8MwZAHjI+3AmSfsZpw8AQL9UPMbOGQB4yOtwNjkbzvbS2ggAQL+iRKAOukoAwDteh7PKbDhjKAgAAC/LDARh5wwAfON1OOvbOdtHWyMAAP0yA0HYOQMA33gdzvqeOdvX2hFyJQAAREdRgp0zAPCR1+GsojgpM9oaAQDhMLNlZtZgZmuHvP73ZrbOzJ41sy9PdF3snAGAn7wOZ7HAVDEpob2EMwBAOO6UdMnAF8zsdZKulLTIOXeypK9MdFFFiRjhDAA85HU4k7IHURPOAAAhcM49LGnfkJevl/Ql51xH9jMNE11XUSJQT69jnD4AeMb7cDa5JEU4AwBEyYmSLjCzx83sITM7K9eHzOw6M1tpZisbGxvHtYBJybgk6VAn4QwAfOJ9OGPnDAAQMXFJVZLOlfRJST82Mxv6Iefcrc65Jc65JTU1NeNaQEkyJklqI5wBgFe8D2eT00ntYVojACA66iXd7TKekNQrqXoiC5hEOAMAL3kfzqrTKe1v61JXDw8+AwAi4ReSXidJZnaipKSkPRNZQDFtjQDgJf/DWWlKEuP0AQATz8yWS1ohab6Z1ZvZNZKWSZqTHa9/l6QPOufcRNZVnN05O9jZPZGXBQAcpXjYBRytmnTmIOrGlg5NLSsKuRoAQCFxzl09zFvvm9BChugLZ+ycAYBf/N85S2d2znjuDACAjL62Rp45AwC/5FE4o60RAADp5Z2zNtoaAcAr/oezUnbOAAAYqJhpjQDgJe/DWUkypqJEoD0thDMAACTaGgHAV96HMzNTdTrFzhkAAFlFiUBm0iHaGgHAK96HM0nZcMYzZwAASJkbl5MSMXbOAMAzeRTO2DkDAKBPcTKuti7CGQD4JC/CWU1pknAGAMAAxcmY2jpoawQAn+RFOKtOp7TvYKd6el3YpQAAEAnFSdoaAcA3eRPOep207yDPnQEAIEnpVFyt7JwBgFfyJpxJnHUGAECf0qK4WtoJZwDgk7wIZ1PKMuGsgbPOAACQJJUWJdTS3hV2GQCAVyAvwtn08iJJ0s6mQyFXAgBANLBzBgD+yYtwNrWsSGbSzgPtYZcCAEAkZHbOCGcA4JO8CGeJWKCadEo7D7BzBgCAlNk56+zpVTtnnQGAN/IinEmZ1kZ2zgAAyCgtiksSu2cA4JE8CmeTCGcAAGS9HM4YCgIAvsifcFZRpJ1Nh+QcB1EDAFCaSkhi5wwAfJI/4ay8SAc7e9TCgZsAANDWCAAeyqNwNkmStLOJ1kYAAEqL+nbOaGsEAF/kTTirrciedcbERgAA+nfOmglnAOCNvAln0/p2zhgKAgCAKoozO2dNbYQzAPDFiOHMzJaZWYOZrR3y+t+b2Toze9bMvnzsShydKaUpBSbtbGLnDACAdCqueGDaTzgDAG+MZufsTkmXDHzBzF4n6UpJi5xzJ0v6yviX9sokYoFqSlPsnAEAIMnMVFmSVFNbZ9ilAABGacRw5px7WNK+IS9fL+lLzrmO7GcajkFtrxhnnQEA8LLK4oT2E84AwBtjfebsREkXmNnjZvaQmZ013AfN7DozW2lmKxsbG8d4udGprShiIAgAAFkVxUnaGgHAI2MNZ3FJVZLOlfRJST82M8v1Qefcrc65Jc65JTU1NWO83OhMK8vsnHEQNQAA2Z2zg+ycAYAvxhrO6iXd7TKekNQrqXr8yhqb2ooitXX2qPkQB24CAFBVws4ZAPhkrOHsF5JeJ0lmdqKkpKQ941XUWPUfRN1MayMAABXFmYEgdJQAgB9GM0p/uaQVkuabWb2ZXSNpmaQ52fH6d0n6oIvAv/zTyrMHUTcxFAQAgMrihLp7nVo76CgBAB/ER/qAc+7qYd563zjXctRmVmZ2zur3t4VcCQAA4asoTkrKHERdWpQIuRoAwEjG2tYYSTXplJLxQNv209YIAEBlNpwxTh8A/JBX4SwITDMrJ7FzBgCApKqSzG4ZQ0EAwA95Fc4kaWZlsbbtY+cMAIC+tkbG6QOAH/IunNVVTtI2ds4AAKCtEQA8k3/hrKpYTW1dammnhQMAUNjKJyVkRlsjAPgi78LZyxMbaW0EABS2WGAqK0qoiZ0zAPBC3oWzuspiSdK2fbQ2AgBQVZJk5wwAPJF/4awqE87YOQMAQKooZucMAHyRd+Gssjih4mSMoSAAAEiaXJLUnlbCGQD4IO/CmZmpjnH6AABIkmpKi9TY0h52GQCAUci7cCZJdVUcRA0AgCRNLUtpT2ununp6wy4FADCCvAxnMyuLVb//kJxzYZcCAECoppQWSZL2tHaEXAkAYCR5Gs4mqbWjW01MpwIAFLipZSlJ0u5mwhkARF1ehjMmNgIAkNG3c7a7mefOACDq8jKc9R1EzcRGAECh69s5a2hh5wwAoi4vw1nfzhkHUQMACt3kdEqBSQ3snAFA5OVlOCsrSqh8UoK2RgBAwYsFpup0Sg08cwYAkZeX4UzKtDbS1ggAgDSlLKXdnHUGAJGXt+EscxA14QwAgKmlReycAYAH8jecVU3irDMAAJTZOWtg5wwAIi9vw9nMymJ1dPeqkUM3AQAFbkppkfa0dqqrpzfsUgAAR5C34ayuKjtOfx9DQQAAhW1Kdpx+I+P0ASDS8jecVfYdRM1zZwCAwlZbnrlhufMANywBIMryNpzNyB5EzTh9AECh6zv/cyuDsgAg0vI2nBUn46pOJ5nYCAAoeDMrafUHAB/kbTiTMkNB2DkDABS6okRMU8tS7JwBQMTleTjjIGoAACRpVlUx4QwAIi6vw1ldVbF2NB1STy9nnQEACltdVbHqCWcAEGn5Hc4qi9XV47S7mYM3AQCFra6yWDub29XR3RN2KQCAYeR1OHv5AWjuFAIACtusqmI5J23nWWwAiKy8Dmd9o4O3sRABAArcrMmsiQAQdXkdzmorimTGQdQAAMzirDMAiLy8DmepeExTS4s41wUAUPBq0iml4oG27j0YdikAgGHkdTiTpLoqxukDABAEptmTS7RpD+EMAKIq/8NZZTEPPwMAIGlOTYleaiScAUBU5X04m1k5STsPHFJXT2/YpQAAEKo5NSXauq+NNREAIir/w1lVsXqdtKOJ3TMAQGGbU51Wd6/Tlr20+wNAFOV9OKurzEynqqe1EQBQ4OZPK5UkPbezOeRKAAC55H044yBqAAAyTppWqkmJmFZt2R92KQCAHPI+nE0vL1IsMCY2AgAKXjwWaFFduVZtJZwBQBTlfTiLxwLVVhTR1ggAgKRFdRV6fmezuhkKAgCRk/fhTJJmVhTT1ggAgKR5NWl19Tht46YlAEROQYSzzEHULEIAAMydkpYkvdTYGnIlAIChCiOcVRarsaVD7V09YZcCAECo5lZnwtlGwhkARE5BhLOZVZmJjTx3BgAodOXFCVWnk9rYcDDsUgAAQxREOOs764yJjQAASDMqi7XjADcsASBqCiOcVXEQNQAAfWZUFGl7E/PnvgsAACAASURBVGsiAERNQYSzmnRKyXigeiY2AgCg6eWTtLOpXc65sEsBAAxQEOEsCEwzKybR1ggAgKTp5UU61NWjA4e6wi4FADBAQYQzSZpZVUxbIwAAkmorMoOyaG0EgGgpnHBWOYmDqAEA0MvhbEdTe8iVAAAGKphwVldZrP1tXWrt6A67FAAAQjV7cmZQFgdRA0C0FE446z/rjN0zAEBhqyhOZs46I5wBQKQUTDib2XfW2T766wEAmFuT1osNhDMAiJKCCWd1lZmdM547AwBAOmFqJpwxTh8AoqNgwllVSVLFyRgTGwEAkDSvJq3m9m41tnaEXQoAIKtgwpmZZSY28swZAACaN6VUkmhtBIAIKZhwJmUmNtLWCACANG9KWpK0kXAGAJFRWOGsqljbaWsEAEBTy1JKp+LsnAFAhBRUOKutKFJLR7ea27vCLgUAgFCZmeZNSWvDbsIZAERFQYWz6eWZiY07m9pDrgQAgPAtmF6q53c1M7ERACKioMJZbUUmnO1oorURAICF08vU1NalnQe4aQkAUVBg4axIkrTjAOEMAIAF08skSc/vbA65EgCAVGDhbEppkWKBsXMGAICkk7Lh7LkdhDMAiIKCCmexwDSlNKVdBzhwEwCAdCqu4yYX6/ldhDMAiIKCCmeSVD4poRamNQIAICnz3NnzO1vCLgMAoAIMZ+lUXAc7u8MuAwCASFgwvUyb9x5UawdrIwCErfDCWVFcre0sQAAASNKpM8vlnLSmvinsUgCg4BVeOEvF1cLdQQAAJEln1FVKkv66lXAGAGEbMZyZ2TIzazCztQNeu8nMtpvZ6uzXm49tmeOnlJ0zAAD6lRcnNLemRE9t2R92KQBQ8Eazc3anpEtyvP4159zi7Nd941vWsZNOxemrBwBggDOPq9Rft+6Xcy7sUgCgoI0YzpxzD0vaNwG1TIh0KqG2zh719LIAAQAgSWfMqtT+ti5t2nMw7FIAoKAdzTNnN5jZmmzbY+VwHzKz68xspZmtbGxsPIrLjY90UVyS2D0DACDrjOMyy/gqnjsDgFCNNZx9W9JcSYsl7ZR083AfdM7d6pxb4pxbUlNTM8bLjZ90KiaJcAYAQJ95NWmVFsW1aivPnQFAmMYUzpxzu51zPc65Xkm3STp7fMs6dtKphCTpIOEMAABJUhCYFtdVaBVDQQAgVGMKZ2Y2fcC3b5W0drjPRk1fW2MLExsBAOh3xqxKrd/dopb2rrBLAYCCFR/pA2a2XNKFkqrNrF7S5yVdaGaLJTlJmyV99BjWOK7SKZ45AwBgqJNry+Sc9FLjQS2qqwi7HAAoSCOGM+fc1TlevuMY1DIhqkqSkqTGlo6QKwEA+M7Mlkm6XFKDc+6U7Gs3SbpWUt8UrE/7cORMTWlKkrT3IOsjAITlaKY1eqmucpISMdPGxtawSwEA+O9O5clZoNXpTDjb09oZciUAULgKLpzFY4FmTy7RxgbCGQDg6OTTWaCT05nOkj2t7JwBQFgKLpxJ0tyatF5k5wwAcOyMeBZo1M4BLU7GVZyMaS87ZwAQmoIMZ/OmpLVlb5s6u3vDLgUAkH9GdRZo1M4BlTKtjeycAUB4Cjac9fQ6bd13MOxSAAB5xuezQKvTSXbOACBEBRnO5takJUkv8twZAGCc+XwW6GR2zgAgVCOO0s9Hc2pKJBHOAABHJ9/OAp03Ja0/rWvQgbYulRcnwi4HAApOQYazklRcteVF2thIWyMAYOzy7SzQi0+epm8/uFH3P79b7zhzZtjlAEDBKci2RkmaOyXNzhkAAAMsmlmu2vIi/XbtzrBLAYCCVLDhbN6UtDY2tqq314VdCgAAkWBmuviUaXr4hT1q7egOuxwAKDgFG87m1qTV1tmjXc3tYZcCAEBkXHrKdHV29+qBdQ1hlwIABadgw9m8KUxsBABgqDOPq1R1OkVrIwCEoODD2cZGwhkAAH1igenik6fqT+sadaizJ+xyAKCgFGw4m1ySVPmkBDtnAAAMcekp03Woq0cPbWgMuxQAKCgFG87MTPOY2AgAwGHOmVOliuKEfkNrIwBMqIINZ5I0rybNWWcAAAyRiAW69JRpuv+53bQ2AsAEKuhwNndKifa0duhAW1fYpQAAEClXLKpVW2eP/rhud9ilAEDBKOhw1j+xsbEl5EoAAIiWc46frCmlKd2zekfYpQBAwSjscFZTKkna2EBrIwAAA8UC02WnTdeD6xvV3E6HCQBMhIIOZzMqJykZD/Qi4/QBADjM0kW16uzp1e/W7gq7FAAoCAUdzmKBaU51CRMbAQDIYXFdheqqJumep2ltBICJUNDhTMo8d8ZB1AAAHM7MdMVptfrLxr3a09oRdjkAkPcKPpzNrUlr2742tXcxKhgAgKGWLq5VT6/Tb57hzDMAONYKPpzNm5JWr5M27WEoCAAAQ500rUwnTk3T2ggAE4Bwlh2nT2sjAAC5LV1Uqyc379f2pkNhlwIAea3gw9nx1SUKTNqwm3AGAEAul59WK0n69Rp2zwDgWCr4cFaUiGlOTVrP72wOuxQAACJpdnWJFs0sp7URAI6xgg9nkrRwepme20E4AwBgOFcsqtXa7c16iccAAOCYIZxJWlhbpu1Nh9TU1hl2KQAARNLlp9XKTOyeAcAxRDhTZudMkp6jtREAgJymlRfp7NlVuvfpHXLOhV0OAOQlwpmkBX3hjNZGAACGtXRxrTY2HuRmJgAcI4QzSTWlKU0pTbHYAABwBG8+ZbrigdHaCADHCOEsa2EtQ0EAADiSypKkLjihWr96eqd6e2ltBIDxRjjLOrm2TC82tKqjuyfsUgAAiKwrFtVqe9Mh/XXb/rBLAYC8QzjLWji9XN29Ti9wGDUAAMO66ORpSsUD3bOa1kYAGG+Es6yFtQwFAQBgJOlUXG9YMEW/fmanunt6wy4HAPIK4SzruKpilSRjenbHgbBLAQAg0pYuqtWe1k6teGlv2KUAQF4hnGUFgenk2nKt2U44AwDgSC6cP0XpVFz3MrURAMYV4WyAU2eW67kdzeqiTQMAgGEVJWK66OSp+s3aXQzSAoBxRDgb4LSZ5ero7mUoCAAAI1i6qFYt7d16aH1j2KUAQN4gnA1w2swKSdIz25tCrgQAgGh79bxqVZUkOZAaAMYR4WyA46qKVVoU19P1PHcGAMCRJGKBLj1lmv74fIPaOrvDLgcA8gLhbIAgMJ06o1zPEM4AABjR0kW1OtTVo/uf2x12KQCQFwhnQ5w6o1zrdjEUBACAkZw1u0rTyoqY2ggA44RwNsT8aaXq6nHavOdg2KUAABBpQWC6/LTpemhDo5raOsMuBwC8RzgbYv60UknSul0tIVcCAED0LV1cq64ep989uyvsUgDAe4SzIebWpBULTBt2E84AABjJqTPKNXtyMVMbAWAcEM6GKErENHtyMTtnAACMgplp6aJardi4Vw0t7WGXAwBeI5zlMH9aqdYTzgAAGJUrFtWq10m/XrMz7FIAwGuEsxzmTy3T1n1tnNsCAMAonDC1VCdNK2VqIwAcJcJZDn1DQTbsbg25EgAA/LB0ca1WbW3Stn1tYZcCAN4inOWwYHomnD27g8OoAQAYjStOq5Uk3buG3TMAGCvCWQ6zqopVUZzQmm2EMwAARqOuqlinz6rQPasJZwAwVoSzHMxMi2ZW6On6prBLAQDAG0sX1Wrdrha9wHE0ADAmhLNhnD6rQht2t+jAoa6wSwEAwAuXnTZdknT/87tDrgQA/EQ4G8Z5c6vV66QVG/eGXQoAAF6YUlqksqK4dh/gvDMAGAvC2TBOn1WhdCquh19oDLsUAAC8MTmd0t6DnWGXAQBeIpwNIxEL9Kq5k/XwhkY558IuBwAAL1SVJLW/jXAGAGNBODuC15xQrfr9h7RlL2e2AAAwGpXFSe1tJZwBwFgQzo7gghNqJEkPrGsIuRIAAPwwmZ0zABgzwtkRzK4u0UnTSjlQEwCAUaosSWrfwU4eCQCAMSCcjeDKxTP0161N2kprIwAAI5pcklRXj1NrR3fYpQCAdwhnI7hiUebMFnbPAAAYWWVJUpK0j4mNAPCKEc5GMLOyWEuOq9QvV28PuxQAACLvuMnFkqTV25pCrgQA/EM4G4UrF9dqw+5WrdvVHHYpAABE2pmzKjWrqljLn9gadikA4B3C2Si8+dTpigWmu1exewYAwJEEgekdZ87U45v2qaG5PexyAMArhLNRmJxO6aKFU/XjldvU3tUTdjkAAETapadMk3PS757dFXYpAOAVwtkovf/c49TU1qVfr9kZdikAAETaCVNLNbemRPc9QzgDgFeCcDZKr5o7WXNqSvSDx7aEXQoAAJF36SnT9fimvdrb2hF2KQDgDcLZKJmZ3n/ucVq9rUlrtx8IuxwAACLtstOmq9dJ9zzNUTQAMFojhjMzW2ZmDWa2Nsd7nzAzZ2bVx6a8aHnbGTM1KRHTnX/ZHHYpAABE2oLpZTptZrnuemKbnHNhlwMAXhjNztmdki4Z+qKZ1Um6SFLBzMotn5TQO5fM1C9Xb2cCFQAAI7j67Flav7tFq7Zy5hkAjMaI4cw597CkfTne+pqkGyUV1O2wa84/Xj29jt0zAABGcMWiWpUkY5x5BgCjNKZnzszsSknbnXNPj+Kz15nZSjNb2djYOJbLRcpxk0t00cJpuuvJbWGXAgBApKVTcS1dPEO/WrNDze1dYZcDAJH3isOZmRVL+rSkz43m8865W51zS5xzS2pqal7p5SJpUV2F9h3s1MGO7rBLAQAg0t5z9iy1d/Xqpyvrwy4FACJvLDtncyUdL+lpM9ssaaakVWY2bTwLi7Ka0pQkaQ/jgQEAOKJTZ5brrNmVWvboJnX39IZdDgBE2isOZ865Z5xzU5xzs51zsyXVSzrDOVcwJ032hbPGFsIZAAAj+cgFc1S//5B++2zB/L8KADAmoxmlv1zSCknzzazezK459mVF2xTCGQAAo/bGBVN1fHWJbnv4JcbqA8ARjGZa49XOuenOuYRzbqZz7o4h7892zu05diVGT9/OWQPhDACAEcUC0zXnH6+n6w/oiU25BkADAKQxTmssdJXFScUCY+cMAIBRevsZM1WdTunm+zewewYAwyCcjUEsME0uSWoXB1EDADAqk5Ix/cMb5umJTfv00Ab/j9YBgGOBcDZGi+sq9OD6RnUxeQoAgFF591mzVFc1SV/+7Xr19rJ7BgBDEc7G6Kqz6rSntUMPrufuHwAAo5GMB/rEm+bruZ3NunfNjrDLAYDIIZyN0WtOrFFlcUK/ZnEBAGDUli6q1YLpZfryb9ervasn7HIAIFIIZ2OUiAW6aOE0/eH5BrV1doddDgAAXggC02cvX6DtTYd0xyObwi4HACKFcHYU3rlkplo7uvXTp+rDLgUAAG+cN7dab1o4Vbf86UU1tDBcCwD6EM6OwpnHVerM4yr1nw+8qNYOds8AABitT795gTp7evXl364PuxQAiAzC2VEwM3328oVqbO3QN/6wIexyAADwxvHVJbrm/Dn66VP1enIzB1MDgEQ4O2qL6yr07rPqtOzRzVq/qyXscgAA8MY/vGGeZlRM0r/+fC1H0wCACGfj4pMXn6TSorg+98u1co5zWwAAGI3iZFyfv2Kh1u9u0Z2Pbg67HAAIHeFsHFSVJHXjxSfp8U379PO/bg+7HAAAvPGmhVN14fwafeuBF3SgrSvscgAgVISzcXLVWXU6Y1aFvnDvc9rdzOQpAABGw8x048Unqbm9W99bsTnscgAgVISzcRILTF955yJ1dPfoxp+uob0RAIBRWlhbpteeWKMfPLaFg6kBFDTC2TiaU5PWv1xykh7a0Ki7ntwWdjkAAHjjYxfOVWNLh259+KWwSwGA0BDOxtkHXjVb582drC/+6jlt3dsWdjkAAHjhnDmTddmp03XLgy9qR9OhsMsBgFAQzsZZEJj+452LFJjpn368Wt2MBgYAYFT+5dKT5Jz0pd+sC7sUAAgF4ewYmFExSf/2llO0cst+feehjWGXAwCAF+qqivXR18zRPU/v4GBqAAWJcHaMXLm4VlcsqtXX//CC1tQ3hV0OAABe+NsL52paWZFu/v36sEsBgAlHODtGzExfvPIU1ZSm9PG7VqutszvskgAAiLziZFwXnTxVz25vZvIxgIJDODuGyosTuvmdi/TSnoP6X/c9H3Y5AAB4YVZVsVo6unXgEIdSAygshLNj7Lx51br2guP1w8e26oF1u8MuBwCAyKurKpYkbd3H1GMAhYVwNgH++eL5OmlaqW786RrtP9gZdjkAAETarGw427aPkfoACgvhbAKk4jF97arF2t/Wpf/9W8YDAwBwJH07Z3/duj/kSgBgYhHOJsiC6WW65vzjddeT2/TUFsYDAwAwnHQqrktPmabbH9mkb/3xBQaDACgYhLMJ9P+84QRNLy/SZ36+Vl0cTg0AwLC+efXpeuvpM3Tz/Rt00z3PqreXgAYg/xHOJlBJKq6blp6sdbta9Pl7ng27HAAAIisRC3TzOxfpI+cfr++t2KKP/89qdXNjE0CeI5xNsItPnqa/fe1c/ejxrfrVmh1hlwMAQGQFgekzly3QjZfM1z1P79CNP1vDDhqAvBYPu4BC9M8XnajHXtqrT9/9jM6eXaUpZUVhlwQAQCSZmT524Tx19zh99f4NSqfi+sLSk2VmYZcGAOOOnbMQxGOB/v+3narm9m79cV1D2OUAABB5f//6ebruNXP0/RVbdMuDG8MuBwCOCcJZSE6aVqqqkqRWbWFMMAAAIzEzferSk3Tl4lr9x+/W65ert4ddEgCMO9oaQ2JmOr2uQk9t2S/nHO0ZAACMwMz05Xecpp0H2vXJn6zRtLIinTNncthlAcC4YecsRG9YMFUv7Tmoz/3yWc5wAQBgFFLxmG59/5maWTVJH/n+Sj1TfyDskgBg3BDOQnT12XX66Gvm6AePbdGn7n5Gze1dYZcEAEDkVRQn9YNrzlFZUULvX/a4nt/ZHHZJADAuCGchMjP9y6Un6WMXztVdT27Tq7/0gL71xxd0qLMn7NIAAIi0GRWTtPzac1UUj+l9tz+uFxtawi4JAI4a4SxkZqYbLzlJ995wvl41Z7Juvn+DLvnGw3qxoTXs0gAAiLRZk4v1o2vPkZnpPbc9rk17DoZdEgAcFcJZRJw6s1y3fmCJfnTtOTrY0a233vKoHt7QGHZZAABE2pyatH507Tnq7nV6z22Padu+trBLAoAxI5xFzHlzq/WLv3u1ZlRM0ofvfFL//fiWsEsCAAzDzJaZWYOZrc3x3ifMzJlZdRi1FZITp5bqh9eco7bOHr3n9se0o+lQ2CUBwJgQziJoZmWxfnr9eXrNCdX6zM/X6t9+9Zy6e3rDLgsAcLg7JV0y9EUzq5N0kaStE11QoVpYW6YfXHO2mg526b23P66G5vawSwKAV4xwFlHpVFy3fWCJPviq43THI5v0gWVPaE9rR9hlAQAGcM49LGlfjre+JulGSZyTMoFOm1mhO//mbO1ubtd7bn+cdROAdwhnERaPBfrClafoy+84TSu37NcV33pEf926P+yyAABHYGZXStrunHt6hM9dZ2YrzWxlYyPPGI+XM4+r1LIPnaX6/W1a8sU/6G23PEpIA+ANwpkH3rWkTndff55igemq7z6mH6/cFnZJAIAczKxY0qclfW6kzzrnbnXOLXHOLampqTn2xRWQc+dM1h0fPEsnTk1r1dYmXfXdFdp5gOfQAEQf4cwTp8wo1703nK+zjq/UjT9do8//cq26eA4NAKJmrqTjJT1tZpslzZS0ysymhVpVAXr1vGr9/h9fqx9/9FXa3dyhd35nBZMcAUQe4cwjlSVJfe/DZ+vaC47X91Zs0ftuf1x7adUAgMhwzj3jnJvinJvtnJstqV7SGc65XSGXVrDOPr5KP7r2HLW0d+vdtz6mrXsJaACii3DmmXgs0GcuW6ivX7VYq7c16fJvPaIfrNis9q6esEsDgIJjZsslrZA038zqzeyasGvC4U6bWaH//sg5OtjZratuXcFh1QAii3DmqbecPkM/u/48pVNxffaXz+qa7z2pts7usMsCgILinLvaOTfdOZdwzs10zt0x5P3Zzrk9YdWHl50yo1w/+si56uju1btvXaGXGlvDLgkADkM489gpM8r1+398jb78jtO0YuNefWjZk2pp7wq7LAAAImlhbZmWX3uuunuc3n3rY9pIQAMQMYQzz5mZ3rWkTt949+l6aut+veu7j2nXAQ7eBAAgl/nTSrX8unPV65ze9Z0VHFEDIFIIZ3niikW1Wvahs7R170G99ZZH9fzO5rBLAgAgkk6cWqoff/RVKknFdfVtj+n3zzKvBUA0EM7yyGtPrNFP/vY8OSe98zsr9JtndoZdEgAAkTSnJq27P3ae5k8r00d/+JTufHRT2CUBAOEs3yysLdPP/+48zZ2S1vX/vUr/9qvnOA8NAIAcqtMp3XXtuXrjgqm66d7n9O+/fk69vS7ssgAUMMJZHppePkk/+eir9KHzZuuORzbpqu+u0I6mQ2GXBQBA5ExKxvSd952pD77qON325026YfkqjqcBEBrCWZ5KxgPdtPRkfevq07V+V4su++af9dCGxrDLAgAgcmKB6aalJ+tfL1ug+57Zpffe/rj2HewMuywABYhwlueuWFSre/7+fE0pLdKH/s8T+ur9G9RDywYAAIOYmT5ywRzd8t4z9Mz2A3r7t/+iLXsPqrunV4++uIe1E8CEIJwVgLk1af3i716tt54+Q9/84wv64LIntKe1I+yyAACInDefOl0/+sg5amrr1Ftv+Ys+dfczeu/tj+u6769Ua0d32OUByHOEswIxKRnTze9cpC+97VQ9sXmfLv/mI5ztAgBADktmV+ln15+ndCqunzxVr2llRXpwQ6Pe8e2/qH5/W9jlAchjhLMCYmZ699mzdPf15ykeM1313ce0/ImtYZcFAEDkzKlJ6+cfO09vO32GvvWe03Xnh8/S9qZDest/PaqntnBzE8CxQTgrQKfMKNe9N5yvc+ZU6VN3P6NP3b1GD6zbrRd2t4RdGgAAkTE5ndJXr1qss2ZX6YITavTzj726/+DqX/x1e9jlAchDhLMCVVmS1J0fPlsfu3Culj+xTX9z50pd9PWH9eD6hrBLAwAgkuZNSesXH3u1Tq+r0Mf/Z7Vu/v16zkUDMK4IZwUsFphuvOQk3f6BJbr67DrNq0nrI99bqZ8+VR92aQAARFJlSVI/uOYcXbWkTt964EXdsHyVDnVyLhqA8REPuwCE740Lp+qNC6eqpb1L1/9wlf75J09r/a5m/fPF85WKx8IuDwCASEnGA33p7adq3pS0/tdvnlf9/hW67QNLNLWsKOzSAHiOnTP0Ky1KaNmHztL7zp2l2/68SW+75S9at6s57LIAAIgcM9O1r5mj296/RBsbWrX0Px/R2u0Hwi4LgOcIZxgkGQ/0xbecqts+sEQ7D7Trsm8+opvueVYHDnWFXRoAAJHzxoVT9dPrz1M8CPSO7/xFv127M+ySAHiMcIac3rRwqv74T6/V1WfX6XsrNuv1X3lQP165jQefAQAYYsH0Mv3i716tBdPL9Lc/XKX/+tOLco71EsArRzjDsCpLkvriW07VvTecr9nV/7e9O4+Pq7rvPv45M9pHo9G+b5a1eJF3YYyNl9hADKEkUCAhaQgtTxLaJoRAkpb2eaVt+nRLG5KQkDRNQtOUEAiEJYSw2sY2GGy8SF6wLdna9320r3OfP2YsbEteBLZmJH3fr9e8ZubO1fjcnzXz0++ec89x8I2nD3Lzj3dpfRcREZGzJDhD+fXnV3HTklT+/ZXjPPCbEgZHNFGIiEyOijO5oMI0F0/fcxUP3b6Ehs5+/vjHu/jKEweo7+z3d9NEREQCRliwne9/ain3X5vPMwfq+PRPd9PaM+jvZonINKLiTC6KMYZblqez7Wsb+PLGXF4+3MjG77zBd18r1RTCIiIiPsYY7t2Uxw8/vYzDdW4+8chbHG/s9nezRGSaUHEmk+IIDeKB6wrY8sB6Ns1P4vtbytj4nTd47kAd7b1D7K/WkEcREZEbF6fymy9exdCIh1t+9Ba/P1jv7yaJyDSgdc7kA0mPieCRTy/nrtXtfOuF97jvyWJCg2wMjni4aUkqf3/TQmIdIf5upoiIiN8syYjm+S+t4UuPH+ArTxQzMmrx8aWpGGP83TQRCVAX7DkzxjxqjGk2xhw+bds/GmMOGmOKjTGvGmNSL28zJVBdkR3L83+5hn+/dTGL013ctTqblw43cO1D23nxoKYTFhGR2S3FFc5//+kVLEiJ4r4ni7n5R7vYXd7m72aJSIAyF5rq1RizDugBfmlZVqFvW5RlWV2+x/cCCyzLuudC/1hRUZG1d+/eD99qCWjHG7v5+tMlHKx1szYvnr/aPI/CNJe/myUiU8gYs8+yrCJ/t2O6UH6c+UY9Fr/dX8tDr5bS2DXANfOT+KvNBeQlOf3dNBGZYufLkRfsObMsawfQfta2rtOeOgAt5iFjCpKdPPPnq/nmjQs4VOfmxh+8yVefLKamvc/fTRMREfELu81we1EGb3x9A1//aAHvlLdx7Xd3cPcv3mVPRbvWRRMR4CJ6zgCMMdnA70/1nPm2/RNwJ+AGPmJZVss5fvYLwBcAMjMzV1RVVX34Vsu04e4f5j+3n+TRNyuwLLjzqiy+tDGX6AhdjyYyk6nnbHLUczb7tPcO8cu3K/nl21W09w6xNCOaL67L4bqFydhtuiZNZCY7X478wMXZaa89CIRZlvV3F3ofJZ/Zq8Hdz0OvlvLb/bU4QoO4Z/1c7rwqC2dYsL+bJiKXgYqzyVF+nL36h0Z5el8NP3uzgqq2PtKiw/nMqkw+WZRBXGSov5snIpfB5S7OMoE/TPTa2ZR85HhjN99++RhbjjXjCg/mz9bM4a412bjCVaSJzCQqziZH+VFGPRavvdfI/+yq4u3yNkLsNq5flMwnizJYlROHOnR96AAAHZpJREFUTb1pIjPG+XLkB5pK3xiTZ1lWme/px4FjH7RxMrsUJDv5+V1XcLC2k4e3nOC7r5fys53l3FaUwedWZwHwhV/uY0NBAv9nbQ4JTp01FBGRmc9uM2wuTGFzYQonmrv537ereOZAHc8X15MeE86tK9K5dUU66TER/m6qiFxGFzNb46+BDUA80AT8HXADUAB4gCrgHsuy6i70j+nMoJztSL2bn2wv5w+HGhi1LJKjwmjpHsRjWYQE2bhjZSZ/vmEuic4wfzdVRCZBPWeTo/woExkYHuWVI408tbeWt062EhFsZ9vXNpAYpZwoMp196GGNl4qSj5xLU9cAv3qniifereH2ogxuWZ7GI9tO8lxxHcF2w51XZfPFdTkafy8yTag4mxzlR7mQN8ta+ZOf7+Ynn13BRxcm+7s5IvIhXPJhjSKXWlJUGPdfV8D91xWMbfvO7Uv48sZcHt5Sxs92lvPYO1X86ZpsPr82R7M9iojIrLI8Kxpj4GhDl4ozkRnsguucifhTdryDhz65lFe/uo6N8xJ5ZNtJ1v7bNr73eildA8P+bp6IiMiUiAgJYk6cg72VHXQr/4nMWCrOZFrITXTyw08v5+X71rI6N47vvV7G2n/bxiPbTtA7ODJuf8uytKCniIjMKMuzYnjzRCtLv/Uadz66h6f21uDuV6EmMpPomjOZlg7Xufnua6VsOdZMnCOEe9bP5bNXZREWbAfgph++SUffELetyODWFemkRof7ucUis4uuOZsc5Ue5GAPDo7xb2c5bJ9p48VA9Ne39hATZuGZ+IrcsS2d9QQLBdp13Fwl0mhBEZqwD1R089FopO8taSXCG8qWP5LImN45rHtpBRmw4Ne39GAMrs2PJSYgkJiKYGxensiA1yt9NF5nRVJxNjvKjTJZlWRTXdPJ8cT2/K6mnvXeIWEcIf7Q4hZuXp7Mk3YUxWhtNJBCpOJMZb09FO//x6nH2VLQTEmRjaMTD1gfWE2y38dS+WrYda6a+s5/O/mFGPRbLM6P5k1VZ3LAoZay37WwHqjt4+Ugjd16VTZp63kQmRcXZ5Cg/yocxPOphR2kLzxyo47X3mhga8ZCT4OCWZWl8Ylma1kYTCTAqzmRWsCyLXSfb+NEbJ/B44PHPXznurGFn3xBP76vl8d3VlLf2EhMRzG1FGXx6ZSbZ8Y4z9v3yrw/wQkk9IXYbn1mVyV9syNWi2CIXScXZ5Cg/yqXi7h/mpUMNPHOgjj0V7QCsnBPLLcvSuG5hMrEOzXYs4m8qzkTOcqqQe+ydKl59r4lRj8XavHj+ZFUWm+YlEmS3sek7bxDnCCU7PoLf7q8jxG7jztVZfHHdXCU3kQtQcTY5yo9yOdS09/F8cR3P7K+jvLUXY2BZRjT/+IlCFqa6/N08kVlLxZnIeTR1DfDkuzX8ek81De4BUlxh3F6UwQ+2lnHvpjzuuyafitZevv96Kc+X1BMRbOfPrp7D3VfP0XprIueg4mxylB/lcrIsi8N1XWw51sQPt57g7rVzePD6+f5ulsisdb4cqSl9ZNZLigrj3k157PzGR/jJZ1eQmxjJ97eU4bFgQYp34pA58Q6+96llvHLfOtYXJPCDrSdY869b+deXjtHaM3jO9+4dHOH/PneIXSdbp+pwREREzmCMYVG6i/uuyScrLoKq1j5/N0lEziHI3w0QCRRBdhsfXZjMRxcmU9HayzvlbWycl3jGPvlJTn70mRUca+zikW0n+cmOk/xiVwV3rMzki+vmkuwKO2P/t0608tg71Tz2TjWbFybzNzfMJzNOF2aLiIh/ZMc5qGzr9XczROQc1HMmMoE58Q7uWJlJ0DnWi5mXHMUP7ljG6/ev58bFqfzy7SrWfXsbf/PsIWra3z8jWdbcA8C9G3PZUdbCNQ9t55//cJSW7nP3tomIiFwuWXEOqtr6mMrLWkTk4qk4E/kQ5iZE8h+3LeGNr23gtqJ0nt5by4b/eIMHflNCeUsPJ5t7SHGFcf91BWx9YAM3LknhZzvLWfvtrXzrhfdo6hrw9yGIiMgskh0fQf/wKP/vxaO8eqSR/qFRfzdJRE6jCUFELqFG9wD/taOcx/dUMTjiISzITlF2DP9795Vj+5S39PCjN07y7IE67DbD7UXpfH5tDllxjnO+79GGLsKD7eOm+xcJVJoQZHKUH2WqVLX1ct+TxRyuczM8ahERYufmZWn8+Ya5Wg9NZIpotkaRKdbaM8jP36zgl7squWf9XL68KW/cPtVtffx4+wl+u6+OEY+HzYXJfGHdXJZmRJ+xn2VZLP/H1+gaGOHmZWnctTqbwjRNgSyBTcXZ5Cg/ylQbGB5lf1UHzx6o47niOgCuW5jMNfMTWZ+fqCVjRC4jFWcifuLxWBjDuMWwT9fcNcB/76rksXeq6B4YYeWcWO5Zn8OG/ERsNkNNex9rv72NpRnRHGvsYmDYw9KMaD67KouPLU4hLNg+hUckcnFUnE2O8qP4U31nPz/ZfpIXDzXQ2jOEzcCyzBg2zktk47xE5iU7z5vHRGRyVJyJTAM9gyM8saeaR9+soN49QG5iJJ9dlYUjNIivPVXCs3+xmpz4SH67v5bHdldR3tKLMyyIm5akcntRBovTXedNnt0DwzS4B8hPck7hUclspeJscpQfJRB4PBaH6txsOdbMtmPNHKpzA5DiChsr1FbPjSc8RCcFRT4MFWci08jwqIcXDzbw6FsVHKz1JkabgSP/sHksIVqWxdvlbTy1t5Y/HGpgcMRDQZKT24rSuXlZGnGRoePe9++eP8z/vF3F+vwE/nRNNmvzErDbdCZULg8VZ5Oj/CiBqLlrgG3Hm9l6rJmdZa30DY0SGmRj9dw4Prc6mw0FiRd+ExEZR8WZyDR1qNbN43uqCA8O4pt/tGDCfboGhnmhpJ7f7K2lpKaTIJthfX4Cn1iWxjXzk8YKuht/sJP2niEGRjy09w6RFBXKzcvS+diiFArToi56yErv4AiOUC2RKOen4mxylB8l0A2OjLKnop2tx5p5oaQeR2gQ27/+EX83S2RaOl+O1F9YIgFsUbqLf0lffN59osKC+cyVWXzmyiyON3bzzP5ani+uZ8uxZiJDg9hcmMyNi1M43tjN3Vfn8NVr89h6tJmn9tXy053l/Of2k6RFh/PRhclsLkxmRVbMOXvU3qvv4mM/2MmqOXHctSab9fkJuuZNRGQWCA2yszYvgbV5CcRGhPCd10rpGRwhUifrRC4pfaJEZpCCZCcP3jCfb2yex+6KNp47UMdLhxp5el8tAIvTXYQG2bl+UQrXL0qho3eI14828fLhRh57p4pH36ogPjKU6xYmsXlhMqty4ggJen85xHfK27As7+LaX/zffThC7Gyan8Sm+Ymsy0sg5iJn9zrZ0kNEiJ0UV/hliYOIiFw+81OiADje2MWKrFg/t0ZkZlFxJjID2W2G1XPjWT03nm99vJCtx5o5UN3BhoKEM/aLcYRwW1EGtxVl0DM4wrZjzbx8pJHnDtTx+O5qnGFBbChI5Jr5iWzIT+RwvZtEZyhv/fVG3j7ZxkuHG3jlSBO/K6nHZmBpRjQbChLZUJBAYaoL2wQ9cB6Pxa0/3kX3wAgfW5zCTUtSuTovntAg9cCJiEwHC1K9xdk/vXiUFVkxZMY5WJDiZH5KFBEh+tNS5MPQNWciMs7A8Cg7y1p5/b0mthxrorVnCLvNEGQzrMmN59G7rhjbd9RjcbC2k23HW9h+vJmDdW4sC+IjQ1iXn8CGgkTW5cUTHeHtVTvR3MM1D23niuwYjjd20zXgHRazoSCB9fneW2JUmL8OXS4RXXM2OcqPMp1YlsWDzxzi3cp2ajr6GRrxAN7Jq+YmRFKY5qIwzcXidBeFqS7N7ihyFk0IIiIfmMdjUVzbyZajTewsa+XP1szhE8vSzrl/W88gO8pa2HashR1lLXT2DZ/RqzYy6uHhrSd45b51zIl3sOtkKy8damTr8WZaugcB75CZU4XaiqyYM4ZWnvKbd2v49bvV/PHydDYXJhM/wQyV4j8qziZH+VGmK4/HoqFrgPfquzhc5+ZIvZtDdW6aurzf5zYD+UlOFqe7WJwezdKMaAqSnQTbx3+vi8wWKs5ExC9GPRYltZ284etVK/EtDRARYufQ33/0jIlHLMviaEM320tb2F7azN7KDkY8Fo4QO6tz48eKtYzYCAA+/shbHKlzM+LxfoctSnOxPj+BVTlxLM+K1tAaP1NxNjnKjzLTNHcPcLDGzcHaTkpqvfcdfcMAhATZWJASxbr8BO7dmEuQCjWZZVSciUhAaO0ZZEdpC67wYDbNTzrvvj2DI+w60eor1lqo7egHIDM2gjW5cTz5bg1f3pjHtQuSeON4M28cb+FATSejHosgm2FxuouVc+K4MieWoqwYnGHBU3GI4qPibHKUH2WmsyyL2o5+Smo7OVjrZm9lO/urO/npnUVcu+D8+UBkplFxJiLTmmVZlLf28mZZKzvLWnmnvI2ewRGe/8s1LMmIHtuvZ3CEvZXt7K5oZ3d5GwdrvT1rNgOFaS6unBPLyjlxrMyOxRURTIO7n2+98B7LMqPZOC+JuQmOi17vTc5PxdnkKD/KbDM86uGqf9lKWLCN5ZkxxEWGEB8ZSnpMOJmxEWTFOYiJCNZ3ssxIKs5EZEYZHvXQ3D1IWvT5p+LvGxrhQHUnu8vbeKeineKaToZGPBgD85KjMMDRxi5OfQ3GOUIoyo7hiuxYVmTFsCA1SrNIfkAqziZH+VFmo6f31fKr3VW09w7R3jNE9+DIGa9HhgaRERtBTryDvKRI8pOc5CdFkhXn0DVrMq1pEWoRmVGC7bYLFmYAESFBrMmNZ01uPOCdhbKkppPdFe3sqWhnf3UH923K5+Zlaew62cqeynberWznlSNNAITYbcxPjWJZhvci9iUZ0WTHRehMrojIJXDrinRuXZE+9rx/aJTajj6q2vqobvfeqtp6OVzv5g+HG8ZOpAXbDTnxkWcUbPlJTrLiHGdcyywyHannTERmLcuyJiy0Gt0DHKjuoLimkwM1nRyqddM/PApAdEQwS3wzjp0q2GIvcvHt2UQ9Z5Oj/Chyfv1Do5xs6aG0qZvSph7Kmropbe6mpr1/bJ+QIBtzEyLJT4qkINnJ0oxoFqdHExmqvggJLOo5ExGZwLl6wJJdYVy/KIXrF6UAMDLqobSph5LaToqrOymu6eThsrKxs7hZcRFnFGsLNRxSROSSCg+xj62fdrq+oRFONPdwvLGbsmZv8ba3soPni+uB96fyP/07Oi8xUjNESsBSz5mIyAfQMzjCoVo3xTWdFNd4e9lOresTbDcsSIka+0NgaUY0c+Jn12Qj6jmbHOVHkUurs2/I9/3cyQHfSTV3v3cq//BgO4VpUSxJ935Hz0t28j9vVzLqsViY6mJhahTzU6IIC9ZJNrk8NCGIiMgUaHD3U+IbCllc3cmhOjd9Q97hkM6wIBakRI0l/oVpUcxNiJyxF7WrOJsc5UeRy8uyLKra+rwjIGo6Kanp5HB9F0MjHsDbw+YMCx4r4Ow2w9wEB4WpLhakRlGY5r2P0rIscgloWKOIyBRIcYWT4gpnc6F3OOSox6KsuZvi6k4O1rk5Ut/Fr3ZXMej7YyAkyEZBkpOFqVFckR3LzcvSsOlidhGRS84YQ3a8g+x4Bx9fmgZ4Z/493thNSW0nuQmRrJwTS21HP0fquzhS7/3OfutkK88cqBt7n7kJDoqyYlmRHUNRVswZoyLqO/s50dxDekw4aTHhGt4uH4iKMxGRy8RuM8xLjmJechSf8m0bGfVQ0dp7RvJ/6XAjT7xbgzFwy/L0876niIhcGsF227jr2DJiI8iIjWBzYfLYtpbuQY7Uuzlc52Z/dScvH2nkyb01AMQ6QlieGUNRdgxP7Kmmsq1v7OeSokLJiPG+X2ZsBAXJTvKTnGTHRZzzmjfLsqhs6yMmIhhXuNZ5m400rFFExM88HosbHt5JbUc/yzKjmZ8SRV6id2ro3MRIHNNwpjENa5wc5UeR6cPjsShv7WFvZQd7qzrYV9VBRWsvAP9yyyJC7DZqOvqoae+npqOP2vY+GroGxiaRCrHbmJsYSUFSJHlJTgqSnBQkO0mLDufxPdX83+cOAxAaZCPZFUZyVBhzEyPH8kJeYiQJztDzFm4nmnsIDbKRHhOuAi8AaVijiEgAs9kMD9+xjJ/uKOdoYxe/2FU5dh0EQFp0OPm+JD7dizYRkenOZjPkJjrJTXTyqZWZALT1DNLWO0R+knPCnxkYHh2bVbK0uZvSxm7erezgOd+skgARIXYsCxalufjEsjQa3f00dg1S39nPiwcbxq6HA3CFB1OQ7KQw1UVhmveauLkJkdhthvrOfjZ/bwcjHouosCAW+CY4mZ8SxYKUKHITIy9qshPLsrAsNNx+iimzi4gEgPwkJ/9+2xLAO/Sxur2P0qYeTjR71/QpbermrRNtDI2OL9pOFWsFyU4Wpbl0llREZIrFRYYSFxl6ztfDgideCqBrYJgy33f88cZuKtt6uXdTHsszY87Yz7IsWnoGKRtb462HYw1dPL6nioFhb14ID7YzP8WJ3WYY8Vj87Q3zqWjr5b36Lp7YUzO2XqfdZsiJd4wVbPNTnMxPiSLxrN64+39TwitHGlmSHk1eUiQ58Q5yEiLJSXCQ6gpX0XaZqDgTEQkwQXabLwFGAu9f93AxRdv91+Zz76Y8P7VcREQmIyosmBVZMazIijnvfsYYEp1hJDrDWJMbP7Z9ZNRDeWsvh+vcHK7r4nCdmyP1bq5dkMTn1+WM7Tfqsahq6+VYYzdHG7o42tDFvqoOflfyfs9drCOE+SlO5iV7ZxN+oaSehalR9A2N8Oz+OroHR8b2DQu2kR3nICfBQVacg6zYCDLjIsiKc5ASFTZWuG0vbeGvnj5IToJ337ToiLEJU9Kjw4mPDFWRdxZdcyYiMs2dKtr+5tlDVLf1seMbH/H7Aqu65mxylB9F5FLxeCyM4aJGUbj7hznmK9ZOFW7Hm7oZGPZgDLx63zrykpxjPXflLb2+Ww/lrb1UtPZS29HH8Oj79URIkI2MmHCy4hyUNnUzOOIh1RVGVXsfnX3DZ/z7IUE20qLDSY4KI8UV5r3Gzned3anH0eEhPLm3BsuyyIyNINkVRpwjlJiIYL/nug9K15yJiMxgp3raPnlFBl99soQF33yF7PgIcuIjmZPgYE6cd/roOfEO4iNDNOxRRGQGm0xPlCs8mCtz4rgyJ25s26jHoqK1l4HhUfJ819Cd3nO36rR9wXuCsME9QFVbH1XtvVS39VHZ1ktVWx89gyP8882LuGGRd4mZnsER6jr6qevso66jn9qOfmo7+2l0D7C7op2mrgFGPGd2HBkDE/UlGQPR4cHeIaWOEOIiQ4hzhPruQ4iLDCXWEUJ8ZAhJUWE4p8kadSrORERmiD9anIrHA6VN3Zxs6aW0uZstx5rOOKMZGRpEdnwEc+IjmRMXMVa0zYl3EB0R4sfWi4hIILDbDLmJkRe9f5DdNrYEwdXEn3ffyNAgCpK9s1NOxOOxaOsdotE9QGPXgG9SlAEWpblYnhVDVVsfLd2DtPUM0tozRHvvEG293selTT209bTRcVbv3Cmu8GBSo8NJcYWREBmKy7dcQVS49z7ad3/qFhUejN0PQy5VnImIzBBBdht/vOLMddJGRj3Udw5Q3tpDpW8ISkVbHyU1nbx4sJ7TT1DGRAQzNyGSwjQXf3/TwiluvYiIzHY2myHBGUqCM5RFuMa9nugMu+B7jIx6aO/zFW49Q7T2DNLoHqCmo4+GTm/Rd6Tejbt/eGwylXNxhga9X7z5irlPX5nJ2ryED3yMF6LiTERkBguy28iM816oTcGZrw2OjFLT3k9Fay+Vrb2Ut/ZwsqWXky09/mmsiIjIhxRkt40NwbyQwZFR3P3DuPuGvfdn3Tr7huk67fmJ5p5x181d8vZf1ncXEZGAFRpkJzcxclLDV0RERGaK0CA7iU77RRVyU2V6TnEiIiIiIiIyw6g4ExERERERCQAqzkRERERERAKAijMREREREZEAoOJMREREREQkAKg4ExERERERCQAqzkRERERERAKAijMREREREZEAoOJMREREREQkAKg4ExERERERCQAqzkRERERERAKAijMREREREZEAoOJMREREREQkAKg4ExERERERCQAqzkRERERERAKAijMREREREZEAoOJMREREREQkAKg4ExERERERCQAqzkRERERERAKAijMREREREZEAoOJMREREREQkAKg4ExERERERCQAqzkRERERERAKAsSxr6v4xY1qAqg/5NvFA6yVozkyjuIynmIynmIynmEzsw8Yly7KshEvVmJnuEuVH0O/zRBST8RSTiSku4ykm412KmJwzR05pcXYpGGP2WpZV5O92BBrFZTzFZDzFZDzFZGKKy/Sk/7fxFJPxFJOJKS7jKSbjXe6YaFijiIiIiIhIAFBxJiIiIiIiEgCmY3H2X/5uQIBSXMZTTMZTTMZTTCamuExP+n8bTzEZTzGZmOIynmIy3mWNybS75kxERERERGQmmo49ZyIiIiIiIjOOijMREREREZEAMK2KM2PMZmPMcWPMCWPMX/u7PVPFGPOoMabZGHP4tG2xxpjXjDFlvvsY33ZjjHnYF6ODxpjl/mv55WOMyTDGbDPGvGeMOWKM+Ypv+2yPS5gxZo8xpsQXl3/wbZ9jjNntO/4njTEhvu2hvucnfK9n+7P9l5Mxxm6MOWCM+b3v+ayOiTGm0hhzyBhTbIzZ69s2qz8/09lszY+gHDkR5cjxlB/PTflxPH/myGlTnBlj7MAjwPXAAuAOY8wC/7ZqyvwC2HzWtr8GtliWlQds8T0Hb3zyfLcvAD+eojZOtRHgAcuyFgCrgL/0/T7M9rgMAhsty1oCLAU2G2NWAf8GfNeyrFygA7jbt//dQIdv+3d9+81UXwGOnvZcMYGPWJa19LT1Wmb752damuX5EZQjJ6IcOZ7y47kpP07MPznSsqxpcQOuAl457fmDwIP+btcUHn82cPi058eBFN/jFOC47/FPgDsm2m8m34DngWsVlzNiEgHsB67Eu5J9kG/72GcJeAW4yvc4yLef8XfbL0Ms0n1fpBuB3wNGMaESiD9rmz4/0/A22/Oj75iVI88fH+XIM+Oh/Ph+LJQfJ46L33LktOk5A9KAmtOe1/q2zVZJlmU1+B43Akm+x7MuTr5u9WXAbhSXU8MTioFm4DXgJNBpWdaIb5fTj30sLr7X3UDc1LZ4SnwP+Abg8T2PQzGxgFeNMfuMMV/wbZv1n59pSv8/4+l32Uc58n3KjxNSfpyY33Jk0Af9QQkclmVZxphZuSaCMSYS+C1wn2VZXcaYsddma1wsyxoFlhpjooFngXl+bpJfGWNuBJoty9pnjNng7/YEkKsty6ozxiQCrxljjp3+4mz9/MjMM5t/l5Ujz6T8eCblx/PyW46cTj1ndUDGac/TfdtmqyZjTAqA777Zt33WxMkYE4w36fzKsqxnfJtnfVxOsSyrE9iGd0hCtDHm1MmY0499LC6+111A2xQ39XJbA9xkjKkEnsA7dOP7zO6YYFlWne++Ge8fKSvR52e60v/PeLP+d1k58tyUH8coP56DP3PkdCrO3gXyfDPIhACfAn7n5zb50++Az/kefw7vePJT2+/0zRyzCnCf1gU7Yxjv6b+fA0cty3rotJdme1wSfGcEMcaE473G4CjeJHSrb7ez43IqXrcCWy3fgOmZwrKsBy3LSrcsKxvv98ZWy7I+wyyOiTHGYYxxnnoMXAccZpZ/fqYx5cfxZvXvsnLkeMqP4yk/TszvOdLfF9xN5gbcAJTiHSP8t/5uzxQe96+BBmAY7zjWu/GO8d0ClAGvA7G+fQ3eWbtOAoeAIn+3/zLF5Gq844EPAsW+2w2KC4uBA764HAa+6dueA+wBTgBPAaG+7WG+5yd8r+f4+xguc3w2AL+f7THxHXuJ73bk1PfpbP/8TOfbbM2PvmNXjhwfE+XI8TFRfjx/fJQf34+FX3Ok8b2piIiIiIiI+NF0GtYoIiIiIiIyY6k4ExERERERCQAqzkRERERERAKAijMREREREZEAoOJMREREREQkAKg4ExERERERCQAqzkRERERERALA/wemknr0Jry1SgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model =  MLP(2,128,2, device).to(device)#MLP(input_size=100, hidden_size=128, output_size=120, device=device).to(device)#Regression().to(device)\n",
        "opto = torch.optim.Adam(model.parameters(), lr = .00009)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(opto, 25 , gamma=0.9)\n",
        "loss_fct = nn.MSELoss()\n",
        " \n",
        "generate_submission('./submission.csv', model, 500, 128, opto, scheduler, loss_fct, device, valid=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QnPQxcOlWx_e"
      },
      "id": "QnPQxcOlWx_e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "BEST_FINAL_SUBMIT_MLP_LR_DECAY_ELUactivation.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
